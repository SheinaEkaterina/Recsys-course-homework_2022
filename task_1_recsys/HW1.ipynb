{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data.csv')\n",
    "data.head()\n",
    "\n",
    "drop_columns = ['oaid_hash', 'banner_id0', 'banner_id1', 'rate0', 'rate1', 'g0', 'g1', 'coeff_sum0', 'coeff_sum1']\n",
    "data = data.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone_id</th>\n",
       "      <th>banner_id</th>\n",
       "      <th>campaign_clicks</th>\n",
       "      <th>os_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.582147e+07</td>\n",
       "      <td>1.582147e+07</td>\n",
       "      <td>1.582147e+07</td>\n",
       "      <td>1.582147e+07</td>\n",
       "      <td>1.582147e+07</td>\n",
       "      <td>15821472.0</td>\n",
       "      <td>1.582147e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.152679e+01</td>\n",
       "      <td>3.816483e+02</td>\n",
       "      <td>6.238540e-01</td>\n",
       "      <td>1.840605e+00</td>\n",
       "      <td>4.346986e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.668835e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.632448e+02</td>\n",
       "      <td>3.959386e+02</td>\n",
       "      <td>9.249152e+00</td>\n",
       "      <td>1.530005e+00</td>\n",
       "      <td>4.317701e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.611710e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>5.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>2.170000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>6.110000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.443000e+03</td>\n",
       "      <td>1.632000e+03</td>\n",
       "      <td>8.290000e+02</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            zone_id     banner_id  campaign_clicks         os_id  \\\n",
       "count  1.582147e+07  1.582147e+07     1.582147e+07  1.582147e+07   \n",
       "mean   8.152679e+01  3.816483e+02     6.238540e-01  1.840605e+00   \n",
       "std    1.632448e+02  3.959386e+02     9.249152e+00  1.530005e+00   \n",
       "min    0.000000e+00  0.000000e+00     0.000000e+00  0.000000e+00   \n",
       "25%    1.400000e+01  5.200000e+01     0.000000e+00  1.000000e+00   \n",
       "50%    1.900000e+01  2.170000e+02     0.000000e+00  2.000000e+00   \n",
       "75%    6.000000e+01  6.110000e+02     0.000000e+00  3.000000e+00   \n",
       "max    3.443000e+03  1.632000e+03     8.290000e+02  1.000000e+01   \n",
       "\n",
       "         country_id  impressions        clicks  \n",
       "count  1.582147e+07   15821472.0  1.582147e+07  \n",
       "mean   4.346986e+00          1.0  2.668835e-02  \n",
       "std    4.317701e+00          0.0  1.611710e-01  \n",
       "min    0.000000e+00          1.0  0.000000e+00  \n",
       "25%    0.000000e+00          1.0  0.000000e+00  \n",
       "50%    4.000000e+00          1.0  0.000000e+00  \n",
       "75%    7.000000e+00          1.0  0.000000e+00  \n",
       "max    1.600000e+01          1.0  1.000000e+00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates: ['2021-09-01', '2021-09-26', '2021-09-27', '2021-09-28', '2021-09-29', '2021-09-30', '2021-10-01', '2021-10-02']\n",
      "Count of null data:  0\n",
      "2     4589979\n",
      "0     3856798\n",
      "1     3178693\n",
      "4     3012541\n",
      "3      759767\n",
      "6      310346\n",
      "5      111946\n",
      "8        1273\n",
      "7          99\n",
      "9          25\n",
      "10          5\n",
      "Name: os_id, dtype: int64\n",
      "0     4956393\n",
      "5     1910054\n",
      "6     1582705\n",
      "7     1525569\n",
      "1     1346321\n",
      "3     1337392\n",
      "15     603301\n",
      "12     478038\n",
      "9      439004\n",
      "4      388801\n",
      "10     356490\n",
      "11     212245\n",
      "8      210211\n",
      "13     190855\n",
      "14     138385\n",
      "16      79166\n",
      "2       66542\n",
      "Name: country_id, dtype: int64\n",
      "17      2280422\n",
      "14      1638642\n",
      "12       736352\n",
      "0        708379\n",
      "19       693292\n",
      "         ...   \n",
      "2186          1\n",
      "2188          1\n",
      "2518          1\n",
      "2962          1\n",
      "3443          1\n",
      "Name: zone_id, Length: 3444, dtype: int64\n",
      "22      613367\n",
      "361     387563\n",
      "3       286999\n",
      "18      262946\n",
      "21      246378\n",
      "         ...  \n",
      "1501         1\n",
      "1503         1\n",
      "1504         1\n",
      "1507         1\n",
      "1632         1\n",
      "Name: banner_id, Length: 1633, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def analysis(data: pd.DataFrame):\n",
    "    # По data.describe заметим, что все значения impressions = 1, значит колонка бесполезна\n",
    "    # Посчитаем в каких временных интервалах лежат наши данные\n",
    "    print(\"Dates:\", sorted(set(data['date_time'].map(lambda s: s[:10]))))\n",
    "    # Заметим лишний день в нашей неделе - 1 сентября\n",
    "    \n",
    "    # Посмотрим на пропущенные значения\n",
    "    print(\"Count of null data: \", data.isnull().sum().sum())\n",
    "    # Пропущенных данных нет\n",
    "    \n",
    "    # Проверим, что все категориальные фичи представленны в достаточном количестве\n",
    "    print(data['os_id'].value_counts())\n",
    "    # Заметим, что некоторые os-и не популярны: 8, 7, 9, 10. Объединим их в одну группу\n",
    "    print(data['country_id'].value_counts())\n",
    "    # Страны представлены в достаточном количестве\n",
    "    print(data['zone_id'].value_counts())\n",
    "    # Среди мест баннера есть непопулярные, закодируем их в одну группу\n",
    "    print(data['banner_id'].value_counts())\n",
    "    # Среди банеров есть как очень популярные, по которым много информации, также много тех, что встречаются 1 раз во всем датасете, то есть не несут в себе полезной информации\n",
    "\n",
    "\n",
    "analysis(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def feature_engineering(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Удаляем 1е сентября\n",
    "    data.drop(data[data['date_time'].map(lambda s: s[:10]) == '2021-09-01'].index, inplace=True, axis=0)\n",
    "    # Преобразуем дату в datetime для дальнейших манипуляций\n",
    "    data['datetime'] = pd.to_datetime(data['date_time'])\n",
    "    # Добавим фичи, говорящие о дне недели (поведение пользователей в рабочие дни могут отличаться от выходных)\n",
    "    data[\"day_of_week\"] = data[\"datetime\"].dt.dayofweek\n",
    "    # Добавим фичи, времени суток\n",
    "    data['hour'] = data[\"datetime\"].dt.hour\n",
    "    # Удаляем непопулярные значения\n",
    "    zone_mask = data['zone_id'].isin(data.groupby('zone_id')['date_time'].count().sort_values(key=lambda x: -x).index[250:])\n",
    "    data.loc[zone_mask, 'zone_id'] = 0\n",
    "    os_mask = data['os_id'].isin(data.groupby('os_id')['date_time'].count().sort_values(key=lambda x: -x).index[7:])\n",
    "    data.loc[os_mask, 'os_id'] = 0\n",
    "    banner_mask = data['banner_id'].isin(data.groupby('banner_id')['date_time'].count().sort_values(key=lambda x: -x).index[600:])\n",
    "    data.loc[banner_mask, 'banner_id'] = 0\n",
    "    categorical_cols = [\"zone_id\", \"os_id\", \"day_of_week\", \"hour\", \"country_id\", \"banner_id\"]\n",
    "    # Понадобится в будущем для кросс-валидации\n",
    "    data = data.sort_values(\"datetime\")\n",
    "    return categorical_cols, data\n",
    "\n",
    "categorical_cols, df = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data: pd.DataFrame, categorical_cols):\n",
    "    train_condition = data['date_time'].apply(lambda s: s.split()[0]) < '2021-10-02'\n",
    "    test_condition = data['date_time'].apply(lambda s: s.split()[0]) == '2021-10-02'\n",
    "    train_data = data[train_condition]\n",
    "    test_data = data[test_condition]\n",
    "\n",
    "    train_val = train_data['clicks']\n",
    "    test_val = test_data['clicks']\n",
    "    \n",
    "    train_data = train_data.drop(['clicks', 'date_time', 'datetime'], axis=1)\n",
    "    test_data = test_data.drop(['clicks', 'date_time', 'datetime'], axis=1)\n",
    "    \n",
    "    # Сразу создаем sparse-матрицы, так как в категориальных фичах будет много 0\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse = True)\n",
    "    ohe.fit(train_data[categorical_cols])\n",
    "    # Encoding задаем только на train, но значения кодируем везде\n",
    "    train_data = ohe.transform(train_data[categorical_cols])\n",
    "    test_data = ohe.transform(test_data[categorical_cols])\n",
    "\n",
    "    return train_data, train_val, test_data, test_val\n",
    "\n",
    "train_data, train_val, test_data, test_val = train_test_split(df, categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<13692493x900 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 82154958 stored elements in Compressed Sparse Row format>,\n",
       " 8423230     0\n",
       " 7683145     0\n",
       " 4647065     0\n",
       " 11536774    0\n",
       " 1442602     0\n",
       "            ..\n",
       " 2876844     0\n",
       " 10358819    0\n",
       " 15652742    0\n",
       " 14917859    0\n",
       " 13364121    0\n",
       " Name: clicks, Length: 13692493, dtype: int64,\n",
       " 346887,\n",
       " <2128978x900 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 10514650 stored elements in Compressed Sparse Row format>,\n",
       " 9767447     0\n",
       " 13846765    0\n",
       " 3091651     0\n",
       " 10045990    0\n",
       " 9054327     0\n",
       "            ..\n",
       " 1745969     0\n",
       " 13959634    0\n",
       " 13319080    0\n",
       " 3336944     0\n",
       " 3226555     0\n",
       " Name: clicks, Length: 2128978, dtype: int64,\n",
       " 75362)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_val, train_val.sum(), test_data, test_val, test_val.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    return LogisticRegression(solver='liblinear', random_state=42, penalty=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] END ............................................C=0.001; total time=   7.7s\n",
      "[CV] END ............................................C=0.001; total time=  15.1s\n",
      "[CV] END ............................................C=0.001; total time=  26.6s\n",
      "[CV] END .............................................C=0.01; total time=  11.7s\n",
      "[CV] END .............................................C=0.01; total time=  26.5s\n",
      "[CV] END .............................................C=0.01; total time=  38.7s\n",
      "[CV] END ..............................................C=0.1; total time=  16.6s\n",
      "[CV] END ..............................................C=0.1; total time=  48.0s\n",
      "[CV] END ..............................................C=0.1; total time= 1.2min\n",
      "{'mean_fit_time': array([14.55146027, 23.78637997, 44.61973286]), 'std_fit_time': array([ 7.6981539 , 11.01271569, 23.72757774]), 'mean_score_time': array([1.93299039, 1.83300289, 1.87705056]), 'std_score_time': array([0.06693285, 0.04160138, 0.11077021]), 'param_C': masked_array(data=[0.001, 0.01, 0.1],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.001}, {'C': 0.01}, {'C': 0.1}], 'split0_test_neg_log_loss': array([-0.09355058, -0.09089676, -0.0907356 ]), 'split1_test_neg_log_loss': array([-0.11580901, -0.11368485, -0.11339297]), 'split2_test_neg_log_loss': array([-0.15093519, -0.14673742, -0.14588952]), 'mean_test_neg_log_loss': array([-0.12009826, -0.11710634, -0.1166727 ]), 'std_test_neg_log_loss': array([0.02362268, 0.02292487, 0.02263561]), 'rank_test_neg_log_loss': array([3, 2, 1], dtype=int32), 'split0_test_roc_auc': array([0.62903309, 0.65942337, 0.66935166]), 'split1_test_roc_auc': array([0.65767575, 0.69271375, 0.70036458]), 'split2_test_roc_auc': array([0.7495972 , 0.76505231, 0.765687  ]), 'mean_test_roc_auc': array([0.67876868, 0.70572981, 0.71180108]), 'std_test_roc_auc': array([0.05143027, 0.04409408, 0.04015154]), 'rank_test_roc_auc': array([3, 2, 1], dtype=int32)}\n",
      "Best score: -0.11667269635623645 \n",
      "Best params: {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def cv(train_data, train_val):\n",
    "    model = create_model()\n",
    "    param_search = {'C' : [0.001, 0.01, 0.1]}\n",
    "    \n",
    "    # TimeSeriesSplit чтобы тестовые данные были позже обучающих(иначе получится, что учимся на данных, которые учитывают вердикт)\n",
    "    splits = TimeSeriesSplit(n_splits=3)\n",
    "    gsearch = GridSearchCV(estimator=model, cv=splits,\n",
    "                            param_grid=param_search, verbose=2, scoring=[\"neg_log_loss\", \"roc_auc\"], refit=\"neg_log_loss\")\n",
    "    gsearch.fit(train_data, train_val)\n",
    "\n",
    "    print(gsearch.cv_results_)\n",
    "    # выбираем лучшую по logloss model\n",
    "    best_model = gsearch.best_estimator_\n",
    "    print(\"Best score: {} \\nBest params: {}\".format(gsearch.best_score_, gsearch.best_params_))\n",
    "    \n",
    "    return best_model.fit(train_data, train_val)\n",
    "\n",
    "model = cv(train_data, train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  0.7754759364636382 0.13552848196046108\n",
      "Random:  0.5 0.15303289904918688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "predictions = model.predict_proba(test_data)\n",
    "baseline = np.full(test_val.shape, np.mean(test_val))\n",
    "\n",
    "print('Model: ', roc_auc_score(test_val, model.predict_proba(test_data)[:, 1]), log_loss(test_val, model.predict_proba(test_data)))\n",
    "print('Random: ', roc_auc_score(test_val, baseline), log_loss(test_val, baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
