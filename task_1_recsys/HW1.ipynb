{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9pqZgUYC5wCl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_uZoDnqYUkw"
      },
      "source": [
        "Я работаю в гугл колабе и беру данные с гугл диска. При необходимости поменяйте два блока внизу на нужный вам способ хранения и получения данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFCGO7gC6AGm",
        "outputId": "249d2a21-3a76-4bd6-c543-3d21b7b7cfe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SKq0BSKs6qGk"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Recsys_data1.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C3ecsUpYiImI"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YU6capgtiBE1"
      },
      "outputs": [],
      "source": [
        "def analysis(data: pd.DataFrame):\n",
        "    data = data.drop(['oaid_hash', 'banner_id0', 'banner_id1', 'rate0', 'rate1', 'g0', 'g1', 'coeff_sum0',  'coeff_sum1'], axis=1) #remove unnecessary cols (according to the task)\n",
        "    print(data.head)\n",
        "    print(\"Data contains null is \", data.isnull().values.any()) #check if contains null\n",
        "    print(len(df[df['impressions'] == 0])) #check if impressions contains 0\n",
        "    #count how many data on each day we have\n",
        "    cur = data.copy()\n",
        "    cur['date_time'] = cur['date_time'].apply(lambda x: x[:10])\n",
        "    cur = cur.groupby(['date_time']).size()\n",
        "    print(cur)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIwRDUPbphz1",
        "outputId": "b31c157b-51d5-42c8-a715-3a0dda42e72c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of                            date_time  zone_id  banner_id  campaign_clicks  \\\n",
            "0         2021-09-27 00:01:30.000000        0          0                0   \n",
            "1         2021-09-26 22:54:49.000000        1          1                0   \n",
            "2         2021-09-26 23:57:20.000000        2          2                3   \n",
            "3         2021-09-27 00:04:30.000000        3          3                0   \n",
            "4         2021-09-27 00:06:21.000000        4          4                0   \n",
            "...                              ...      ...        ...              ...   \n",
            "15821467  2021-10-02 15:51:35.000000      146        530                0   \n",
            "15821468  2021-09-27 22:03:14.000000       12         22                0   \n",
            "15821469  2021-10-02 17:41:10.000000       12       1236                0   \n",
            "15821470  2021-09-29 00:39:32.000000      967         21                0   \n",
            "15821471  2021-09-28 07:00:18.000000       19        635                0   \n",
            "\n",
            "          os_id  country_id  impressions  clicks  \n",
            "0             0           0            1       1  \n",
            "1             0           1            1       1  \n",
            "2             0           0            1       1  \n",
            "3             1           1            1       1  \n",
            "4             1           0            1       1  \n",
            "...         ...         ...          ...     ...  \n",
            "15821467      2           9            1       0  \n",
            "15821468      1           6            1       0  \n",
            "15821469      2           0            1       0  \n",
            "15821470      0           0            1       0  \n",
            "15821471      0           3            1       0  \n",
            "\n",
            "[15821472 rows x 8 columns]>\n",
            "Data contains null is  False\n",
            "0\n",
            "date_time\n",
            "2021-09-01          1\n",
            "2021-09-26    3102610\n",
            "2021-09-27    2367303\n",
            "2021-09-28    2307355\n",
            "2021-09-29    2420588\n",
            "2021-09-30    1851189\n",
            "2021-10-01    1643448\n",
            "2021-10-02    2128978\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "df = analysis(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO2H2rnno3wh"
      },
      "source": [
        "Выводы из анализа данных:\n",
        "1. Есть ненужная числовая зависимость в колонках zone_id, banner_id, os_id, country_id, значит в обработке будем использовать например OneHotEncoding.\n",
        "\n",
        "2. В данных нет null.\n",
        "3. Все impressions равны 1 (что логично), так что уберем этот столбец.\n",
        "\n",
        "4. Также есть день 2021-09-01, для которого есть всего одна запись и он далеко от остальных. Видимо он попал в данные случайно, его надо удалить.\n",
        "\n",
        "5. Последний день (который будем брать в тест) 2021-10-02.\n",
        "\n",
        "Ровно этим и будем заниматься в функции feature_engineering. Правда в OneHotEncoding отправим все данные, потому что, они так сожмутся. А без сжатия трудно закодировать даже один столбец.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E73TkBzfo2k5"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "#feature engineering according to the analysis and spliting into train and test\n",
        "def feature_engineering(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    data = data.drop(['impressions'], axis=1)\n",
        "    data = data[data['date_time'] > '2021-09-20']\n",
        "    enc = OneHotEncoder(handle_unknown='ignore')\n",
        "    enc = enc.fit(data.drop(['clicks', 'date_time'], axis=1))\n",
        "    cur = data[data['date_time'] < '2021-10-02']\n",
        "    x_train = cur.drop(['clicks', 'date_time'], axis=1)\n",
        "    x_train = enc.transform(x_train)\n",
        "    y_train = cur['clicks']\n",
        "    cur = data[data['date_time'] >= '2021-10-02']\n",
        "    x_test = cur.drop(['clicks', 'date_time'], axis=1)\n",
        "    x_test = enc.transform(x_test)\n",
        "    y_test = cur['clicks']\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DaVOWexokcJ_"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test = feature_engineering(df)\n",
        "df = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jHqPA3Ka09e"
      },
      "source": [
        "Дальше создаем макет линейной модели. В качестве оптимизатора берем liblinear. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SwCYFpupV2or"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def create_model(fit_intercept=False, solver='liblinear', C=0.5, penalty='l2'):\n",
        "    model = LogisticRegression(solver='liblinear', C=C, penalty=penalty, fit_intercept=fit_intercept)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w5D_Cs9bcbV"
      },
      "source": [
        "Делаем тесты с l2 регуляризацией."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb5aQ3G6q4uM",
        "outputId": "bfff7030-ad3f-4590-b481-6ba6cf348750"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.001\n",
            "mean_test_neg_log_loss -0.11093903850984717\n",
            "test_roc_auc 0.7059417789326434\n",
            "0.01\n",
            "mean_test_neg_log_loss -0.109815321105411\n",
            "test_roc_auc 0.7178021331020474\n",
            "0.1\n",
            "mean_test_neg_log_loss -0.11000979333761407\n",
            "test_roc_auc 0.7164108310476427\n",
            "1.0\n",
            "mean_test_neg_log_loss -0.11025877812638318\n",
            "test_roc_auc 0.7153793959727327\n",
            "10.0\n",
            "mean_test_neg_log_loss -0.11043268421479822\n",
            "test_roc_auc 0.7149254488556916\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "c_arr_l2 = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
        "\n",
        "for C in c_arr_l2:\n",
        "    model = create_model(C=C)\n",
        "    scores = cross_validate(model, x_train, y_train, scoring=['neg_log_loss', 'roc_auc'], cv=4)\n",
        "    print(C)\n",
        "    print('mean_test_neg_log_loss', np.mean(scores['test_neg_log_loss']))\n",
        "    print('test_roc_auc', np.mean(scores['test_roc_auc']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tenvNDTLbsGJ"
      },
      "source": [
        "Также я проводила эксперименты с l1 регуляризацией. Они работали в несколько раз дольше, но не давали значительного прироста метрик. Еще были проведены эксперементы с наличием свободного коэффициента (fit_interceipt=True), но это также не оказало влияния на результат. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drh-URSLcIvs"
      },
      "source": [
        "В итоге как оптимальный из рассмотренных вариантов берем l2 регуляризацию с коэффициентом 0.01."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "nU4ZLTKt0HWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb7676e-99b8-49cb-97e5-c748fba3e66a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auc: 0.779, log_loss: 0.134\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "best_C = 0.01\n",
        "model = create_model(C=best_C)\n",
        "model = model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "auc_metric = roc_auc_score(y_test, model.predict_proba(x_test)[:, 1])\n",
        "log_loss_metric = log_loss(y_test, model.predict_proba(x_test))\n",
        "print('Auc: {:.3f}, log_loss: {:.3f}'.format(auc_metric, log_loss_metric))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UivxNBjd5cjd"
      },
      "source": [
        "Теперь сравним с бейзлайном."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "pAHGsVR55eNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d949e36-587f-49c3-af6a-7237efc383b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auc base: 0.500, log_loss base: 0.155\n"
          ]
        }
      ],
      "source": [
        "y_pred_base = np.full(y_pred.shape, np.mean(y_train))\n",
        "auc_metric_base = roc_auc_score(y_test, y_pred_base)\n",
        "log_loss_metric_base = log_loss(y_test, y_pred_base)\n",
        "print('Auc base: {:.3f}, log_loss base: {:.3f}'.format(auc_metric_base, log_loss_metric_base))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наша модель по метрикам превзошла бейзлайн. Ура."
      ],
      "metadata": {
        "id": "eXqX22_gmuKN"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}