{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Я сделал задание в .py файле (так было удобнее его запускать каждый раз + юпитер ноутбук не справляется с освобождением памяти после загрукзи датасета 1 раз в память)\n",
    "\n",
    "Сюда просто переношу фрагментами и объясняю, что они делают.\n",
    "\n",
    "Также, в разных частях кода я использую не весь датасет, а его часть - это связано с тем, что кросс-валидацию и другие вещи на всём датасете делать очень долго, и у меня не хватает памяти (16гб оперативки), чтобы делать это параллельно"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Зафиксируем рандом, чтобы добиться воспроизводимости результатов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "random.seed(1337)\n",
    "np.random.seed(1337)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В качестве модели возьмём логистическую регрессию. В ней можно использовать разные оптимизаторы, если мы хотим не sgd и работать на больших данных, то подходит lbfgs и newton-cg, так как указано, что они лучше сходятся для большого объема данных. На деле лучше сходится liblinear, его и используем"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_model(C=0.1):\n",
    "    return LogisticRegression(penalty='l2',\n",
    "                              C=C,\n",
    "                              solver='liblinear',\n",
    "                              random_state=1337,\n",
    "                              max_iter=100,\n",
    "                              verbose=0\n",
    "                              )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Функция для препроцессинга\n",
    "\n",
    "Время в чистом виде использовать сложно. Скорее всего, на клик может влиять день недели (например, в пятницу-воскресенье все расслабляются и охотнее покупают), и час (днём, на работе, некогда отвлекаться на рекламу, но вечером и дома вполне можно). Поэтому я добавляю фичи день недели и час. Однако я померил и особо крутого прироста они не дают\n",
    "\n",
    "campaing_clicks единственная фича, которую можно интерпретироавть как числовую - вероятно, чем меньше campagin_click, тем лучше реклама. Поэтому её надо отнормализовать\n",
    "\n",
    "Остальные фичи нужно one-hot-encodить. Получится на самом деле очень много фич, больше 4000"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "ohe = None # OneHotEncoder должен быть обучен по всему датасету, так что мы его запомним"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def preprocess(X, y, remember=False, return_last_day=False):\n",
    "    global ohe\n",
    "\n",
    "    X['date_time'] = pd.to_datetime(X['date_time'])\n",
    "\n",
    "    if return_last_day:\n",
    "        idx = X['date_time'].dt.date == X['date_time'].dt.date.max()\n",
    "\n",
    "    X['day_of_week'] = X['date_time'].dt.dayofweek\n",
    "    X['hour'] = X['date_time'].dt.hour\n",
    "\n",
    "    X = X.drop(columns=['date_time'])\n",
    "\n",
    "    to_normalize = ['campaign_clicks']\n",
    "    to_one_hot = ['zone_id', 'banner_id', 'os_id', 'country_id', 'day_of_week', 'hour']\n",
    "\n",
    "    X[to_normalize] = StandardScaler().fit_transform(X[to_normalize])\n",
    "\n",
    "    X_to = X[to_one_hot]\n",
    "\n",
    "    if ohe is None:\n",
    "        ohe = OneHotEncoder()\n",
    "        X_to = ohe.fit_transform(X_to)\n",
    "        if not remember:\n",
    "            ohe = None\n",
    "    else:\n",
    "        X_to = ohe.transform(X_to)\n",
    "\n",
    "\n",
    "    X = X.drop(columns=to_one_hot)\n",
    "    X = sparse.hstack([X, X_to])\n",
    "    X = X.tocsr()\n",
    "\n",
    "    if return_last_day:\n",
    "        X_last, y_last = X[idx], y[idx]\n",
    "        return X, y, X_last, y_last\n",
    "    else:\n",
    "        return X, y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Просто функция, которая достаёт и препроцессит нужное количество данных, опционально шаффлит\n",
    "\n",
    "При этом можно заметить, что некоторые колонки вообще не нужны: impressions всегда 1 (реклама в датасете всегда была показана), так что можно её выкинуть"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_data(nrows=None, remember=False, shuffle=True, return_last_day=False):\n",
    "    df = pd.read_csv('/opt/downloads/ml/recsys/data.csv',\n",
    "                     nrows=nrows,\n",
    "                     usecols=[\n",
    "                         'date_time',\n",
    "                         'zone_id',\n",
    "                         'banner_id',\n",
    "                         'campaign_clicks',\n",
    "                         'os_id',\n",
    "                         'country_id',\n",
    "                         'clicks'\n",
    "                     ])\n",
    "\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    X, y = df.drop(columns=['clicks']), df['clicks']\n",
    "\n",
    "    return preprocess(X, y, remember=remember, return_last_day=return_last_day)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Фич получилось многовато. Давайте сделаем feature selection и отсечем фичи с низкой важностью"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def select_features(validate=False):\n",
    "    X, y = get_data(1000000, shuffle=False)\n",
    "\n",
    "    model = get_model()\n",
    "\n",
    "    fs = SelectFromModel(model)\n",
    "    fs.fit(X, y)\n",
    "\n",
    "    if validate:\n",
    "        X, y = get_data(1000000, shuffle=False)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "        model_full, model_sel = get_model(), get_model()\n",
    "\n",
    "        model_full.fit(X_train, y_train)\n",
    "        model_sel.fit(fs.transform(X_train), y_train)\n",
    "        print(model_full.score(X_test, y_test))\n",
    "        print(model_sel.score(fs.transform(X_test), y_test))\n",
    "\n",
    "    return fs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Займёмся регуляризацией. Попробуем разные C и сделаем дополнительно кросс-валидацию"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def adjust_regularization():\n",
    "    X, y = get_data(1000000, shuffle=False)\n",
    "\n",
    "    metrics = ['neg_log_loss', 'roc_auc']\n",
    "\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    nlls = []\n",
    "    print('Regularization')\n",
    "    for C in Cs:\n",
    "        model = get_model(C=C)\n",
    "        cv = cross_validate(model, X, y, cv=5, n_jobs=5, return_estimator=True, scoring=metrics, verbose=0)\n",
    "\n",
    "        print(f'C = {C}')\n",
    "        for i, metric in enumerate(metrics):\n",
    "            metric_values = cv[f\"test_{metric}\"]\n",
    "            print(f'{metric}: avg: {np.average(metric_values)}, metrics: {metric_values}')\n",
    "        nlls.append(np.average(cv[f\"test_neg_log_loss\"]))\n",
    "    return Cs[np.argmax(nlls)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Наконец запустим наш код"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1437/5137 features\n",
      "Regularization\n",
      "C = 0.001\n",
      "neg_log_loss: avg: -0.680740132490651, metrics: [-0.84411357 -0.66685434 -0.64370331 -0.61320486 -0.63582459]\n",
      "roc_auc: avg: 0.6126805811728866, metrics: [0.42206964 0.62120583 0.65443841 0.69926418 0.66642484]\n",
      "C = 0.01\n",
      "neg_log_loss: avg: -0.7080524329656097, metrics: [-1.01587563 -0.65578927 -0.62851286 -0.60638804 -0.63369636]\n",
      "roc_auc: avg: 0.6215720009055564, metrics: [0.39627361 0.6485326  0.68049035 0.70801284 0.6745506 ]\n",
      "C = 0.1\n",
      "neg_log_loss: avg: -0.7251968199238948, metrics: [-1.1081896  -0.65190166 -0.62514571 -0.6078433  -0.63290382]\n",
      "roc_auc: avg: 0.6274334783727794, metrics: [0.40571681 0.65757954 0.68653014 0.70813095 0.67920994]\n",
      "C = 1\n",
      "neg_log_loss: avg: -0.7292812735916836, metrics: [-1.12759203 -0.65129937 -0.62507155 -0.60913393 -0.63330949]\n",
      "roc_auc: avg: 0.6298197225877247, metrics: [0.41244255 0.66028188 0.68792361 0.70787271 0.68057787]\n",
      "C = 10\n",
      "neg_log_loss: avg: -0.7305484660254434, metrics: [-1.13131221 -0.65187174 -0.62556138 -0.61007486 -0.63392215]\n",
      "roc_auc: avg: 0.6302438799469016, metrics: [0.41394992 0.66076618 0.68812689 0.707669   0.68070739]\n",
      "Selected 0.001 for regularization\n",
      "Auc: 0.7740441159302278, ll: 0.13460922473523965\n",
      "Auc: 0.5, ll: 0.1543597869812059\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = get_data(None, remember=True, shuffle=True, return_last_day=True)\n",
    "\n",
    "fs = select_features()\n",
    "print(f'Selected {np.sum(fs.get_support())}/{len(fs.get_support())} features')\n",
    "X_train = fs.transform(X_train)\n",
    "X_test = fs.transform(X_test)\n",
    "\n",
    "C = adjust_regularization()\n",
    "print(f'Selected {C} for regularization')\n",
    "\n",
    "model = get_model(C=C)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "ll = log_loss(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(f'Auc: {auc}, ll: {ll}')\n",
    "\n",
    "y_test_pred_baseline = np.full(y_test_pred.shape, np.mean(y_train))\n",
    "auc_baseline = roc_auc_score(y_test, y_test_pred_baseline)\n",
    "ll_baseline = log_loss(y_test, y_test_pred_baseline)\n",
    "print(f'Auc: {auc_baseline}, ll: {ll_baseline}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Бейзлайн превзойдён!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
