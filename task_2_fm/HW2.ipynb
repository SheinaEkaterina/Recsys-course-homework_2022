{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlearn as xl"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Считываем данные и сразу дропаем ненужные фичи. Как и в первой домашке беру рандомно один процент данных для ускорения и потому что xlearn.cv не считает метрики на всём датасете: показывает -nan(ind)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                           date_time  zone_id  banner_id            oaid_hash  \\\n741246    2021-09-29 18:06:03.000000       13        358  9147519693626110830   \n11133560  2021-09-26 02:04:47.000000        0          3  6359232853395132451   \n5348767   2021-09-28 00:26:59.000000       15         16   794521774265082201   \n4078254   2021-09-26 17:07:20.000000       17         59  3250419304175957434   \n8784861   2021-09-29 15:47:26.000000       17         22  2904848336510916961   \n\n          campaign_clicks  os_id  country_id  impressions  clicks  \n741246                  0      2           5            1       0  \n11133560                0      2           1            1       0  \n5348767                16      0           6            1       0  \n4078254                 0      2           7            1       0  \n8784861                 0      2           7            1       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>zone_id</th>\n      <th>banner_id</th>\n      <th>oaid_hash</th>\n      <th>campaign_clicks</th>\n      <th>os_id</th>\n      <th>country_id</th>\n      <th>impressions</th>\n      <th>clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>741246</th>\n      <td>2021-09-29 18:06:03.000000</td>\n      <td>13</td>\n      <td>358</td>\n      <td>9147519693626110830</td>\n      <td>0</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11133560</th>\n      <td>2021-09-26 02:04:47.000000</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6359232853395132451</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5348767</th>\n      <td>2021-09-28 00:26:59.000000</td>\n      <td>15</td>\n      <td>16</td>\n      <td>794521774265082201</td>\n      <td>16</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4078254</th>\n      <td>2021-09-26 17:07:20.000000</td>\n      <td>17</td>\n      <td>59</td>\n      <td>3250419304175957434</td>\n      <td>0</td>\n      <td>2</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8784861</th>\n      <td>2021-09-29 15:47:26.000000</td>\n      <td>17</td>\n      <td>22</td>\n      <td>2904848336510916961</td>\n      <td>0</td>\n      <td>2</td>\n      <td>7</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/data.csv').sample(frac=0.01, random_state=1337)\n",
    "data.drop(['banner_id0', 'banner_id1', 'rate0', 'rate1', 'g0', 'g1', 'coeff_sum0', 'coeff_sum1'], axis=1, inplace=True)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пользуемся анализом из прошлой задачи + проверяем, что в новом поле нет нулов и смотрим на количество разных юзеров"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any nulls in oaid_hash=False\n",
      "Number of users=148281\n"
     ]
    }
   ],
   "source": [
    "def analysis(data: pd.DataFrame):\n",
    "    print(f\"Any nulls in oaid_hash={data['oaid_hash'].isnull().values.any()}\")\n",
    "    print(f\"Number of users={data['oaid_hash'].nunique()}\")\n",
    "    data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "\n",
    "analysis(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Эта часть полностью дублирует прошлую задачу: удаляем campaign_clicks и impressions. И разделяем на train и test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def feature_engineering(data: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame):\n",
    "    data.drop(['campaign_clicks', 'impressions'], axis=1, inplace=True)\n",
    "    train = data[data['date_time'] < '2021-10-02']\n",
    "    train_clicks = train['clicks']\n",
    "    test = data[data['date_time'] >= '2021-10-02']\n",
    "    test_clicks = test['clicks']\n",
    "    train = train.drop(['date_time', 'clicks'], axis=1)\n",
    "    test = test.drop(['date_time', 'clicks'], axis=1)\n",
    "    return train, train_clicks, test, test_clicks\n",
    "\n",
    "train, train_clicks, test, test_clicks = feature_engineering(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Факторизуем все столбцы, так как все фичи у нас категориальные"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def factor_encoding(train, test):\n",
    "    full = pd.concat([train, test], axis=0, sort=False)\n",
    "    # Factorize everything\n",
    "    for f in full:\n",
    "        full[f], _ = pd.factorize(full[f])\n",
    "        full[f] += 1\n",
    "\n",
    "    return full.iloc[:train.shape[0]], full.iloc[train.shape[0]:]\n",
    "\n",
    "train_f, test_f = factor_encoding(train, test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Приводим к libffm формату: эту клетку я взял с одного ноутбука из kaggle. Сохраняем train и test в файлы."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class LibFFMEncoder(object):\n",
    "    def __init__(self):\n",
    "        self.encoder = 1\n",
    "        self.encoding = {}\n",
    "\n",
    "    def encode_for_libffm(self, row):\n",
    "        txt = f\"{row[0]}\"\n",
    "        for i, r in enumerate(row[1:]):\n",
    "            try:\n",
    "                txt += f' {i+1}:{self.encoding[(i, r)]}:1'\n",
    "            except KeyError:\n",
    "                self.encoding[(i, r)] = self.encoder\n",
    "                self.encoder += 1\n",
    "                txt += f' {i+1}:{self.encoding[(i, r)]}:1'\n",
    "\n",
    "        return txt\n",
    "\n",
    "encoder = LibFFMEncoder()\n",
    "libffm_format_trn = pd.concat([train_clicks, train_f], axis=1).apply(\n",
    "        lambda row: encoder.encode_for_libffm(row), raw=True, axis=1\n",
    ")\n",
    "libffm_format_tst = pd.concat([test_clicks, test_f], axis=1).apply(\n",
    "    lambda row: encoder.encode_for_libffm(row), raw=True, axis=1\n",
    ")\n",
    "\n",
    "libffm_format_trn.to_csv(f'train.txt', index=False, header=False)\n",
    "libffm_format_tst.to_csv(f'test.txt', index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Подбираем гиперпараметры: регуляризацию и размерность эмбедингов."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=2, C=1e-06\n",
      "K=2, C=1e-05\n",
      "K=2, C=0.0001\n",
      "K=2, C=0.001\n",
      "K=2, C=0.01\n",
      "K=4, C=1e-06\n",
      "K=4, C=1e-05\n",
      "K=4, C=0.0001\n",
      "K=4, C=0.001\n",
      "K=4, C=0.01\n",
      "K=8, C=1e-06\n",
      "K=8, C=1e-05\n",
      "K=8, C=0.0001\n",
      "K=8, C=0.001\n",
      "K=8, C=0.01\n",
      "K=16, C=1e-06\n",
      "K=16, C=1e-05\n",
      "K=16, C=0.0001\n",
      "K=16, C=0.001\n",
      "K=16, C=0.01\n"
     ]
    }
   ],
   "source": [
    "for k in [2, 4, 8, 16]:\n",
    "    for c in [0.000001, 0.00001, 0.0001, 0.001, 0.01]:\n",
    "        ffm_model = xl.create_ffm()\n",
    "        ffm_model.setTrain(\"./train.txt\")\n",
    "        param = {'task':'binary', 'lr':0.2, 'lambda': c, 'k': k, 'metric': 'auc', 'fold': 4}\n",
    "        print(f'K={k}, C={c}')\n",
    "        ffm_model.cv(param)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сравниваем с бейзлайном: побили его и предыдущую модель."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc=0.7769001506067655, log_loss=0.14258316108167948\n",
      "roc_auc_base: 0.5, log_loss base: 0.16643236596578298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain('train.txt')\n",
    "ffm_model.setValidate('test.txt')\n",
    "param = {'task':'binary', 'lr':0.2, 'lambda':0.0001, 'k': 8, 'metric': 'auc'}\n",
    "\n",
    "ffm_model.fit(param, './model.out')\n",
    "\n",
    "ffm_model.setSigmoid()\n",
    "ffm_model.setTest('test.txt')\n",
    "ffm_model.predict('./model.out', './output.txt')\n",
    "\n",
    "with open('output.txt', 'r') as f:\n",
    "    y_pred_proba = np.array(list(map(float, filter(lambda s: len(s) > 0, f.read().split('\\n')))))\n",
    "roc_auc_metric = roc_auc_score(test_clicks, y_pred_proba)\n",
    "log_loss_metric = log_loss(test_clicks, y_pred_proba)\n",
    "print(f\"roc_auc={roc_auc_metric}, log_loss={log_loss_metric}\")\n",
    "\n",
    "y_pred_base = np.full(y_pred_proba.shape, np.mean(train_clicks))\n",
    "roc_auc_metric_base = roc_auc_score(test_clicks, y_pred_base)\n",
    "log_loss_metric_base = log_loss(test_clicks, y_pred_base)\n",
    "print(f\"roc_auc_base: {roc_auc_metric_base}, log_loss base: {log_loss_metric_base}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}