{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9pqZgUYC5wCl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SKq0BSKs6qGk"
   },
   "outputs": [],
   "source": [
    "path = 'Recsys_data1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "C3ecsUpYiImI"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YU6capgtiBE1"
   },
   "outputs": [],
   "source": [
    "def analysis(data: pd.DataFrame):\n",
    "    data = data.drop(['banner_id0', 'banner_id1', 'rate0', 'rate1', 'g0', 'g1', 'coeff_sum0',  'coeff_sum1'], axis=1) #remove unnecessary cols (according to the task)\n",
    "    print(data.head)\n",
    "    print(\"Data contains null is \", data.isnull().values.any()) #check if contains null\n",
    "    print(len(df[df['impressions'] == 0])) #check if impressions contains 0\n",
    "    #count how many data on each day we have\n",
    "    cur = data.copy()\n",
    "    cur['date_time'] = cur['date_time'].apply(lambda x: x[:10])\n",
    "    cur = cur.groupby(['date_time']).size()\n",
    "    print(cur)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIwRDUPbphz1",
    "outputId": "ab372a9c-3dec-42b6-9bcd-a4392bc48bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                            date_time  zone_id  banner_id            oaid_hash  \\\n",
      "0         2021-09-27 00:01:30.000000        0          0  5664530014561852622   \n",
      "1         2021-09-26 22:54:49.000000        1          1  5186611064559013950   \n",
      "2         2021-09-26 23:57:20.000000        2          2  2215519569292448030   \n",
      "3         2021-09-27 00:04:30.000000        3          3  6262169206735077204   \n",
      "4         2021-09-27 00:06:21.000000        4          4  4778985830203613115   \n",
      "...                              ...      ...        ...                  ...   \n",
      "15821467  2021-10-02 15:51:35.000000      146        530  4329496688011613719   \n",
      "15821468  2021-09-27 22:03:14.000000       12         22   453968700792456599   \n",
      "15821469  2021-10-02 17:41:10.000000       12       1236  9112780675655118328   \n",
      "15821470  2021-09-29 00:39:32.000000      967         21  6968514095695555037   \n",
      "15821471  2021-09-28 07:00:18.000000       19        635  8754492963501134426   \n",
      "\n",
      "          campaign_clicks  os_id  country_id  impressions  clicks  \n",
      "0                       0      0           0            1       1  \n",
      "1                       0      0           1            1       1  \n",
      "2                       3      0           0            1       1  \n",
      "3                       0      1           1            1       1  \n",
      "4                       0      1           0            1       1  \n",
      "...                   ...    ...         ...          ...     ...  \n",
      "15821467                0      2           9            1       0  \n",
      "15821468                0      1           6            1       0  \n",
      "15821469                0      2           0            1       0  \n",
      "15821470                0      0           0            1       0  \n",
      "15821471                0      0           3            1       0  \n",
      "\n",
      "[15821472 rows x 9 columns]>\n",
      "Data contains null is  False\n",
      "0\n",
      "date_time\n",
      "2021-09-01          1\n",
      "2021-09-26    3102610\n",
      "2021-09-27    2367303\n",
      "2021-09-28    2307355\n",
      "2021-09-29    2420588\n",
      "2021-09-30    1851189\n",
      "2021-10-01    1643448\n",
      "2021-10-02    2128978\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pO2H2rnno3wh"
   },
   "source": [
    "Выводы из анализа данных:\n",
    "\n",
    "1. В данных нет null.\n",
    "2. Все impressions равны 1 (что логично), так что уберем этот столбец.\n",
    "3. Столбец campaign_clicks содержит какие-то странные данные, непонятно, что они нам дают. Как будто бы мы не можем сделать никакой вывод, зная только о том, что человеку уже показывалась похожая реклама. Так что уберем его, так и данные поменьше станут.\n",
    "\n",
    "4. Также я не буду использовать дату при работе. Само число дня недели использовать точно странно, ведь их у нас мало, да и на тесте дата будет отличаться, так что ничему хорошему у модели научиться не получится. Можно было бы использовать время дня, что могло бы помочь (например, вечером люди могут быть уставшие и не кликать на рекламу или наоборот днем быть занятыми и так далее). Но этот момент может быть подвержен сезонности (например в выходные люди могут вести себя не так, как на рабочей неделе), а данных у нас опять же слишком мало, для учета таких вещей.\n",
    "\n",
    "5. Также есть день 2021-09-01, для которого есть всего одна запись и он далеко от остальных. Видимо он попал в данные случайно, его надо удалить.\n",
    "\n",
    "6. Последний день (который будем брать в тест) 2021-10-02, предпоследний 20-10-01 берем в валидационное множество.\n",
    "\n",
    "7. Остальные данные категориальные\n",
    "\n",
    "Ровно этим и будем заниматься в функции feature_engineering. \n",
    "\n",
    "\n",
    "Я пробовала пытаться как-то объединять в филды оставшиеся данные, но в итоге так и оставила для каждого параметра свой филд, потому что так было лучше.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "E73TkBzfo2k5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "#feature engineering according to the analysis and spliting into train and test\n",
    "def feature_engineering(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data = data.drop(['impressions', 'campaign_clicks'], axis=1)\n",
    "    data = data[data['date_time'] > '2021-09-20']\n",
    "    \n",
    "    cur = data[data['date_time'] < '2021-10-01']\n",
    "    x_train = cur.drop(['clicks', 'date_time'], axis=1)\n",
    "    y_train = cur['clicks']\n",
    "    \n",
    "    cur = data[(data['date_time'] < '2021-10-02') & (data['date_time'] >= '2021-10-01')] \n",
    "    x_val = cur.drop(['clicks', 'date_time'], axis=1)\n",
    "    y_val = cur['clicks']\n",
    "    \n",
    "    cur = data[data['date_time'] >= '2021-10-02']\n",
    "    x_test = cur.drop(['clicks', 'date_time'], axis=1)\n",
    "    y_test = cur['clicks']\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_zc-AyYmCcKD"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val, x_test, y_test = feature_engineering(df)\n",
    "df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Da7hJW5lS8sj"
   },
   "outputs": [],
   "source": [
    "#https://github.com/Bobe24/Dataframe2libffm/tree/3e34cb0c195242560d85753b2963ad845691e14e\n",
    "category_column = ['oaid_hash', 'banner_id', 'clicks', 'zone_id', 'os_id', 'country_id']\n",
    "\n",
    "class FFMFormat:\n",
    "    def __init__(self):\n",
    "        self.field_index_ = None\n",
    "        self.feature_index_ = None\n",
    "        self.y = None\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        self.y = y\n",
    "        df_ffm = df[df.columns.difference([self.y])]\n",
    "        if self.field_index_ is None:\n",
    "            self.field_index_ = {col: i for i, col in enumerate(df_ffm)}\n",
    "\n",
    "        if self.feature_index_ is not None:\n",
    "            last_idx = max(list(self.feature_index_.values()))\n",
    "\n",
    "        if self.feature_index_ is None:\n",
    "            self.feature_index_ = dict()\n",
    "            last_idx = 0\n",
    "\n",
    "        for col in df_ffm.columns:\n",
    "            vals = df_ffm[col].unique()\n",
    "            for val in vals:\n",
    "                if pd.isnull(val):\n",
    "                    continue\n",
    "                name = '{}_{}'.format(col, val)\n",
    "                if name not in self.feature_index_:\n",
    "                    self.feature_index_[name] = last_idx\n",
    "                    last_idx += 1\n",
    "            self.feature_index_[col] = last_idx\n",
    "            last_idx += 1\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, df, y=None):\n",
    "        self.fit(df, y)\n",
    "        return self.transform(df)\n",
    "\n",
    "    def transform_row_(self, row, t):\n",
    "        ffm = []\n",
    "        if self.y != None:\n",
    "            ffm.append(str(row.loc[row.index == self.y][0]))\n",
    "        if self.y is None:\n",
    "            ffm.append(str(0))\n",
    "\n",
    "        for col, val in row.loc[row.index != self.y].to_dict().items():\n",
    "            col_type = t[col]\n",
    "            name = '{}_{}'.format(col, val)\n",
    "            # if col_type.kind == 'O':\n",
    "            if col in category_column:\n",
    "                ffm.append('{}:{}:1'.format(self.field_index_[col],\n",
    "                                            self.feature_index_[name]))\n",
    "            else:\n",
    "            # elif col_type.kind == 'i':\n",
    "                ffm.append('{}:{}:{}'.format(self.field_index_[col],\n",
    "                                             self.feature_index_[col], val))\n",
    "        return ' '.join(ffm)\n",
    "\n",
    "    def transform(self, df):\n",
    "        t = df.dtypes.to_dict()\n",
    "        return pd.Series(\n",
    "            {idx: self.transform_row_(row, t) for idx, row in df.iterrows()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем данные в libffm формат с помощью алогритма выше. Почему-то при записи результата в csv файл пишется лишний первый 0. Чтобы дальше использовать файлы в модели, нужно удалить ноль руками из файла, иначе модель упадет\n",
    ":("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "HXQ4hR6HYxSS",
    "outputId": "e0866140-f68b-4c9c-c8e3-808eb39a37b3"
   },
   "outputs": [],
   "source": [
    "train_df = x_train\n",
    "train_df['clicks'] = y_train\n",
    "\n",
    "val_df = x_val\n",
    "val_df['clicks'] = y_val\n",
    "\n",
    "test_df = x_test\n",
    "test_df['clicks'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Fi2BDXOkXj7x"
   },
   "outputs": [],
   "source": [
    "ffm_encoder = FFMFormat()\n",
    "ffm_train_data = ffm_encoder.fit_transform(train_df, y='clicks')\n",
    "ffm_train_data.to_csv('train_ffm.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "hFYvCs4oYJiJ",
    "outputId": "7fa89602-7bcf-4df2-bfda-84ba03829a2b"
   },
   "outputs": [],
   "source": [
    "ffm_val_data = ffm_encoder.fit_transform(val_df, y='clicks')\n",
    "ffm_val_data.to_csv('val_ffm.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перейдем к самой модели. Для работы я выбрала библиотеку xlearn, потому что она достаточно удобная и быстрее альтернатив, которые я видела."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nKaXkHtowf9",
    "outputId": "142ae999-076e-4f19-d23c-54398421b95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlearn in /Users/bagryanova/opt/anaconda3/lib/python3.9/site-packages (0.40a1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlearn as xl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим модель с разными параметрами. Я еще запускала с другими lr, с ними результат был гораздо хуже. Так что в целях экономии времени запуска не добавила сюда эти эксперименты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 30, 'k': 4, 'lambda': 0.1, 'lr': 0.1, 'metric': 'auc', 'task': 'binary'}\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 11.22 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 907.69 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.87 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.108102            0.175736            0.758440                3.82\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.107185            0.175578            0.763409                3.72\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.106555            0.175581            0.768903                3.72\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.105965            0.175058            0.768663                3.73\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.105504            0.174904            0.768853                3.69\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.105091            0.174856            0.770546                3.19\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.104740            0.174457            0.768834                3.88\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.104419            0.174895            0.770660                3.74\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.104036            0.174369            0.771335                3.44\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.103855            0.174389            0.772509                3.77\n",
      "\u001b[32m[ \u001b[0m  36%\u001b[32m      ]\u001b[0m    11            0.103550            0.174409            0.770870                3.81\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m    12            0.103180            0.173961            0.773439                3.74\n",
      "\u001b[32m[ \u001b[0m  43%\u001b[32m      ]\u001b[0m    13            0.103048            0.174479            0.771295                3.75\n",
      "\u001b[32m[ \u001b[0m  46%\u001b[32m      ]\u001b[0m    14            0.102900            0.174197            0.772034                3.78\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m    15            0.102623            0.173950            0.772761                3.76\n",
      "\u001b[32m[ \u001b[0m  53%\u001b[32m      ]\u001b[0m    16            0.102323            0.173667            0.771122                3.77\n",
      "\u001b[32m[ \u001b[0m  56%\u001b[32m      ]\u001b[0m    17            0.102008            0.173395            0.771234                3.62\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m    18            0.101913            0.173821            0.771988                3.77\n",
      "\u001b[32m[ \u001b[0m  63%\u001b[32m      ]\u001b[0m    19            0.101989            0.174292            0.770791                3.80\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m    20            0.101786            0.174275            0.771357                3.20\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m    21            0.101540            0.173808            0.771967                3.79\n",
      "\u001b[32m[ \u001b[0m  73%\u001b[32m      ]\u001b[0m    22            0.101310            0.173647            0.773729                3.73\n",
      "\u001b[32m[ \u001b[0m  76%\u001b[32m      ]\u001b[0m    23            0.101077            0.173360            0.772044                3.23\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m    24            0.100837            0.173103            0.773156                3.81\n",
      "\u001b[32m[ \u001b[0m  83%\u001b[32m      ]\u001b[0m    25            0.100576            0.172845            0.771958                3.70\n",
      "\u001b[32m[ \u001b[0m  86%\u001b[32m      ]\u001b[0m    26            0.100448            0.172867            0.772125                3.77\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m    27            0.100370            0.173130            0.769935                3.73\n",
      "\u001b[32m[ \u001b[0m  93%\u001b[32m      ]\u001b[0m    28            0.100521            0.173850            0.773166                3.71\n",
      "\u001b[32m[ \u001b[0m  96%\u001b[32m      ]\u001b[0m    29            0.100552            0.174448            0.771189                3.77\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    30            0.100393            0.174130            0.771478                3.78\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 22, best AUC: 0.773729\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.33 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "{'epoch': 30, 'k': 4, 'lambda': 0.002, 'lr': 0.1, 'metric': 'auc', 'task': 'binary'}\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 125.89 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 10.57 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 907.69 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.82 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.100821            0.157951            0.778936                3.56\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.099083            0.157069            0.781530                3.74\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.097970            0.156042            0.783846                3.77\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.096969            0.155651            0.785963                3.74\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.096011            0.155333            0.787366                3.63\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.095114            0.154951            0.789032                3.42\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.094212            0.154431            0.790618                3.74\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.093327            0.154007            0.791917                3.61\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.092481            0.153666            0.793138                3.07\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.091648            0.153476            0.794431                3.72\n",
      "\u001b[32m[ \u001b[0m  36%\u001b[32m      ]\u001b[0m    11            0.090832            0.153130            0.795288                3.74\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m    12            0.090035            0.152891            0.796313                3.51\n",
      "\u001b[32m[ \u001b[0m  43%\u001b[32m      ]\u001b[0m    13            0.089259            0.152751            0.797192                3.60\n",
      "\u001b[32m[ \u001b[0m  46%\u001b[32m      ]\u001b[0m    14            0.088500            0.152265            0.798282                3.78\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m    15            0.087767            0.152131            0.798981                3.77\n",
      "\u001b[32m[ \u001b[0m  53%\u001b[32m      ]\u001b[0m    16            0.087048            0.151930            0.799721                3.75\n",
      "\u001b[32m[ \u001b[0m  56%\u001b[32m      ]\u001b[0m    17            0.086358            0.151886            0.800392                3.74\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m    18            0.085693            0.151639            0.801055                3.72\n",
      "\u001b[32m[ \u001b[0m  63%\u001b[32m      ]\u001b[0m    19            0.085048            0.151643            0.801479                3.72\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m    20            0.084408            0.151692            0.801851                3.25\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m    21            0.083799            0.151367            0.802455                3.65\n",
      "\u001b[32m[ \u001b[0m  73%\u001b[32m      ]\u001b[0m    22            0.083196            0.151380            0.802799                3.74\n",
      "\u001b[32m[ \u001b[0m  76%\u001b[32m      ]\u001b[0m    23            0.082605            0.151370            0.803305                3.04\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m    24            0.082030            0.151344            0.803605                3.70\n",
      "\u001b[32m[ \u001b[0m  83%\u001b[32m      ]\u001b[0m    25            0.081465            0.151186            0.804070                3.71\n",
      "\u001b[32m[ \u001b[0m  86%\u001b[32m      ]\u001b[0m    26            0.080921            0.151144            0.804145                3.33\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m    27            0.080373            0.151092            0.804560                3.73\n",
      "\u001b[32m[ \u001b[0m  93%\u001b[32m      ]\u001b[0m    28            0.079857            0.150941            0.804872                3.72\n",
      "\u001b[32m[ \u001b[0m  96%\u001b[32m      ]\u001b[0m    29            0.079330            0.151041            0.804894                3.74\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    30            0.078813            0.151076            0.804857                3.74\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 29, best AUC: 0.804894\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.34 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "{'epoch': 30, 'k': 4, 'lambda': 0.0002, 'lr': 0.1, 'metric': 'auc', 'task': 'binary'}\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 125.42 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 10.70 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 907.69 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.83 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.098324            0.150152            0.799709                3.61\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.094992            0.148063            0.805779                3.71\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.091974            0.146808            0.810954                3.74\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.088956            0.145584            0.814823                3.75\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.085798            0.144431            0.818299                3.79\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.082501            0.143859            0.820171                3.32\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.079142            0.143391            0.821651                3.73\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.075743            0.143545            0.822053                3.74\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.072373            0.143830            0.821919                3.27\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.069052            0.144175            0.821145                3.70\n",
      "\u001b[32m[ \u001b[0m  36%\u001b[32m      ]\u001b[0m    11            0.065833            0.145182            0.819620                3.61\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 8, best AUC: 0.822053\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.08 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "{'epoch': 30, 'k': 8, 'lambda': 0.1, 'lr': 0.1, 'metric': 'auc', 'task': 'binary'}\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 55.19 (sec)\u001b[0m\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 10.37 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.73 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.99 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.108147            0.175697            0.759801                4.45\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.107167            0.175468            0.764607                3.74\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.106485            0.175295            0.762966                4.24\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.106010            0.175696            0.767717                3.60\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.105565            0.175005            0.771387                4.05\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.105115            0.174731            0.770387                3.92\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.104701            0.174652            0.770377                3.95\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.104423            0.174505            0.770737                4.28\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.104019            0.174463            0.771208                3.70\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.103873            0.174390            0.772646                3.56\n",
      "\u001b[32m[ \u001b[0m  36%\u001b[32m      ]\u001b[0m    11            0.103489            0.173950            0.772319                4.24\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m    12            0.103193            0.174244            0.772574                4.21\n",
      "\u001b[32m[ \u001b[0m  43%\u001b[32m      ]\u001b[0m    13            0.103154            0.174447            0.771692                4.36\n",
      "\u001b[32m[ \u001b[0m  46%\u001b[32m      ]\u001b[0m    14            0.102779            0.173883            0.770437                3.12\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m    15            0.102461            0.173755            0.771570                3.06\n",
      "\u001b[32m[ \u001b[0m  53%\u001b[32m      ]\u001b[0m    16            0.102157            0.173642            0.771260                2.99\n",
      "\u001b[32m[ \u001b[0m  56%\u001b[32m      ]\u001b[0m    17            0.102163            0.174350            0.770984                3.48\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m    18            0.102146            0.174449            0.773757                4.06\n",
      "\u001b[32m[ \u001b[0m  63%\u001b[32m      ]\u001b[0m    19            0.101940            0.174158            0.772804                4.06\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m    20            0.101679            0.173729            0.771026                4.02\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m    21            0.101410            0.173646            0.772088                3.64\n",
      "\u001b[32m[ \u001b[0m  73%\u001b[32m      ]\u001b[0m    22            0.101125            0.173189            0.771327                4.26\n",
      "\u001b[32m[ \u001b[0m  76%\u001b[32m      ]\u001b[0m    23            0.100902            0.173057            0.772268                4.28\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m    24            0.100699            0.173136            0.772224                4.24\n",
      "\u001b[32m[ \u001b[0m  83%\u001b[32m      ]\u001b[0m    25            0.100611            0.172973            0.770429                4.35\n",
      "\u001b[32m[ \u001b[0m  86%\u001b[32m      ]\u001b[0m    26            0.100793            0.173887            0.770580                3.84\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m    27            0.100802            0.174363            0.771619                4.19\n",
      "\u001b[32m[ \u001b[0m  93%\u001b[32m      ]\u001b[0m    28            0.100632            0.174185            0.771928                4.39\n",
      "\u001b[32m[ \u001b[0m  96%\u001b[32m      ]\u001b[0m    29            0.100440            0.173973            0.771173                4.20\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    30            0.100282            0.173737            0.771398                4.21\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 18, best AUC: 0.773757\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.54 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 136.36 (sec)\u001b[0m\n",
      "{'epoch': 30, 'k': 8, 'lambda': 0.002, 'lr': 0.1, 'metric': 'auc', 'task': 'binary'}\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 10.22 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.73 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.52 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.100788            0.157668            0.779777                4.53\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.099067            0.156879            0.782002                4.14\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.097916            0.156520            0.783826                4.74\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.096878            0.155736            0.786314                4.40\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.095909            0.155228            0.788085                4.61\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.094960            0.154684            0.789856                4.20\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.094023            0.154162            0.791424                4.42\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.093121            0.153909            0.792086                4.37\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.092247            0.153540            0.793687                4.24\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.091378            0.153370            0.794844                4.00\n",
      "\u001b[32m[ \u001b[0m  36%\u001b[32m      ]\u001b[0m    11            0.090525            0.153051            0.796229                4.31\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m    12            0.089712            0.152628            0.797098                4.24\n",
      "\u001b[32m[ \u001b[0m  43%\u001b[32m      ]\u001b[0m    13            0.088885            0.152521            0.798403                4.16\n",
      "\u001b[32m[ \u001b[0m  46%\u001b[32m      ]\u001b[0m    14            0.088101            0.152409            0.798709                4.21\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m    15            0.087339            0.152137            0.799396                4.22\n",
      "\u001b[32m[ \u001b[0m  53%\u001b[32m      ]\u001b[0m    16            0.086592            0.152013            0.800431                3.59\n",
      "\u001b[32m[ \u001b[0m  56%\u001b[32m      ]\u001b[0m    17            0.085872            0.151799            0.801099                4.30\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m    18            0.085177            0.151856            0.801871                4.25\n",
      "\u001b[32m[ \u001b[0m  63%\u001b[32m      ]\u001b[0m    19            0.084504            0.151674            0.802339                4.33\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m    20            0.083845            0.151430            0.802948                4.35\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m    21            0.083204            0.151496            0.803118                4.28\n",
      "\u001b[32m[ \u001b[0m  73%\u001b[32m      ]\u001b[0m    22            0.082564            0.151526            0.803675                4.36\n",
      "\u001b[32m[ \u001b[0m  76%\u001b[32m      ]\u001b[0m    23            0.081948            0.151299            0.804295                3.65\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m    24            0.081347            0.151280            0.804486                4.22\n",
      "\u001b[32m[ \u001b[0m  83%\u001b[32m      ]\u001b[0m    25            0.080761            0.151244            0.804728                4.30\n",
      "\u001b[32m[ \u001b[0m  86%\u001b[32m      ]\u001b[0m    26            0.080192            0.151139            0.805133                4.28\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m    27            0.079620            0.151272            0.805320                4.26\n",
      "\u001b[32m[ \u001b[0m  93%\u001b[32m      ]\u001b[0m    28            0.079070            0.151193            0.805483                4.30\n",
      "\u001b[32m[ \u001b[0m  96%\u001b[32m      ]\u001b[0m    29            0.078534            0.151250            0.805490                4.25\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    30            0.077991            0.151096            0.805706                4.16\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.85 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "{'epoch': 30, 'k': 8, 'lambda': 0.0002, 'lr': 0.1, 'metric': 'auc', 'task': 'binary'}\u001b[32m\u001b[1m[------------] Total time cost: 151.20 (sec)\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 9.93 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.73 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.098133            0.150050            0.800035                4.34\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.094470            0.147878            0.807486                4.26\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.091154            0.146520            0.812641                4.28\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.087858            0.145040            0.816684                4.28\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.084379            0.144253            0.820119                4.29\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.080807            0.143581            0.822062                3.86\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.077169            0.143332            0.823336                4.27\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.073532            0.143605            0.823291                4.24\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.069912            0.144457            0.822701                4.53\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.066363            0.145189            0.821698                4.17\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 7, best AUC: 0.823336\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.60 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 60.12 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "params_grid = {\n",
    "    'task': ['binary'],\n",
    "    'lr': [0.1],\n",
    "    'lambda':[0.1, 0.002, 0.0002],\n",
    "    'k': [4, 8], \n",
    "    'metric': ['auc'], \n",
    "    'epoch': [30]\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(params_grid):\n",
    "    print(params)\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setTrain(\"train_ffm.txt\")\n",
    "    ffm_model.setValidate(\"val_ffm.txt\")\n",
    "    ffm_model.fit(params, \"model.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что $k=8$ немного обыгрывает $k=4$. А еще что лучший результат достигается на граничном значении $lambda = 0.0002$. Попробуем еще уменьшить его, вдруг станет лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 30, 'k': 8, 'lambda': 0.0002, 'lr': 0.1, 'metric': 'auc', 'task': 'binary'}\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 10.97 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.73 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.46 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.098140            0.149646            0.800446                4.04\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.094469            0.147637            0.808054                4.18\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.091175            0.146442            0.812692                4.23\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.087858            0.145045            0.816961                4.30\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.084394            0.144029            0.819844                4.18\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.080825            0.143457            0.822098                4.22\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.077231            0.143437            0.823152                4.25\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.073613            0.143665            0.823385                3.47\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.070037            0.144241            0.822750                2.85\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.066522            0.145188            0.821553                3.10\n",
      "\u001b[32m[ \u001b[0m  36%\u001b[32m      ]\u001b[0m    11            0.063125            0.145993            0.820152                4.03\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 8, best AUC: 0.823385\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.53 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "{'epoch': 30, 'k': 8, 'lambda': 2e-05, 'lr': 0.1, 'metric': 'auc', 'task': 'binary'}\u001b[32m\u001b[1m[------------] Total time cost: 60.96 (sec)\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 10.33 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.73 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.47 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.097261            0.147457            0.805885                4.20\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.089931            0.143106            0.819805                4.25\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.078918            0.143000            0.820988                4.27\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.065836            0.146978            0.814206                4.16\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.054136            0.152675            0.806149                4.22\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.046092            0.158642            0.800322                4.17\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 3, best AUC: 0.820988\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 3.42 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "{'epoch': 30, 'k': 8, 'lambda': 2e-06, 'lr': 0.1, 'metric': 'auc', 'task': 'binary'}\u001b[32m\u001b[1m[------------] Total time cost: 42.80 (sec)\u001b[0m\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 10.44 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.73 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.74 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.097070            0.147089            0.806885                4.45\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.087993            0.142436            0.820468                4.35\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.073098            0.146044            0.813691                4.17\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.057024            0.154709            0.801606                4.40\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.045781            0.164364            0.791907                4.47\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 2, best AUC: 0.820468\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 3.33 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m[------------] Total time cost: 39.57 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "params_grid = {\n",
    "    'task': ['binary'],\n",
    "    'lr': [0.1],\n",
    "    'lambda':[0.0002, 0.00002, 0.000002],\n",
    "    'k': [8], \n",
    "    'metric': ['auc'], \n",
    "    'epoch': [30]\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(params_grid):\n",
    "    print(params)\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setTrain(\"train_ffm.txt\")\n",
    "    ffm_model.setValidate(\"val_ffm.txt\")\n",
    "    ffm_model.fit(params, \"model.out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь заметной разницы между результатами нет. Выберем уже знакомый нам с $lambda=0.0002$ - он немного лучше по auc, но немного проигрывает по log_loss. И теперь запустим лучшую модель на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "SwCYFpupV2or"
   },
   "outputs": [],
   "source": [
    "ffm_test_data = ffm_encoder.fit_transform(test_df, y='clicks')\n",
    "ffm_test_data.to_csv('test_ffm.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"train_ffm.txt\")\n",
    "params = {\n",
    "    'task': 'binary',\n",
    "    'lr': 0.1,\n",
    "    'lambda':0.0002,\n",
    "    'k':8, \n",
    "    'metric':'auc', \n",
    "    'epoch':30\n",
    "}\n",
    "ffm_model.setValidate(\"val_ffm.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 12.30 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.73 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.94 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m   3%\u001b[32m      ]\u001b[0m     1            0.098126            0.149796            0.800911                4.58\n",
      "\u001b[32m[ \u001b[0m   6%\u001b[32m      ]\u001b[0m     2            0.094418            0.147668            0.807830                4.19\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     3            0.091129            0.146341            0.812898                4.08\n",
      "\u001b[32m[ \u001b[0m  13%\u001b[32m      ]\u001b[0m     4            0.087823            0.144787            0.817264                4.23\n",
      "\u001b[32m[ \u001b[0m  16%\u001b[32m      ]\u001b[0m     5            0.084333            0.144156            0.820055                4.37\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     6            0.080760            0.143438            0.822099                9.16\n",
      "\u001b[32m[ \u001b[0m  23%\u001b[32m      ]\u001b[0m     7            0.077175            0.143187            0.823300               10.73\n",
      "\u001b[32m[ \u001b[0m  26%\u001b[32m      ]\u001b[0m     8            0.073592            0.143667            0.823251                7.33\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     9            0.070036            0.144543            0.822665                4.38\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m    10            0.066573            0.145159            0.821535                4.18\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 7, best AUC: 0.823300\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: model.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.71 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 81.26 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ffm_model.fit(params, \"model.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 12 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from model.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 5665369\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 8\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 5\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 1.10 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.94 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.136277\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.91 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ffm_model.setTest('test_ffm.txt')\n",
    "ffm_model.setSigmoid()\n",
    "ffm_model.predict(\"model.out\", \"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y_pred = pd.read_csv('output.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auc: 0.791, log_loss: 0.136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "auc_metric = roc_auc_score(y_test, y_pred)\n",
    "log_loss_metric = log_loss(y_test, y_pred)\n",
    "print('Auc: {:.3f}, log_loss: {:.3f}'.format(auc_metric, log_loss_metric))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В линейной модели у меня получились метрики auc: 0.779, log_loss: 0.134.\n",
    "Получается, что ffm немного выиграла по auc, но совсем чуть-чуть проиграла по лоссу. Так как я выбрала модель с оптимальным auc, может, если бы мы взяли лямбду еще меньше (то есть выбрали оптимальную по лоссу), то не проиграли бы по лоссу. Ну или это просто случайность:)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
