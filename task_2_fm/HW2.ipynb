{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "id": "tX6_Eyt-vJ8B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/data.csv')"
   ],
   "metadata": {
    "id": "CSPgajZ6vJ8J"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Анализ"
   ],
   "metadata": {
    "collapsed": false,
    "id": "H5WYUkxSvJ8K"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Анализ остается в точности тем же самым, что и в первом домашнем задании. Сначала удалим ненужные столбцы"
   ],
   "metadata": {
    "collapsed": false,
    "id": "9TgZkCtOvJ8N"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                    date_time  zone_id  banner_id            oaid_hash  \\\n0  2021-09-27 00:01:30.000000        0          0  5664530014561852622   \n1  2021-09-26 22:54:49.000000        1          1  5186611064559013950   \n2  2021-09-26 23:57:20.000000        2          2  2215519569292448030   \n3  2021-09-27 00:04:30.000000        3          3  6262169206735077204   \n4  2021-09-27 00:06:21.000000        4          4  4778985830203613115   \n\n   campaign_clicks  os_id  country_id  impressions  clicks  \n0                0      0           0            1       1  \n1                0      0           1            1       1  \n2                3      0           0            1       1  \n3                0      1           1            1       1  \n4                0      1           0            1       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>zone_id</th>\n      <th>banner_id</th>\n      <th>oaid_hash</th>\n      <th>campaign_clicks</th>\n      <th>os_id</th>\n      <th>country_id</th>\n      <th>impressions</th>\n      <th>clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-09-27 00:01:30.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5664530014561852622</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-09-26 22:54:49.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5186611064559013950</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-09-26 23:57:20.000000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2215519569292448030</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-09-27 00:04:30.000000</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6262169206735077204</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-09-27 00:06:21.000000</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4778985830203613115</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = [\"banner_id0\", \"banner_id1\", \"rate0\", \"rate1\", \"g0\", \"g1\", \"coeff_sum0\", \"coeff_sum1\"]\n",
    "data = data.drop(to_drop, axis=1)\n",
    "data.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qgNgptn0vJ8O",
    "outputId": "757ffc02-d4d9-43a5-fbf3-d665eef9ea6f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Посмотрим на столбец impressions, пока кажется, что он не несет информации."
   ],
   "metadata": {
    "collapsed": false,
    "id": "S96E6rFxvJ8R"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "             date_time   zone_id  banner_id  oaid_hash  campaign_clicks  \\\nimpressions                                                               \n1             15821472  15821472   15821472   15821472         15821472   \n\n                os_id  country_id    clicks  \nimpressions                                  \n1            15821472    15821472  15821472  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>zone_id</th>\n      <th>banner_id</th>\n      <th>oaid_hash</th>\n      <th>campaign_clicks</th>\n      <th>os_id</th>\n      <th>country_id</th>\n      <th>clicks</th>\n    </tr>\n    <tr>\n      <th>impressions</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>15821472</td>\n      <td>15821472</td>\n      <td>15821472</td>\n      <td>15821472</td>\n      <td>15821472</td>\n      <td>15821472</td>\n      <td>15821472</td>\n      <td>15821472</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"impressions\").count()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "K4QQDqkDvJ8S",
    "outputId": "3ce8524b-a172-4b84-e2b0-858eaf1c17c4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data = data.drop(\"impressions\", axis=1)"
   ],
   "metadata": {
    "id": "3KotQ3KFvJ8V"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверим, есть ли None:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "R8aE_RxGvJ8W"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "date_time  zone_id  banner_id  oaid_hash  campaign_clicks  os_id  country_id  clicks\nFalse      False    False      False      False            False  False       False     15821472\ndtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ded0r6bKvJ8Y",
    "outputId": "94f8b40f-f4b0-46b3-bcff-048c126ed9dd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Таких значений нет, чистить датасет не нужно. Посмотрим на статистику по дням"
   ],
   "metadata": {
    "collapsed": false,
    "id": "tsNADWCKvJ8a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "2021-09-26    3102610\n2021-09-29    2420588\n2021-09-27    2367303\n2021-09-28    2307355\n2021-10-02    2128978\n2021-09-30    1851189\n2021-10-01    1643448\n2021-09-01          1\nName: date, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"date_time\"] = pd.to_datetime(data[\"date_time\"])\n",
    "data['date'] = data.date_time.dt.date\n",
    "data.date.value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iEIgXu6vJ8b",
    "outputId": "cddb5e6a-9c16-47df-de2c-c738e632bb16"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "По одному из дней только одна запись, выбросим его."
   ],
   "metadata": {
    "collapsed": false,
    "id": "0Eotx_r2vJ8c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8343/2394282383.py:2: FutureWarning: Index.asi8 is deprecated and will be removed in a future version.\n",
      "  data = data.drop(data[data[\"date\"] == datetime.date(2021, 9, 1)].index.asi8)\n"
     ]
    },
    {
     "data": {
      "text/plain": "2021-09-26    3102610\n2021-09-29    2420588\n2021-09-27    2367303\n2021-09-28    2307355\n2021-10-02    2128978\n2021-09-30    1851189\n2021-10-01    1643448\nName: date, dtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "data = data.drop(data[data[\"date\"] == datetime.date(2021, 9, 1)].index.asi8)\n",
    "data = data.sort_values(by='date')\n",
    "data.date.value_counts()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqMEV6DUvJ8d",
    "outputId": "86f8f404-a10f-400f-8d27-b4f640e551f8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Из данной в README информации можно сделать вывод, что все фичи, кроме campaign_click, категориальные. К ним в последствии применим One Hot encoding. Посмотрим ближе на величину campaign cliсks - насколько велики значения, какое распределение"
   ],
   "metadata": {
    "collapsed": false,
    "id": "uWPTiSH3vJ8e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "829"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.campaign_clicks.max()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CyItPNa9vJ8e",
    "outputId": "e747a23c-9958-42a4-a756-c054683473ac"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data.campaign_clicks.value_counts().plot(figsize=(12, 8), xlabel=\"number of clicks\", xticks=np.arange(0, 900, 100))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "gtu380YV7EcJ",
    "outputId": "1373e188-895c-43fb-e7da-655526bc8a51"
   },
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:xlabel='number of clicks'>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видим, что распределение перекошено. Было бы хорошо придумать такое преобразование, которое бы \"растянуло\" распределение, то есть область маленьких величин сделало пошире, а больших сгладило. В таких случаях обычно используют логарифм."
   ],
   "metadata": {
    "id": "9BsGS5oF7dih"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Преобразование данных и обучение модели."
   ],
   "metadata": {
    "collapsed": false,
    "id": "Ke78rH4RvJ8f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для дальнейших экспериментов используем библиотеку [xlearn](https://xlearn-doc.readthedocs.io/en/latest/python_api/index.html#choose-machine-learning-algorithm). Чтобы воспользоваться ею, данные нужно перевести в определенный формат (libfmm), поэтому дальше нам не будет нужен OneHotEncoding\n",
    "\n",
    "В отличие от первого домашнего задания, здесь нужны будут данные для валидации. Для этого выделим предпоследний день."
   ],
   "metadata": {
    "collapsed": false,
    "id": "gbtZqYEgvJ8g"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "def feature_engineering(data: pd.DataFrame):\n",
    "\n",
    "    data[\"campaign_clicks\"] = np.log(data['campaign_clicks']+1e-4)\n",
    "\n",
    "    train = data[data[\"date\"] < datetime.date(2021, 10, 1)]\n",
    "    val = data[data[\"date\"] == datetime.date(2021, 10, 1)]\n",
    "    test = data[data[\"date\"] == datetime.date(2021, 10, 2)]\n",
    "\n",
    "    train = train.drop([\"date\", \"date_time\"], axis=1)\n",
    "    val = val.drop([\"date\", \"date_time\"], axis=1)\n",
    "    test = test.drop([\"date\", \"date_time\"], axis=1)\n",
    "\n",
    "    return train, val, test"
   ],
   "metadata": {
    "id": "ASPgsAsOvJ8g"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train, val, test = feature_engineering(data)"
   ],
   "metadata": {
    "id": "kRhWE3L9vJ8i"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "          zone_id  banner_id            oaid_hash  campaign_clicks  os_id  \\\n3398262       302        403  6294099772840197869         -9.21034      2   \n12412212       38        753  7246070537034303857         -9.21034      4   \n5092342         3       1237  7290717137500041108         -9.21034      4   \n2526141        20        140  5119833759207605654         -9.21034      2   \n12412207       54         36  7860369112178585780         -9.21034      1   \n\n          country_id  clicks  \n3398262            6       0  \n12412212           0       0  \n5092342            0       0  \n2526141            0       0  \n12412207           0       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>zone_id</th>\n      <th>banner_id</th>\n      <th>oaid_hash</th>\n      <th>campaign_clicks</th>\n      <th>os_id</th>\n      <th>country_id</th>\n      <th>clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3398262</th>\n      <td>302</td>\n      <td>403</td>\n      <td>6294099772840197869</td>\n      <td>-9.21034</td>\n      <td>2</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12412212</th>\n      <td>38</td>\n      <td>753</td>\n      <td>7246070537034303857</td>\n      <td>-9.21034</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5092342</th>\n      <td>3</td>\n      <td>1237</td>\n      <td>7290717137500041108</td>\n      <td>-9.21034</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2526141</th>\n      <td>20</td>\n      <td>140</td>\n      <td>5119833759207605654</td>\n      <td>-9.21034</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12412207</th>\n      <td>54</td>\n      <td>36</td>\n      <td>7860369112178585780</td>\n      <td>-9.21034</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для того чтобы перевести наши данные в нужный формат, воспользуемся функцией из следующего источника ([статья](https://wngaw.github.io/field-aware-factorization-machines-with-xlearn/)): https://github.com/wngaw/blog/blob/master/xlearn_example/src/utils.py"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def _convert_to_ffm(path, df, type, target, numerics, categories, features, encoder):\n",
    "    # Flagging categorical and numerical fields\n",
    "    print('convert_to_ffm - START')\n",
    "    for x in numerics:\n",
    "        if(x not in encoder['catdict']):\n",
    "            encoder['catdict'][x] = 0\n",
    "    for x in categories:\n",
    "        if(x not in encoder['catdict']):\n",
    "            encoder['catdict'][x] = 1\n",
    "\n",
    "    nrows = df.shape[0]\n",
    "    with open(path + str(type) + \"_ffm.txt\", \"w\") as text_file:\n",
    "\n",
    "        # Looping over rows to convert each row to libffm format\n",
    "        for n, r in enumerate(tqdm(range(nrows))):\n",
    "            datastring = \"\"\n",
    "            datarow = df.iloc[r].to_dict()\n",
    "            datastring += str(int(datarow[target]))  # Set Target Variable here\n",
    "\n",
    "            # For numerical fields, we are creating a dummy field here\n",
    "            for i, x in enumerate(encoder['catdict'].keys()):\n",
    "                if(encoder['catdict'][x] == 0):\n",
    "                    # Not adding numerical values that are nan\n",
    "                    if math.isnan(datarow[x]) is not True:\n",
    "                        datastring = datastring + \" \"+str(i)+\":\" + str(i)+\":\" + str(datarow[x])\n",
    "                else:\n",
    "\n",
    "                    # For a new field appearing in a training example\n",
    "                    if(x not in encoder['catcodes']):\n",
    "                        encoder['catcodes'][x] = {}\n",
    "                        encoder['currentcode'] += 1\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    # For already encoded fields\n",
    "                    elif(datarow[x] not in encoder['catcodes'][x]):\n",
    "                        encoder['currentcode'] += 1\n",
    "                        encoder['catcodes'][x][datarow[x]] = encoder['currentcode']  # encoding the feature\n",
    "\n",
    "                    code = encoder['catcodes'][x][datarow[x]]\n",
    "                    datastring = datastring + \" \"+str(i)+\":\" + str(int(code))+\":1\"\n",
    "\n",
    "            datastring += '\\n'\n",
    "            text_file.write(datastring)\n",
    "\n",
    "    return encoder"
   ],
   "metadata": {
    "id": "RMMvjhu1ZRIS"
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разделим фичи на числовые и категориальные"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "num_features = [\"campaign_clicks\"]\n",
    "cat_features = [\"zone_id\", \"banner_id\", \"oaid_hash\", \"os_id\", \"country_id\"]\n",
    "features = num_features+cat_features\n",
    "train.columns"
   ],
   "metadata": {
    "id": "W9a64Sf0SE33"
   },
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['zone_id', 'banner_id', 'oaid_hash', 'campaign_clicks', 'os_id',\n       'country_id', 'clicks'],\n      dtype='object')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сохраним преобразованные данные в отдельных файлах."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialise fields and variables encoder\n",
    "encoder = {\"currentcode\": len(num_features),  # Unique index for each numerical field or categorical variables\n",
    "           \"catdict\": {},  # Dictionary that stores numerical and categorical variables\n",
    "           \"catcodes\": {}}  # Dictionary that stores index for each categorical variables per categorical field"
   ],
   "metadata": {
    "id": "7ZgjN8FHUYa6"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "encoder = _convert_to_ffm('./data/', train, 'train1', 'clicks',\n",
    "                          num_features,\n",
    "                          cat_features,\n",
    "                          features,\n",
    "                          encoder)\"\"\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3EvVZZYEVH-m",
    "outputId": "36100f48-2977-4b4a-c079-34ba7f689260"
   },
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nencoder = _convert_to_ffm('./data/', train, 'train1', 'clicks',\\n                          num_features,\\n                          cat_features,\\n                          features,\\n                          encoder)\""
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nencoder = _convert_to_ffm('./data/', val, 'val1', 'clicks',\\n                          num_features,\\n                          cat_features,\\n                          features,\\n                          encoder)\\n                          \""
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "encoder = _convert_to_ffm('./data/', val, 'val1', 'clicks',\n",
    "                          num_features,\n",
    "                          cat_features,\n",
    "                          features,\n",
    "                          encoder)\n",
    "                          \"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"encoder = _convert_to_ffm('./data/', test, 'test1', 'clicks',\n",
    "                          num_features,\n",
    "                          cat_features,\n",
    "                          features,\n",
    "                          encoder)\"\"\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDg7JBLIV0HV",
    "outputId": "3898424e-8494-4e6f-a55c-ff78b5210490"
   },
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "\"encoder = _convert_to_ffm('./data/', test, 'test1', 'clicks',\\n                          num_features,\\n                          cat_features,\\n                          features,\\n                          encoder)\""
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обучим модель: будем менять параметры k и lambda."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import xlearn as xl\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "params = {\n",
    "    'task': ['binary'],\n",
    "    'lr': [0.15],\n",
    "    'lambda':[1e-2, 1e-3, 5e-4, 1e-4],\n",
    "    'k': [4],\n",
    "    'metric': ['auc'],\n",
    "    'epoch': [35],\n",
    "    'opt': ['adagrad']\n",
    "}"
   ],
   "metadata": {
    "id": "xGCzHjuBXonU"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 35, 'k': 4, 'lambda': 0.01, 'lr': 0.15, 'metric': 'auc', 'opt': 'adagrad', 'task': 'binary'}\n",
      "\u001B[32m\u001B[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001B[39m\u001B[0m\u001B[32m[------------] \u001B[0mxLearn uses 8 threads for training task.\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Read Problem ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/train1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/val1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mNumber of Feature: 5665363\n",
      "\u001B[32m[------------] \u001B[0mNumber of Field: 6\n",
      "\u001B[32m[------------] \u001B[0mTime cost for reading problem: 8.02 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Initialize model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel size: 1.06 GB\n",
      "\u001B[32m[------------] \u001B[0mTime cost for model initial: 11.34 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to train ...\u001B[0m\n",
      "\u001B[32m[------------]\u001B[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001B[32m[ \u001B[0m   2%\u001B[32m      ]\u001B[0m     1            0.107499            0.176061            0.739203                6.30\n",
      "\u001B[32m[ \u001B[0m   5%\u001B[32m      ]\u001B[0m     2            0.107036            0.175118            0.742665                6.75\n",
      "\u001B[32m[ \u001B[0m   8%\u001B[32m      ]\u001B[0m     3            0.106671            0.175591            0.744079                7.22\n",
      "\u001B[32m[ \u001B[0m  11%\u001B[32m      ]\u001B[0m     4            0.106388            0.175378            0.747294                7.14\n",
      "\u001B[32m[ \u001B[0m  14%\u001B[32m      ]\u001B[0m     5            0.106196            0.175220            0.748414                7.15\n",
      "\u001B[32m[ \u001B[0m  17%\u001B[32m      ]\u001B[0m     6            0.105926            0.175351            0.748300                7.29\n",
      "\u001B[32m[ \u001B[0m  20%\u001B[32m      ]\u001B[0m     7            0.105656            0.175074            0.752282                7.15\n",
      "\u001B[32m[ \u001B[0m  22%\u001B[32m      ]\u001B[0m     8            0.105845            0.175043            0.751262                7.64\n",
      "\u001B[32m[ \u001B[0m  25%\u001B[32m      ]\u001B[0m     9            0.105315            0.174891            0.753625                7.52\n",
      "\u001B[32m[ \u001B[0m  28%\u001B[32m      ]\u001B[0m    10            0.105219            0.174723            0.753675                7.97\n",
      "\u001B[32m[ \u001B[0m  31%\u001B[32m      ]\u001B[0m    11            0.105160            0.174718            0.753354                8.78\n",
      "\u001B[32m[ \u001B[0m  34%\u001B[32m      ]\u001B[0m    12            0.105018            0.174598            0.752450                7.15\n",
      "\u001B[32m[ \u001B[0m  37%\u001B[32m      ]\u001B[0m    13            0.104732            0.174996            0.755151                7.19\n",
      "\u001B[32m[ \u001B[0m  40%\u001B[32m      ]\u001B[0m    14            0.104715            0.174988            0.754702                7.41\n",
      "\u001B[32m[ \u001B[0m  42%\u001B[32m      ]\u001B[0m    15            0.104639            0.174379            0.755233                7.28\n",
      "\u001B[32m[ \u001B[0m  45%\u001B[32m      ]\u001B[0m    16            0.104452            0.174303            0.756507                7.21\n",
      "\u001B[32m[ \u001B[0m  48%\u001B[32m      ]\u001B[0m    17            0.104292            0.174901            0.757854                7.22\n",
      "\u001B[32m[ \u001B[0m  51%\u001B[32m      ]\u001B[0m    18            0.104234            0.174721            0.758099                7.50\n",
      "\u001B[32m[ \u001B[0m  54%\u001B[32m      ]\u001B[0m    19            0.104162            0.174438            0.757014                7.93\n",
      "\u001B[32m[ \u001B[0m  57%\u001B[32m      ]\u001B[0m    20            0.104223            0.174071            0.756847                7.83\n",
      "\u001B[32m[ \u001B[0m  60%\u001B[32m      ]\u001B[0m    21            0.103989            0.173915            0.758327                7.24\n",
      "\u001B[32m[ \u001B[0m  62%\u001B[32m      ]\u001B[0m    22            0.103855            0.173730            0.759410                7.39\n",
      "\u001B[32m[ \u001B[0m  65%\u001B[32m      ]\u001B[0m    23            0.103699            0.174461            0.758547                7.57\n",
      "\u001B[32m[ \u001B[0m  68%\u001B[32m      ]\u001B[0m    24            0.103715            0.174519            0.759345                7.40\n",
      "\u001B[32m[ \u001B[0m  71%\u001B[32m      ]\u001B[0m    25            0.103622            0.174383            0.758768                7.45\n",
      "\u001B[32m[ \u001B[0m  74%\u001B[32m      ]\u001B[0m    26            0.103498            0.174232            0.759391                7.24\n",
      "\u001B[32m[ \u001B[0m  77%\u001B[32m      ]\u001B[0m    27            0.103385            0.173892            0.759789                7.23\n",
      "\u001B[32m[ \u001B[0m  80%\u001B[32m      ]\u001B[0m    28            0.103484            0.173573            0.759694                7.56\n",
      "\u001B[32m[ \u001B[0m  82%\u001B[32m      ]\u001B[0m    29            0.103397            0.173423            0.759933                7.68\n",
      "\u001B[32m[ \u001B[0m  85%\u001B[32m      ]\u001B[0m    30            0.103443            0.173654            0.758484                7.84\n",
      "\u001B[32m[ \u001B[0m  88%\u001B[32m      ]\u001B[0m    31            0.103088            0.173754            0.760621                7.90\n",
      "\u001B[32m[ \u001B[0m  91%\u001B[32m      ]\u001B[0m    32            0.102935            0.173904            0.760749                7.07\n",
      "\u001B[32m[ \u001B[0m  94%\u001B[32m      ]\u001B[0m    33            0.102934            0.174229            0.761403                7.15\n",
      "\u001B[32m[ \u001B[0m  97%\u001B[32m      ]\u001B[0m    34            0.102936            0.174527            0.760014                7.82\n",
      "\u001B[32m[ \u001B[0m 100%\u001B[32m      ]\u001B[0m    35            0.102823            0.174538            0.760231                7.12\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Early-stopping at epoch 33, best AUC: 0.761403\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to save model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel file: ./models/model0.01_4.out\n",
      "\u001B[32m[------------] \u001B[0mTime cost for saving model: 1.33 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Finish training\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Clear the xLearn environment ...\u001B[0m\n",
      "{'epoch': 35, 'k': 4, 'lambda': 0.001, 'lr': 0.15, 'metric': 'auc', 'opt': 'adagrad', 'task': 'binary'}\u001B[32m\u001B[1m[------------] Total time cost: 282.79 (sec)\u001B[0m\n",
      "\n",
      "\u001B[32m\u001B[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001B[39m\u001B[0m\u001B[32m[------------] \u001B[0mxLearn uses 8 threads for training task.\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Read Problem ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/train1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/val1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mNumber of Feature: 5665363\n",
      "\u001B[32m[------------] \u001B[0mNumber of Field: 6\n",
      "\u001B[32m[------------] \u001B[0mTime cost for reading problem: 7.57 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Initialize model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel size: 1.06 GB\n",
      "\u001B[32m[------------] \u001B[0mTime cost for model initial: 11.46 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to train ...\u001B[0m\n",
      "\u001B[32m[------------]\u001B[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001B[32m[ \u001B[0m   2%\u001B[32m      ]\u001B[0m     1            0.105149            0.168110            0.758326                6.07\n",
      "\u001B[32m[ \u001B[0m   5%\u001B[32m      ]\u001B[0m     2            0.103862            0.166804            0.759160                5.25\n",
      "\u001B[32m[ \u001B[0m   8%\u001B[32m      ]\u001B[0m     3            0.103160            0.165612            0.761015                6.31\n",
      "\u001B[32m[ \u001B[0m  11%\u001B[32m      ]\u001B[0m     4            0.102697            0.165343            0.761831                5.59\n",
      "\u001B[32m[ \u001B[0m  14%\u001B[32m      ]\u001B[0m     5            0.102320            0.165101            0.763060                5.70\n",
      "\u001B[32m[ \u001B[0m  17%\u001B[32m      ]\u001B[0m     6            0.102027            0.164857            0.763814                6.89\n",
      "\u001B[32m[ \u001B[0m  20%\u001B[32m      ]\u001B[0m     7            0.101741            0.164544            0.764586                6.07\n",
      "\u001B[32m[ \u001B[0m  22%\u001B[32m      ]\u001B[0m     8            0.101474            0.165030            0.765373                7.89\n",
      "\u001B[32m[ \u001B[0m  25%\u001B[32m      ]\u001B[0m     9            0.101236            0.164546            0.766183                7.49\n",
      "\u001B[32m[ \u001B[0m  28%\u001B[32m      ]\u001B[0m    10            0.101003            0.164575            0.766657                7.85\n",
      "\u001B[32m[ \u001B[0m  31%\u001B[32m      ]\u001B[0m    11            0.100804            0.164471            0.767071                8.08\n",
      "\u001B[32m[ \u001B[0m  34%\u001B[32m      ]\u001B[0m    12            0.100561            0.164399            0.767694                8.06\n",
      "\u001B[32m[ \u001B[0m  37%\u001B[32m      ]\u001B[0m    13            0.100367            0.164320            0.768202                8.09\n",
      "\u001B[32m[ \u001B[0m  40%\u001B[32m      ]\u001B[0m    14            0.100152            0.164256            0.768685                8.49\n",
      "\u001B[32m[ \u001B[0m  42%\u001B[32m      ]\u001B[0m    15            0.099951            0.164100            0.768883                9.35\n",
      "\u001B[32m[ \u001B[0m  45%\u001B[32m      ]\u001B[0m    16            0.099755            0.163884            0.769487                9.31\n",
      "\u001B[32m[ \u001B[0m  48%\u001B[32m      ]\u001B[0m    17            0.099578            0.163892            0.769929                9.89\n",
      "\u001B[32m[ \u001B[0m  51%\u001B[32m      ]\u001B[0m    18            0.099397            0.163603            0.770261               10.11\n",
      "\u001B[32m[ \u001B[0m  54%\u001B[32m      ]\u001B[0m    19            0.099227            0.163784            0.770693                9.89\n",
      "\u001B[32m[ \u001B[0m  57%\u001B[32m      ]\u001B[0m    20            0.099050            0.163630            0.771115                7.29\n",
      "\u001B[32m[ \u001B[0m  60%\u001B[32m      ]\u001B[0m    21            0.098900            0.163805            0.771318                6.95\n",
      "\u001B[32m[ \u001B[0m  62%\u001B[32m      ]\u001B[0m    22            0.098758            0.163550            0.771867                7.22\n",
      "\u001B[32m[ \u001B[0m  65%\u001B[32m      ]\u001B[0m    23            0.098615            0.163519            0.772171                7.82\n",
      "\u001B[32m[ \u001B[0m  68%\u001B[32m      ]\u001B[0m    24            0.098476            0.163462            0.772398                6.88\n",
      "\u001B[32m[ \u001B[0m  71%\u001B[32m      ]\u001B[0m    25            0.098340            0.163417            0.772676                6.44\n",
      "\u001B[32m[ \u001B[0m  74%\u001B[32m      ]\u001B[0m    26            0.098209            0.163228            0.773081                6.53\n",
      "\u001B[32m[ \u001B[0m  77%\u001B[32m      ]\u001B[0m    27            0.098078            0.163275            0.773296                7.10\n",
      "\u001B[32m[ \u001B[0m  80%\u001B[32m      ]\u001B[0m    28            0.097969            0.163142            0.773439                7.17\n",
      "\u001B[32m[ \u001B[0m  82%\u001B[32m      ]\u001B[0m    29            0.097840            0.163189            0.773967                8.51\n",
      "\u001B[32m[ \u001B[0m  85%\u001B[32m      ]\u001B[0m    30            0.097749            0.163192            0.773943                9.28\n",
      "\u001B[32m[ \u001B[0m  88%\u001B[32m      ]\u001B[0m    31            0.097632            0.163104            0.774173               10.14\n",
      "\u001B[32m[ \u001B[0m  91%\u001B[32m      ]\u001B[0m    32            0.097514            0.163352            0.774361                9.77\n",
      "\u001B[32m[ \u001B[0m  94%\u001B[32m      ]\u001B[0m    33            0.097415            0.163071            0.774606                9.49\n",
      "\u001B[32m[ \u001B[0m  97%\u001B[32m      ]\u001B[0m    34            0.097310            0.163202            0.774920                9.16\n",
      "\u001B[32m[ \u001B[0m 100%\u001B[32m      ]\u001B[0m    35            0.097216            0.162901            0.774797                9.41\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Early-stopping at epoch 34, best AUC: 0.774920\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to save model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel file: ./models/model0.001_4.out\n",
      "\u001B[32m[------------] \u001B[0mTime cost for saving model: 1.74 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Finish training\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Clear the xLearn environment ...\u001B[0m\n",
      "{'epoch': 35, 'k': 4, 'lambda': 0.0005, 'lr': 0.15, 'metric': 'auc', 'opt': 'adagrad', 'task': 'binary'}\u001B[32m\u001B[1m[------------] Total time cost: 301.25 (sec)\u001B[0m\n",
      "\n",
      "\u001B[32m\u001B[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001B[39m\u001B[0m\u001B[32m[------------] \u001B[0mxLearn uses 8 threads for training task.\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Read Problem ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/train1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/val1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mNumber of Feature: 5665363\n",
      "\u001B[32m[------------] \u001B[0mNumber of Field: 6\n",
      "\u001B[32m[------------] \u001B[0mTime cost for reading problem: 13.39 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Initialize model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel size: 1.06 GB\n",
      "\u001B[32m[------------] \u001B[0mTime cost for model initial: 24.96 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to train ...\u001B[0m\n",
      "\u001B[32m[------------]\u001B[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001B[32m[ \u001B[0m   2%\u001B[32m      ]\u001B[0m     1            0.103019            0.161745            0.767164                7.96\n",
      "\u001B[32m[ \u001B[0m   5%\u001B[32m      ]\u001B[0m     2            0.101376            0.160571            0.769275                7.84\n",
      "\u001B[32m[ \u001B[0m   8%\u001B[32m      ]\u001B[0m     3            0.100811            0.159991            0.769354                8.05\n",
      "\u001B[32m[ \u001B[0m  11%\u001B[32m      ]\u001B[0m     4            0.100380            0.159851            0.770341                8.05\n",
      "\u001B[32m[ \u001B[0m  14%\u001B[32m      ]\u001B[0m     5            0.099993            0.159821            0.771361                8.07\n",
      "\u001B[32m[ \u001B[0m  17%\u001B[32m      ]\u001B[0m     6            0.099634            0.159527            0.772179                8.03\n",
      "\u001B[32m[ \u001B[0m  20%\u001B[32m      ]\u001B[0m     7            0.099293            0.159362            0.772487                8.13\n",
      "\u001B[32m[ \u001B[0m  22%\u001B[32m      ]\u001B[0m     8            0.098956            0.158933            0.773421                8.46\n",
      "\u001B[32m[ \u001B[0m  25%\u001B[32m      ]\u001B[0m     9            0.098603            0.159103            0.773575                7.97\n",
      "\u001B[32m[ \u001B[0m  28%\u001B[32m      ]\u001B[0m    10            0.098292            0.158903            0.774172                7.92\n",
      "\u001B[32m[ \u001B[0m  31%\u001B[32m      ]\u001B[0m    11            0.097978            0.158682            0.774751                9.05\n",
      "\u001B[32m[ \u001B[0m  34%\u001B[32m      ]\u001B[0m    12            0.097690            0.158749            0.774941                8.10\n",
      "\u001B[32m[ \u001B[0m  37%\u001B[32m      ]\u001B[0m    13            0.097432            0.158427            0.775040                8.26\n",
      "\u001B[32m[ \u001B[0m  40%\u001B[32m      ]\u001B[0m    14            0.097174            0.158569            0.775532                8.46\n",
      "\u001B[32m[ \u001B[0m  42%\u001B[32m      ]\u001B[0m    15            0.096951            0.158286            0.775600                8.63\n",
      "\u001B[32m[ \u001B[0m  45%\u001B[32m      ]\u001B[0m    16            0.096746            0.158426            0.775692                8.56\n",
      "\u001B[32m[ \u001B[0m  48%\u001B[32m      ]\u001B[0m    17            0.096548            0.158410            0.775633                8.44\n",
      "\u001B[32m[ \u001B[0m  51%\u001B[32m      ]\u001B[0m    18            0.096364            0.158208            0.776312                8.20\n",
      "\u001B[32m[ \u001B[0m  54%\u001B[32m      ]\u001B[0m    19            0.096183            0.158028            0.776063                8.61\n",
      "\u001B[32m[ \u001B[0m  57%\u001B[32m      ]\u001B[0m    20            0.096006            0.158453            0.776788                8.05\n",
      "\u001B[32m[ \u001B[0m  60%\u001B[32m      ]\u001B[0m    21            0.095839            0.158635            0.776684                8.02\n",
      "\u001B[32m[ \u001B[0m  62%\u001B[32m      ]\u001B[0m    22            0.095667            0.158195            0.776931                7.98\n",
      "\u001B[32m[ \u001B[0m  65%\u001B[32m      ]\u001B[0m    23            0.095521            0.158156            0.776563                7.98\n",
      "\u001B[32m[ \u001B[0m  68%\u001B[32m      ]\u001B[0m    24            0.095351            0.158067            0.777156                8.10\n",
      "\u001B[32m[ \u001B[0m  71%\u001B[32m      ]\u001B[0m    25            0.095186            0.157974            0.777135                7.96\n",
      "\u001B[32m[ \u001B[0m  74%\u001B[32m      ]\u001B[0m    26            0.095041            0.158060            0.777369                7.95\n",
      "\u001B[32m[ \u001B[0m  77%\u001B[32m      ]\u001B[0m    27            0.094887            0.157955            0.776932                7.91\n",
      "\u001B[32m[ \u001B[0m  80%\u001B[32m      ]\u001B[0m    28            0.094727            0.158073            0.777733                9.49\n",
      "\u001B[32m[ \u001B[0m  82%\u001B[32m      ]\u001B[0m    29            0.094557            0.157926            0.778138                9.29\n",
      "\u001B[32m[ \u001B[0m  85%\u001B[32m      ]\u001B[0m    30            0.094390            0.157796            0.778232                8.90\n",
      "\u001B[32m[ \u001B[0m  88%\u001B[32m      ]\u001B[0m    31            0.094205            0.157571            0.778212                8.85\n",
      "\u001B[32m[ \u001B[0m  91%\u001B[32m      ]\u001B[0m    32            0.094015            0.157631            0.778652                8.71\n",
      "\u001B[32m[ \u001B[0m  94%\u001B[32m      ]\u001B[0m    33            0.093800            0.157590            0.778996                8.68\n",
      "\u001B[32m[ \u001B[0m  97%\u001B[32m      ]\u001B[0m    34            0.093583            0.157490            0.779277                8.53\n",
      "\u001B[32m[ \u001B[0m 100%\u001B[32m      ]\u001B[0m    35            0.093352            0.157487            0.779523                9.04\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to save model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel file: ./models/model0.0005_4.out\n",
      "\u001B[32m[------------] \u001B[0mTime cost for saving model: 1.71 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Finish training\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Clear the xLearn environment ...\u001B[0m\n",
      "{'epoch': 35, 'k': 4, 'lambda': 0.0001, 'lr': 0.15, 'metric': 'auc', 'opt': 'adagrad', 'task': 'binary'}\u001B[32m\u001B[1m[------------] Total time cost: 337.51 (sec)\u001B[0m\n",
      "\n",
      "\u001B[32m\u001B[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001B[39m\u001B[0m\u001B[32m[------------] \u001B[0mxLearn uses 8 threads for training task.\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Read Problem ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/train1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/val1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mNumber of Feature: 5665363\n",
      "\u001B[32m[------------] \u001B[0mNumber of Field: 6\n",
      "\u001B[32m[------------] \u001B[0mTime cost for reading problem: 13.17 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Initialize model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel size: 1.06 GB\n",
      "\u001B[32m[------------] \u001B[0mTime cost for model initial: 24.98 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to train ...\u001B[0m\n",
      "\u001B[32m[------------]\u001B[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001B[32m[ \u001B[0m   2%\u001B[32m      ]\u001B[0m     1            0.100613            0.155597            0.776506                7.99\n",
      "\u001B[32m[ \u001B[0m   5%\u001B[32m      ]\u001B[0m     2            0.098969            0.155004            0.779410                8.07\n",
      "\u001B[32m[ \u001B[0m   8%\u001B[32m      ]\u001B[0m     3            0.098096            0.154272            0.781511                8.32\n",
      "\u001B[32m[ \u001B[0m  11%\u001B[32m      ]\u001B[0m     4            0.097261            0.153911            0.781952                8.06\n",
      "\u001B[32m[ \u001B[0m  14%\u001B[32m      ]\u001B[0m     5            0.096453            0.153685            0.784063                8.06\n",
      "\u001B[32m[ \u001B[0m  17%\u001B[32m      ]\u001B[0m     6            0.095536            0.153274            0.784811                8.06\n",
      "\u001B[32m[ \u001B[0m  20%\u001B[32m      ]\u001B[0m     7            0.094393            0.152998            0.786013                8.10\n",
      "\u001B[32m[ \u001B[0m  22%\u001B[32m      ]\u001B[0m     8            0.092876            0.152459            0.788256                8.18\n",
      "\u001B[32m[ \u001B[0m  25%\u001B[32m      ]\u001B[0m     9            0.090832            0.151966            0.789636                8.09\n",
      "\u001B[32m[ \u001B[0m  28%\u001B[32m      ]\u001B[0m    10            0.088263            0.151333            0.791822                8.11\n",
      "\u001B[32m[ \u001B[0m  31%\u001B[32m      ]\u001B[0m    11            0.085232            0.150949            0.792782                8.19\n",
      "\u001B[32m[ \u001B[0m  34%\u001B[32m      ]\u001B[0m    12            0.081877            0.150536            0.793715                8.56\n",
      "\u001B[32m[ \u001B[0m  37%\u001B[32m      ]\u001B[0m    13            0.078390            0.150502            0.793594                7.77\n",
      "\u001B[32m[ \u001B[0m  40%\u001B[32m      ]\u001B[0m    14            0.074822            0.150699            0.793127                7.97\n",
      "\u001B[32m[ \u001B[0m  42%\u001B[32m      ]\u001B[0m    15            0.071384            0.150894            0.792479                8.37\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Early-stopping at epoch 12, best AUC: 0.793715\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to save model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel file: ./models/model0.0001_4.out\n",
      "\u001B[32m[------------] \u001B[0mTime cost for saving model: 1.67 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Finish training\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Clear the xLearn environment ...\u001B[0m\n",
      "\u001B[32m\u001B[1m[------------] Total time cost: 164.81 (sec)\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "for item in ParameterGrid(params):\n",
    "    print(item)\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setTrain(\"./data/train1_ffm.txt\")\n",
    "    ffm_model.setValidate(\"./data/val1_ffm.txt\")\n",
    "    ffm_model.fit(item, f\"./models/model{item['lambda']}_{item['k']}.out\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "params = {\n",
    "    'task': ['binary'],\n",
    "    'lr': [0.15],\n",
    "    'lambda':[1e-2, 1e-3, 5e-4, 1e-4],\n",
    "    'k': [6],\n",
    "    'metric': ['auc'],\n",
    "    'epoch': [35],\n",
    "    'opt': ['adagrad']\n",
    "}\n",
    "for item in ParameterGrid(params):\n",
    "    print(item)\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setTrain(\"./data/train1_ffm.txt\")\n",
    "    ffm_model.setValidate(\"./data/val1_ffm.txt\")\n",
    "    ffm_model.fit(item, f\"./models/model{item['lambda']}_{item['k']}.out\")"
   ],
   "metadata": {
    "id": "uZYY2g5pixoZ"
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 35, 'k': 6, 'lambda': 0.01, 'lr': 0.15, 'metric': 'auc', 'opt': 'adagrad', 'task': 'binary'}\n",
      "\u001B[32m\u001B[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001B[39m\u001B[0m\u001B[32m[------------] \u001B[0mxLearn uses 8 threads for training task.\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Read Problem ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/train1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/val1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mNumber of Feature: 5665363\n",
      "\u001B[32m[------------] \u001B[0mNumber of Field: 6\n",
      "\u001B[32m[------------] \u001B[0mTime cost for reading problem: 8.38 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Initialize model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel size: 2.07 GB\n",
      "\u001B[32m[------------] \u001B[0mTime cost for model initial: 17.32 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to train ...\u001B[0m\n",
      "\u001B[32m[------------]\u001B[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001B[32m[ \u001B[0m   2%\u001B[32m      ]\u001B[0m     1            0.107523            0.175821            0.740924                8.01\n",
      "\u001B[32m[ \u001B[0m   5%\u001B[32m      ]\u001B[0m     2            0.107015            0.175398            0.742399                7.85\n",
      "\u001B[32m[ \u001B[0m   8%\u001B[32m      ]\u001B[0m     3            0.106772            0.175445            0.744503                8.54\n",
      "\u001B[32m[ \u001B[0m  11%\u001B[32m      ]\u001B[0m     4            0.106474            0.175327            0.746828                9.09\n",
      "\u001B[32m[ \u001B[0m  14%\u001B[32m      ]\u001B[0m     5            0.106149            0.175166            0.747813               11.47\n",
      "\u001B[32m[ \u001B[0m  17%\u001B[32m      ]\u001B[0m     6            0.105900            0.175063            0.748909               12.31\n",
      "\u001B[32m[ \u001B[0m  20%\u001B[32m      ]\u001B[0m     7            0.105726            0.175102            0.751463               11.92\n",
      "\u001B[32m[ \u001B[0m  22%\u001B[32m      ]\u001B[0m     8            0.105823            0.175078            0.751438               11.85\n",
      "\u001B[32m[ \u001B[0m  25%\u001B[32m      ]\u001B[0m     9            0.105320            0.174906            0.754060               11.81\n",
      "\u001B[32m[ \u001B[0m  28%\u001B[32m      ]\u001B[0m    10            0.105184            0.175016            0.754163               11.73\n",
      "\u001B[32m[ \u001B[0m  31%\u001B[32m      ]\u001B[0m    11            0.105228            0.174490            0.753728               11.73\n",
      "\u001B[32m[ \u001B[0m  34%\u001B[32m      ]\u001B[0m    12            0.104966            0.174460            0.753334               12.64\n",
      "\u001B[32m[ \u001B[0m  37%\u001B[32m      ]\u001B[0m    13            0.104743            0.174954            0.755585               10.93\n",
      "\u001B[32m[ \u001B[0m  40%\u001B[32m      ]\u001B[0m    14            0.104692            0.174623            0.754272               10.73\n",
      "\u001B[32m[ \u001B[0m  42%\u001B[32m      ]\u001B[0m    15            0.104643            0.174292            0.755442               10.69\n",
      "\u001B[32m[ \u001B[0m  45%\u001B[32m      ]\u001B[0m    16            0.104385            0.174474            0.756804               11.40\n",
      "\u001B[32m[ \u001B[0m  48%\u001B[32m      ]\u001B[0m    17            0.104313            0.174790            0.758087               10.95\n",
      "\u001B[32m[ \u001B[0m  51%\u001B[32m      ]\u001B[0m    18            0.104238            0.174589            0.758081               12.39\n",
      "\u001B[32m[ \u001B[0m  54%\u001B[32m      ]\u001B[0m    19            0.104121            0.174302            0.756487               12.11\n",
      "\u001B[32m[ \u001B[0m  57%\u001B[32m      ]\u001B[0m    20            0.104231            0.173865            0.757256               11.29\n",
      "\u001B[32m[ \u001B[0m  60%\u001B[32m      ]\u001B[0m    21            0.103997            0.173909            0.758594               10.96\n",
      "\u001B[32m[ \u001B[0m  62%\u001B[32m      ]\u001B[0m    22            0.103806            0.173943            0.759631               11.39\n",
      "\u001B[32m[ \u001B[0m  65%\u001B[32m      ]\u001B[0m    23            0.103769            0.174599            0.758664               11.06\n",
      "\u001B[32m[ \u001B[0m  68%\u001B[32m      ]\u001B[0m    24            0.103701            0.174317            0.759740                9.00\n",
      "\u001B[32m[ \u001B[0m  71%\u001B[32m      ]\u001B[0m    25            0.103606            0.174222            0.759303                8.27\n",
      "\u001B[32m[ \u001B[0m  74%\u001B[32m      ]\u001B[0m    26            0.103475            0.174110            0.759550                8.27\n",
      "\u001B[32m[ \u001B[0m  77%\u001B[32m      ]\u001B[0m    27            0.103445            0.173867            0.759976                8.35\n",
      "\u001B[32m[ \u001B[0m  80%\u001B[32m      ]\u001B[0m    28            0.103513            0.173526            0.758865                8.46\n",
      "\u001B[32m[ \u001B[0m  82%\u001B[32m      ]\u001B[0m    29            0.103374            0.173459            0.760317                9.07\n",
      "\u001B[32m[ \u001B[0m  85%\u001B[32m      ]\u001B[0m    30            0.103270            0.173636            0.759294                8.47\n",
      "\u001B[32m[ \u001B[0m  88%\u001B[32m      ]\u001B[0m    31            0.103060            0.173899            0.760494                8.47\n",
      "\u001B[32m[ \u001B[0m  91%\u001B[32m      ]\u001B[0m    32            0.102921            0.174058            0.761021                8.54\n",
      "\u001B[32m[ \u001B[0m  94%\u001B[32m      ]\u001B[0m    33            0.103025            0.174420            0.760554                8.28\n",
      "\u001B[32m[ \u001B[0m  97%\u001B[32m      ]\u001B[0m    34            0.102952            0.174445            0.760012               10.03\n",
      "\u001B[32m[ \u001B[0m 100%\u001B[32m      ]\u001B[0m    35            0.102817            0.174449            0.760834                9.50\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Early-stopping at epoch 32, best AUC: 0.761021\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to save model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel file: ./models/model0.01_6.out\n",
      "\u001B[32m[------------] \u001B[0mTime cost for saving model: 2.22 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Finish training\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Clear the xLearn environment ...\u001B[0m\n",
      "{'epoch': 35, 'k': 6, 'lambda': 0.001, 'lr': 0.15, 'metric': 'auc', 'opt': 'adagrad', 'task': 'binary'}\u001B[32m\u001B[1m[------------] Total time cost: 391.39 (sec)\u001B[0m\n",
      "\n",
      "\u001B[32m\u001B[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001B[39m\u001B[0m\u001B[32m[------------] \u001B[0mxLearn uses 8 threads for training task.\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Read Problem ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/train1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/val1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mNumber of Feature: 5665363\n",
      "\u001B[32m[------------] \u001B[0mNumber of Field: 6\n",
      "\u001B[32m[------------] \u001B[0mTime cost for reading problem: 9.48 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Initialize model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel size: 2.07 GB\n",
      "\u001B[32m[------------] \u001B[0mTime cost for model initial: 20.08 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to train ...\u001B[0m\n",
      "\u001B[32m[------------]\u001B[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001B[32m[ \u001B[0m   2%\u001B[32m      ]\u001B[0m     1            0.105137            0.168313            0.757804                6.09\n",
      "\u001B[32m[ \u001B[0m   5%\u001B[32m      ]\u001B[0m     2            0.103840            0.166630            0.759458                6.47\n",
      "\u001B[32m[ \u001B[0m   8%\u001B[32m      ]\u001B[0m     3            0.103156            0.165761            0.760931                6.93\n",
      "\u001B[32m[ \u001B[0m  11%\u001B[32m      ]\u001B[0m     4            0.102684            0.165400            0.761822                7.13\n",
      "\u001B[32m[ \u001B[0m  14%\u001B[32m      ]\u001B[0m     5            0.102316            0.165199            0.762866                7.72\n",
      "\u001B[32m[ \u001B[0m  17%\u001B[32m      ]\u001B[0m     6            0.102029            0.164916            0.763602                8.90\n",
      "\u001B[32m[ \u001B[0m  20%\u001B[32m      ]\u001B[0m     7            0.101745            0.164483            0.764590               11.01\n",
      "\u001B[32m[ \u001B[0m  22%\u001B[32m      ]\u001B[0m     8            0.101476            0.164643            0.765438               10.65\n",
      "\u001B[32m[ \u001B[0m  25%\u001B[32m      ]\u001B[0m     9            0.101231            0.164506            0.766136                9.98\n",
      "\u001B[32m[ \u001B[0m  28%\u001B[32m      ]\u001B[0m    10            0.100998            0.164576            0.766627                9.89\n",
      "\u001B[32m[ \u001B[0m  31%\u001B[32m      ]\u001B[0m    11            0.100785            0.164409            0.766987                7.77\n",
      "\u001B[32m[ \u001B[0m  34%\u001B[32m      ]\u001B[0m    12            0.100541            0.164135            0.767709                6.16\n",
      "\u001B[32m[ \u001B[0m  37%\u001B[32m      ]\u001B[0m    13            0.100335            0.164120            0.768303                5.99\n",
      "\u001B[32m[ \u001B[0m  40%\u001B[32m      ]\u001B[0m    14            0.100119            0.164286            0.768898                6.79\n",
      "\u001B[32m[ \u001B[0m  42%\u001B[32m      ]\u001B[0m    15            0.099912            0.164066            0.769066                8.29\n",
      "\u001B[32m[ \u001B[0m  45%\u001B[32m      ]\u001B[0m    16            0.099723            0.163759            0.769599                8.63\n",
      "\u001B[32m[ \u001B[0m  48%\u001B[32m      ]\u001B[0m    17            0.099536            0.163857            0.770073                7.98\n",
      "\u001B[32m[ \u001B[0m  51%\u001B[32m      ]\u001B[0m    18            0.099357            0.163799            0.770294                7.68\n",
      "\u001B[32m[ \u001B[0m  54%\u001B[32m      ]\u001B[0m    19            0.099196            0.163733            0.770808                7.20\n",
      "\u001B[32m[ \u001B[0m  57%\u001B[32m      ]\u001B[0m    20            0.099021            0.163665            0.771216                7.15\n",
      "\u001B[32m[ \u001B[0m  60%\u001B[32m      ]\u001B[0m    21            0.098866            0.163750            0.771439                7.21\n",
      "\u001B[32m[ \u001B[0m  62%\u001B[32m      ]\u001B[0m    22            0.098721            0.163473            0.771995                7.91\n",
      "\u001B[32m[ \u001B[0m  65%\u001B[32m      ]\u001B[0m    23            0.098578            0.163563            0.772284                9.08\n",
      "\u001B[32m[ \u001B[0m  68%\u001B[32m      ]\u001B[0m    24            0.098433            0.163447            0.772524                9.43\n",
      "\u001B[32m[ \u001B[0m  71%\u001B[32m      ]\u001B[0m    25            0.098303            0.163364            0.772730                9.98\n",
      "\u001B[32m[ \u001B[0m  74%\u001B[32m      ]\u001B[0m    26            0.098164            0.163206            0.773096               10.31\n",
      "\u001B[32m[ \u001B[0m  77%\u001B[32m      ]\u001B[0m    27            0.098046            0.163316            0.773286                8.76\n",
      "\u001B[32m[ \u001B[0m  80%\u001B[32m      ]\u001B[0m    28            0.097938            0.163206            0.773483                8.23\n",
      "\u001B[32m[ \u001B[0m  82%\u001B[32m      ]\u001B[0m    29            0.097804            0.163217            0.774004                8.29\n",
      "\u001B[32m[ \u001B[0m  85%\u001B[32m      ]\u001B[0m    30            0.097707            0.163156            0.774009                8.28\n",
      "\u001B[32m[ \u001B[0m  88%\u001B[32m      ]\u001B[0m    31            0.097601            0.163127            0.774250                8.30\n",
      "\u001B[32m[ \u001B[0m  91%\u001B[32m      ]\u001B[0m    32            0.097485            0.163220            0.774444                8.54\n",
      "\u001B[32m[ \u001B[0m  94%\u001B[32m      ]\u001B[0m    33            0.097375            0.163094            0.774604                9.65\n",
      "\u001B[32m[ \u001B[0m  97%\u001B[32m      ]\u001B[0m    34            0.097267            0.163146            0.774849                8.81\n",
      "\u001B[32m[ \u001B[0m 100%\u001B[32m      ]\u001B[0m    35            0.097186            0.162941            0.774875                8.76\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to save model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel file: ./models/model0.001_6.out\n",
      "\u001B[32m[------------] \u001B[0mTime cost for saving model: 1.92 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Finish training\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Clear the xLearn environment ...\u001B[0m\n",
      "{'epoch': 35, 'k': 6, 'lambda': 0.0005, 'lr': 0.15, 'metric': 'auc', 'opt': 'adagrad', 'task': 'binary'}\n",
      "\u001B[32m\u001B[1m[------------] Total time cost: 329.68 (sec)\u001B[0m\n",
      "\u001B[32m\u001B[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001B[39m\u001B[0m\u001B[32m[------------] \u001B[0mxLearn uses 8 threads for training task.\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Read Problem ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/train1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/val1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mNumber of Feature: 5665363\n",
      "\u001B[32m[------------] \u001B[0mNumber of Field: 6\n",
      "\u001B[32m[------------] \u001B[0mTime cost for reading problem: 6.80 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Initialize model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel size: 2.07 GB\n",
      "\u001B[32m[------------] \u001B[0mTime cost for model initial: 14.09 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to train ...\u001B[0m\n",
      "\u001B[32m[------------]\u001B[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001B[32m[ \u001B[0m   2%\u001B[32m      ]\u001B[0m     1            0.103030            0.161452            0.766018                7.06\n",
      "\u001B[32m[ \u001B[0m   5%\u001B[32m      ]\u001B[0m     2            0.101376            0.160111            0.768580                7.09\n",
      "\u001B[32m[ \u001B[0m   8%\u001B[32m      ]\u001B[0m     3            0.100808            0.160086            0.769550                7.03\n",
      "\u001B[32m[ \u001B[0m  11%\u001B[32m      ]\u001B[0m     4            0.100367            0.160021            0.770325                7.02\n",
      "\u001B[32m[ \u001B[0m  14%\u001B[32m      ]\u001B[0m     5            0.099963            0.159971            0.771163                6.99\n",
      "\u001B[32m[ \u001B[0m  17%\u001B[32m      ]\u001B[0m     6            0.099586            0.159402            0.772034                7.03\n",
      "\u001B[32m[ \u001B[0m  20%\u001B[32m      ]\u001B[0m     7            0.099227            0.159378            0.772435                7.02\n",
      "\u001B[32m[ \u001B[0m  22%\u001B[32m      ]\u001B[0m     8            0.098880            0.159130            0.773761                6.97\n",
      "\u001B[32m[ \u001B[0m  25%\u001B[32m      ]\u001B[0m     9            0.098528            0.159126            0.773646                7.02\n",
      "\u001B[32m[ \u001B[0m  28%\u001B[32m      ]\u001B[0m    10            0.098214            0.159003            0.773874                7.02\n",
      "\u001B[32m[ \u001B[0m  31%\u001B[32m      ]\u001B[0m    11            0.097900            0.158583            0.774568                7.07\n",
      "\u001B[32m[ \u001B[0m  34%\u001B[32m      ]\u001B[0m    12            0.097609            0.158827            0.774735                7.34\n",
      "\u001B[32m[ \u001B[0m  37%\u001B[32m      ]\u001B[0m    13            0.097353            0.158653            0.774910                7.55\n",
      "\u001B[32m[ \u001B[0m  40%\u001B[32m      ]\u001B[0m    14            0.097102            0.158471            0.775332                7.96\n",
      "\u001B[32m[ \u001B[0m  42%\u001B[32m      ]\u001B[0m    15            0.096870            0.158444            0.775485                8.06\n",
      "\u001B[32m[ \u001B[0m  45%\u001B[32m      ]\u001B[0m    16            0.096666            0.158395            0.775566                7.81\n",
      "\u001B[32m[ \u001B[0m  48%\u001B[32m      ]\u001B[0m    17            0.096469            0.158199            0.775423                7.57\n",
      "\u001B[32m[ \u001B[0m  51%\u001B[32m      ]\u001B[0m    18            0.096276            0.158341            0.776070                7.53\n",
      "\u001B[32m[ \u001B[0m  54%\u001B[32m      ]\u001B[0m    19            0.096091            0.158031            0.775615                6.12\n",
      "\u001B[32m[ \u001B[0m  57%\u001B[32m      ]\u001B[0m    20            0.095913            0.158125            0.776090                5.71\n",
      "\u001B[32m[ \u001B[0m  60%\u001B[32m      ]\u001B[0m    21            0.095735            0.158448            0.776312                5.97\n",
      "\u001B[32m[ \u001B[0m  62%\u001B[32m      ]\u001B[0m    22            0.095560            0.158293            0.776456                6.27\n",
      "\u001B[32m[ \u001B[0m  65%\u001B[32m      ]\u001B[0m    23            0.095401            0.158190            0.776087                7.70\n",
      "\u001B[32m[ \u001B[0m  68%\u001B[32m      ]\u001B[0m    24            0.095229            0.158227            0.776735                8.53\n",
      "\u001B[32m[ \u001B[0m  71%\u001B[32m      ]\u001B[0m    25            0.095060            0.158045            0.776651                8.64\n",
      "\u001B[32m[ \u001B[0m  74%\u001B[32m      ]\u001B[0m    26            0.094894            0.158072            0.776740                9.23\n",
      "\u001B[32m[ \u001B[0m  77%\u001B[32m      ]\u001B[0m    27            0.094711            0.157986            0.776109               10.05\n",
      "\u001B[32m[ \u001B[0m  80%\u001B[32m      ]\u001B[0m    28            0.094526            0.158012            0.777355               10.07\n",
      "\u001B[32m[ \u001B[0m  82%\u001B[32m      ]\u001B[0m    29            0.094340            0.157934            0.777892               11.68\n",
      "\u001B[32m[ \u001B[0m  85%\u001B[32m      ]\u001B[0m    30            0.094137            0.157888            0.778304               10.94\n",
      "\u001B[32m[ \u001B[0m  88%\u001B[32m      ]\u001B[0m    31            0.093912            0.157557            0.778050               10.98\n",
      "\u001B[32m[ \u001B[0m  91%\u001B[32m      ]\u001B[0m    32            0.093679            0.157576            0.778452               10.73\n",
      "\u001B[32m[ \u001B[0m  94%\u001B[32m      ]\u001B[0m    33            0.093420            0.157309            0.778992               10.85\n",
      "\u001B[32m[ \u001B[0m  97%\u001B[32m      ]\u001B[0m    34            0.093133            0.157375            0.779592               10.68\n",
      "\u001B[32m[ \u001B[0m 100%\u001B[32m      ]\u001B[0m    35            0.092827            0.157514            0.780051               11.30\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to save model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel file: ./models/model0.0005_6.out\n",
      "\u001B[32m[------------] \u001B[0mTime cost for saving model: 2.87 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Finish training\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Clear the xLearn environment ...\u001B[0m\n",
      "{'epoch': 35, 'k': 6, 'lambda': 0.0001, 'lr': 0.15, 'metric': 'auc', 'opt': 'adagrad', 'task': 'binary'}\u001B[32m\u001B[1m[------------] Total time cost: 317.38 (sec)\u001B[0m\n",
      "\n",
      "\u001B[32m\u001B[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001B[39m\u001B[0m\u001B[32m[------------] \u001B[0mxLearn uses 8 threads for training task.\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Read Problem ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/train1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/val1_ffm.txt.bin) found. Skip converting text to binary.\n",
      "\u001B[32m[------------] \u001B[0mNumber of Feature: 5665363\n",
      "\u001B[32m[------------] \u001B[0mNumber of Field: 6\n",
      "\u001B[32m[------------] \u001B[0mTime cost for reading problem: 13.78 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Initialize model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel size: 2.07 GB\n",
      "\u001B[32m[------------] \u001B[0mTime cost for model initial: 23.78 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to train ...\u001B[0m\n",
      "\u001B[32m[------------]\u001B[0m Epoch      Train log_loss       Test log_loss            Test AUC     Time cost (sec)\n",
      "\u001B[32m[ \u001B[0m   2%\u001B[32m      ]\u001B[0m     1            0.100573            0.155605            0.776579                8.57\n",
      "\u001B[32m[ \u001B[0m   5%\u001B[32m      ]\u001B[0m     2            0.098921            0.154954            0.779739                9.25\n",
      "\u001B[32m[ \u001B[0m   8%\u001B[32m      ]\u001B[0m     3            0.097978            0.154288            0.781851                8.95\n",
      "\u001B[32m[ \u001B[0m  11%\u001B[32m      ]\u001B[0m     4            0.097113            0.153824            0.781842                8.87\n",
      "\u001B[32m[ \u001B[0m  14%\u001B[32m      ]\u001B[0m     5            0.096264            0.153447            0.783712                8.90\n",
      "\u001B[32m[ \u001B[0m  17%\u001B[32m      ]\u001B[0m     6            0.095261            0.153227            0.784869               10.45\n",
      "\u001B[32m[ \u001B[0m  20%\u001B[32m      ]\u001B[0m     7            0.093961            0.152861            0.786120                9.77\n",
      "\u001B[32m[ \u001B[0m  22%\u001B[32m      ]\u001B[0m     8            0.092202            0.152367            0.788831                9.91\n",
      "\u001B[32m[ \u001B[0m  25%\u001B[32m      ]\u001B[0m     9            0.089854            0.151891            0.789718                9.88\n",
      "\u001B[32m[ \u001B[0m  28%\u001B[32m      ]\u001B[0m    10            0.086979            0.151145            0.792169                8.97\n",
      "\u001B[32m[ \u001B[0m  31%\u001B[32m      ]\u001B[0m    11            0.083615            0.150850            0.792529                9.07\n",
      "\u001B[32m[ \u001B[0m  34%\u001B[32m      ]\u001B[0m    12            0.079960            0.150657            0.793434                8.99\n",
      "\u001B[32m[ \u001B[0m  37%\u001B[32m      ]\u001B[0m    13            0.076187            0.150625            0.793150               10.47\n",
      "\u001B[32m[ \u001B[0m  40%\u001B[32m      ]\u001B[0m    14            0.072388            0.150926            0.792552                9.97\n",
      "\u001B[32m[ \u001B[0m  42%\u001B[32m      ]\u001B[0m    15            0.068771            0.151453            0.791957                9.66\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Early-stopping at epoch 12, best AUC: 0.793434\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to save model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mModel file: ./models/model0.0001_6.out\n",
      "\u001B[32m[------------] \u001B[0mTime cost for saving model: 2.82 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Finish training\u001B[0m\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Clear the xLearn environment ...\u001B[0m\n",
      "\u001B[32m\u001B[1m[------------] Total time cost: 188.11 (sec)\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь обучим лучшую модель и проверим ее на тестовой выборке."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32m\u001B[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001B[39m\u001B[0m\u001B[32m[------------] \u001B[0mxLearn uses 8 threads for prediction task.\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Load model ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mLoad model from ./models/model0.0001_4.out\n",
      "\u001B[32m[------------] \u001B[0mLoss function: cross-entropy\n",
      "\u001B[32m[------------] \u001B[0mScore function: ffm\n",
      "\u001B[32m[------------] \u001B[0mNumber of Feature: 5665363\n",
      "\u001B[32m[------------] \u001B[0mNumber of K: 4\n",
      "\u001B[32m[------------] \u001B[0mNumber of field: 6\n",
      "\u001B[32m[------------] \u001B[0mTime cost for loading model: 0.69 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Read Problem ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001B[32m[------------] \u001B[0mBinary file (./data/test1_ffm.txt.bin) NOT found. Convert text file to binary file.\n",
      "\u001B[32m[------------] \u001B[0mTime cost for reading problem: 2.31 (sec)\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Start to predict ...\u001B[0m\n",
      "\u001B[32m[------------] \u001B[0mThe test loss is: 0.135559\n",
      "\u001B[32m\u001B[1m[ ACTION     ] Clear the xLearn environment ...\u001B[0m\n",
      "\u001B[32m\u001B[1m[------------] Total time cost: 3.84 (sec)\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "best_p = {'epoch': 35, 'k': 4, 'lambda': 0.0001, 'lr': 0.15, 'metric': 'auc', 'opt': 'adagrad', 'task': 'binary'}\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"./data/train1_ffm.txt\")\n",
    "ffm_model.setTest('./data/test1_ffm.txt')\n",
    "ffm_model.setSigmoid()\n",
    "ffm_model.predict(\"./models/model0.0001_4.out\", \"./data/result.txt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model: NNL = 0.13556384117468007, ROC AUC = 0.7623435960452609\n"
     ]
    }
   ],
   "source": [
    "y_model = pd.read_csv(\"./data/result.txt\", header=None)\n",
    "y_test = test['clicks']\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "print(f\"My model: NNL = {log_loss(y_test, y_model)}, ROC AUC = {roc_auc_score(y_test, y_model)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для линейной модели результат был таким: NNL = 0.13363618401953573, ROC AUC = 0.7789599619007965, что близко к тому, что я смогла получить с FFM. Возможно, при переборе большего количества значений гиперпараметров результат был бы лучше."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
