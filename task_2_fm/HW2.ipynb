{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Анализ и подготовка данных\n",
    "\n",
    "Колонки:\n",
    "\n",
    "Признаки:\n",
    "\n",
    "+ (banner):\n",
    "\n",
    "banner_id - id баннера, где баннер - сама реклама\n",
    "zone_id - id зоны, где зона - место на сайте для размещения рекламы\n",
    "campaign_clicks - общее количество показов данной кампании (которой соотвествует баннер) данному юзеру, произошедшие до текущего показа. Кампанию стоит понимать как что-то общее (рекламодатель/тематика/ и т. п.) для баннеров.\n",
    "\n",
    "+ (user):\n",
    "\n",
    "oaid_hash - хэш юзера\n",
    "os_id - id операционной системы\n",
    "country_id - id страны\n",
    "\n",
    "+ (date):\n",
    "\n",
    "date_time - время показа рекламы (здесь возьму только час как категориальную фичу)\n",
    "\n",
    "target:\n",
    "clicks - был ли клик\n",
    "\n",
    "удалить:\n",
    "impressions - был ли показ (колонка с единицами)\n",
    "\n",
    "\n",
    "_____\n",
    "В предыдущем задании я кодировала все фичи с помощью One-hot encoding (кроме фичи campaign_clicks, ее логарифмирую и оставляю такой, какая она есть). В этот раз я сделаю почти то же самое - перекодирую все значения переменных на 0...N-1, где N- кол-во уникальных значений в колонке. Так как далее буду писать FFM на pytorch, вместо линейного слоя возьму Embedding, который как раз принимает такие значения."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "            date_time  zone_id  banner_id            oaid_hash  \\\n0 2021-09-27 00:01:30        0          0  5664530014561852622   \n1 2021-09-26 22:54:49        1          1  5186611064559013950   \n2 2021-09-26 23:57:20        2          2  2215519569292448030   \n3 2021-09-27 00:04:30        3          3  6262169206735077204   \n4 2021-09-27 00:06:21        4          4  4778985830203613115   \n\n   campaign_clicks  os_id  country_id  impressions  clicks  \n0                0      0           0            1       1  \n1                0      0           1            1       1  \n2                3      0           0            1       1  \n3                0      1           1            1       1  \n4                0      1           0            1       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>zone_id</th>\n      <th>banner_id</th>\n      <th>oaid_hash</th>\n      <th>campaign_clicks</th>\n      <th>os_id</th>\n      <th>country_id</th>\n      <th>impressions</th>\n      <th>clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-09-27 00:01:30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5664530014561852622</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-09-26 22:54:49</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5186611064559013950</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-09-26 23:57:20</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2215519569292448030</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-09-27 00:04:30</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6262169206735077204</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-09-27 00:06:21</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4778985830203613115</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# читаем данные\n",
    "data = pd.read_csv('../data/data.csv')\n",
    "# сразу удаляем ненужные колонки\n",
    "data = data.drop([\"banner_id0\", \"banner_id1\", \"rate0\", \"rate1\", \"g0\", \"g1\", \"coeff_sum0\", \"coeff_sum1\"], axis=1)\n",
    "# уточняем формат данных колокни с датой\n",
    "data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "На все колонки, кроме oaid_hash, уже смотрели. Поэтому в этот раз посмотрим только на нее."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "oaid_counts = np.unique(data['oaid_hash'], return_counts=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "6510316"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# всего уникальных юзеров\n",
    "len(oaid_counts[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "187834"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сколько всего юзеров, у которых больше 10 наблюдений?\n",
    "np.sum(oaid_counts[1] > 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Оставим лишь тех юзеров, у которых более менее достаточно наблюдений (например, 10). Остальным присвоим одинаковую категорию. Иначе, если оставлять всех юзеров, модель получается огромной и вряд ли сможет нормально обучиться (тем более для юзеров, у которых мало наблюдений)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# кодировщик категориальных колонок по типу OneHotEncoder,\n",
    "# только просто перекодировывает значения категориальных переменных от 1 до N (где N - макс. число уник. значений)\n",
    "# фиттим на трейне, для валидации и теста используем только трансформ\n",
    "# такой вид кодировки был выбран, потому что создать таблицу с настоящим one-hot-encoding даже с большим кол-во оперативной памяти становится проблемой\n",
    "\n",
    "class CatFeatureEncoder:\n",
    "    def __init__(self):\n",
    "        self.encod_dict = None\n",
    "        self.nan_value = 0\n",
    "        self.min_count = 10\n",
    "\n",
    "    def fit(self, feature: pd.Series):\n",
    "        unique_values, unique_counts = np.unique(feature, return_counts=True)\n",
    "\n",
    "        # значение 0 будет использоваться для тех случаев в transform, когда значения нет в self.unique_values\n",
    "        # тем, у кого меньше 20 наблюдений, тоже назначим категорию 0\n",
    "        unique_values = unique_values[unique_counts >= self.min_count]\n",
    "        self.encod_dict = {k: v + 1 for v, k in enumerate(unique_values)}\n",
    "\n",
    "    def transform(self, feature: pd.Series):\n",
    "        return feature.map(self.encod_dict).fillna(self.nan_value).astype(int)\n",
    "\n",
    "    def fit_transform(self, feature: pd.Series):\n",
    "        self.fit(feature)\n",
    "        return self.transform(feature)\n",
    "\n",
    "class ClicksDataset(Dataset):\n",
    "    def __init__(self, df, encoders=None):\n",
    "        data = df.copy()\n",
    "        data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # создаем колонки час и день недели\n",
    "        data['hour'] = data['date_time'].dt.hour\n",
    "        # логарифмируем колонку campaign_clicks\n",
    "        data['campaign_clicks'] = np.log(data['campaign_clicks']+0.001)\n",
    "        # лейбл\n",
    "        self.y = np.array(data['clicks'])\n",
    "        data = data.drop([\"clicks\"], axis=1)\n",
    "        # эти колонки будем использовать для обучения (кроме date и clicks)\n",
    "        data = data[['hour', 'os_id', 'country_id', 'zone_id', 'banner_id', 'oaid_hash', 'campaign_clicks']]\n",
    "\n",
    "        # вместо OneHotEncoding заменим во всех категориальных фичах значения на 1...N, где N- кол-во уникальных значений в колонке\n",
    "        # в таком виде данные будут обрабатываться моделью\n",
    "        cols_to_factorize = ['hour', 'os_id', 'country_id', 'zone_id', 'banner_id', 'oaid_hash']\n",
    "        # если не передали encoder в init (для трейна) - обучаем его, фиттим на данные\n",
    "        if encoders is None:\n",
    "            self.encoders = [CatFeatureEncoder() for _ in range(len(cols_to_factorize))]\n",
    "        # если передали (для вала и теста), то используем существующий\n",
    "        else:\n",
    "            self.encoders = encoders\n",
    "\n",
    "        # кодируем все категориальные фичи\n",
    "        X = []\n",
    "        for i, col in enumerate(cols_to_factorize):\n",
    "            enc = self.encoders[i]\n",
    "            if encoders is None:\n",
    "                X.append(enc.fit_transform(data[col]))\n",
    "            else:\n",
    "                X.append(enc.transform(data[col]))\n",
    "        # присоединяем campaign_clicks отдельно\n",
    "        X.append(np.array(data['campaign_clicks']))\n",
    "\n",
    "        self.X = np.stack(X, axis=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        y = self.y[item]\n",
    "        x = self.X[item, :]\n",
    "        return torch.from_numpy(x).type(torch.float32), torch.from_numpy(np.array(y)).type(torch.float32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12049046 1643448 2128978\n"
     ]
    }
   ],
   "source": [
    "# возьмем в тест последний день, в валидацию - предпоследний день\n",
    "# в трейн пойдет все остальные дни до них\n",
    "\n",
    "train_data = data[data['date_time'].dt.date <= pd.Timestamp('2021-09-30').date()]#.sample(n=1500000, random_state=10)\n",
    "val_data = data[data['date_time'].dt.date == pd.Timestamp('2021-10-01').date()]#.sample(n=500000, random_state=10)\n",
    "test_data = data[data['date_time'].dt.date == pd.Timestamp('2021-10-02').date()]\n",
    "\n",
    "print(len(train_data), len(val_data), len(test_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# подготовим датасеты для обучения и валидации\n",
    "train_dataset = ClicksDataset(train_data)\n",
    "val_dataset = ClicksDataset(val_data, train_dataset.encoders)\n",
    "\n",
    "del train_data\n",
    "del val_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Модель\n",
    "\n",
    "Теперь напишем Field-Aware Factorization Machines.\n",
    "\n",
    "Я тут помимо того, что обсуждали на лекции, еще ввожу какие-то дополнительные вещи для того, чтобы корректней обрабатывать интеракии категориальных фич с числовыми и для имплементации линейных слоев для категориальных и числовых фич.\n",
    "\n",
    "Модель можно описать следующим образом:\n",
    "\n",
    "$$y = \\sigma(\\text{LinearEmbLayer}(categ.feat.) + \\text{Linear}(contin.feat.) + \\text{FAFM(all features)})$$, где FAFM - FieldAwareFactorizationMachine  выглядит как:\n",
    "\n",
    "$$\\text{FAFM(all features)} = \\text{FAFM(categ.feat. x categ. feat.)} + \\text{FAFM(categ. feat. x cont. feat)} + (\\text{FAFM(cont. feat. x cont. feat))}$$\n",
    "\n",
    "(последнего слагаемого у нас нет, т.к. одна числовая фича\n",
    "\n",
    "В $\\text{FAFM(categ.feat. x categ. feat.)}$ все так, как обсуждалось на лекции - создаются эмбеддинги для интеракций со всеми другими фичами, перемножаются.\n",
    "\n",
    "В $\\text{FAFM(categ. feat. x cont. feat)}$ создаются еще эмбеддинги для категориальных фич для их взаимодейтсвия с количественной фичей, и просто умножаются на нее.\n",
    "\n",
    "Размерность эмбеддингов везде равна 10.\n",
    "\n",
    "Оптимизатор взяла AdaGrad по совету с лекции с дефолтными параметрами и weight_decay=5e-4 (L2 рег-ция).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# необходимые слои для FFM + сама модель FFM\n",
    "\n",
    "class LinearEmbLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Линейный слой, реализованный через nn.Embedding, для работы с категориальным фичами\n",
    "    \"\"\"\n",
    "    def __init__(self, field_num_dims, output_dim=1):\n",
    "        super().__init__()\n",
    "        # nn.Embedding почти то же самое, что и nn.Linear\n",
    "        #self.W = nn.Embedding(sum(field_num_dims), output_dim)\n",
    "        self.W = nn.Embedding(sum(field_num_dims), output_dim)\n",
    "        #self.b = nn.Parameter(torch.zeros((len(field_num_dims), output_dim)), requires_grad=True)\n",
    "        # у меня проблемы с этим nn.Parameter - по какой-то причине, pytorch не сохраняет его в чекпойнт\n",
    "        # он 100% оптимизируется, есть в параметрах модели, это проверяла\n",
    "        # но при загрузке модели инициализируется с нуля, поэтому сразу на тесте метрики падают очень сильно\n",
    "        # поэтому тут будет этот странный костыль с добавлением еще одного линейного слоя\n",
    "        # (просто чтобы все-таки более честно изобразить линейный слой через слой nn.Embedding)\n",
    "        # P.S. разобралась, я неправильно загружала чекпойнт, но заново обучать сеть, пожалуй, не буду\n",
    "        self.linear = nn.Linear(len(field_num_dims), output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #return torch.sum(self.W(x) + self.b, dim=1)\n",
    "        return self.linear(self.W(x).squeeze(2))\n",
    "\n",
    "# с числовой переменной (у нас такая campaign_clicks), буду использовать обычный линейный слой\n",
    "\n",
    "\n",
    "class FieldAwareFactorizationMachine(nn.Module):\n",
    "    \"\"\"\n",
    "    слой для FFM (для обучения интеракций между фичами, разные эмбеддинги фичи для интеракций с разными фичами\n",
    "    \"\"\"\n",
    "    def __init__(self, field_num_dims, embed_dim, cat_feats, cont_feats):\n",
    "        super().__init__()\n",
    "        self.cat_feats = cat_feats\n",
    "        self.cont_feats = cont_feats\n",
    "        self.num_fields = len(field_num_dims)\n",
    "        # эмбеддинги для взаимодействия категориальных фичей с категориальными фичами\n",
    "        # на позиции [i, j] находится эмбеддинг для взаимодействия j категории (среди всех значений всех категорий)\n",
    "        # с эмбеддингом i признака\n",
    "        self.cat_embeddings = torch.nn.ModuleList([\n",
    "            torch.nn.Embedding(sum(field_num_dims), embed_dim) for _ in range(self.num_fields)\n",
    "        ])\n",
    "        # эмбеддинги для взаимодействия категориальных фичей с числовыми фичами\n",
    "        self.cont_embeddings = torch.nn.ModuleList([\n",
    "            torch.nn.Embedding(sum(field_num_dims), embed_dim) for _ in range(len(self.cont_feats))\n",
    "        ])\n",
    "        for embedding in self.cat_embeddings:\n",
    "            torch.nn.init.xavier_uniform_(embedding.weight.data)\n",
    "        for embedding in self.cont_embeddings:\n",
    "            torch.nn.init.xavier_uniform_(embedding.weight.data)\n",
    "        self.num_cat_values = sum(field_num_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # получаем эмбеддинги для всех значений всех категориальных фич\n",
    "        xs = [self.cat_embeddings[i](x[:, self.cat_feats].type(torch.int)) for i in range(self.num_fields)]\n",
    "        interactions = list()\n",
    "        # считаем взаимодействия всех категориальных признаков\n",
    "        for i in range(self.num_fields - 1):\n",
    "            for j in range(i + 1, self.num_fields):\n",
    "                interactions.append(xs[j][:, i] * xs[i][:, j])\n",
    "        # взаимодействия всех числовых признаков со всем остальными\n",
    "        # получаем эмбеддинги для всех значений всех категориальных фич (относительно числовых)\n",
    "        xs = [self.cont_embeddings[i](x[:, self.cat_feats].type(torch.int)) for i in range(len(self.cont_feats))]\n",
    "        # взамодействия между категор. и числовыми фичами\n",
    "        for i in range(self.num_fields):\n",
    "            for j in range(len(self.cont_feats)):\n",
    "                interactions.append(xs[j][:, i] * x[:, j].view(-1, 1))\n",
    "        # взамодействия между числовыми фичами\n",
    "        for i in range(len(self.cont_feats)-1):\n",
    "            for j in range(i + 1, len(self.cont_feats)):\n",
    "                interactions.append(x[:, i] * x[:, j])\n",
    "\n",
    "        interactions = torch.stack(interactions, dim=1)\n",
    "        return interactions\n",
    "\n",
    "\n",
    "class FFModel(nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim, cat_feats, cont_feats):\n",
    "        \"\"\"\n",
    "        :param field_dims: список с кол-вом уникальных значений в категориальных фичах (в порядке этих фичей)\n",
    "        :param embed_dim: размерность эмбеддингов\n",
    "        :param cat_feats: индексы категориальных фичей\n",
    "        :param cont_feats: индексы числовых фичей\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # линейный слой для работы с категориальными фичами\n",
    "        self.emb_linear = LinearEmbLayer(field_dims, 1)\n",
    "        # линейный слой для работы с числовыми фичами\n",
    "        self.linear = nn.Linear(len(cont_feats), 1)\n",
    "        self.ffm = FieldAwareFactorizationMachine(field_dims, embed_dim, cat_feats, cont_feats)\n",
    "        self.cat_feats = cat_feats\n",
    "        self.cont_feats = cont_feats\n",
    "        # далее 6 категориальных фичей как бы расплющиваются в одну, создавая одну большую категориальную фичу\n",
    "        # для этого посчитаем сдвиги, которые надо прибавить к фичам, чтобы сохранить их различия\n",
    "        self.offsets = np.array((0, *np.cumsum(len(field_dims))[:-1]), dtype=np.long)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x[:, self.cat_feats] = x[:, self.cat_feats] + x.new_tensor(self.offsets).unsqueeze(0)\n",
    "        ffm = torch.sum(torch.sum(self.ffm(x), dim=1), dim=1, keepdim=True)\n",
    "        x = self.linear(x[:, self.cont_feats]) + self.emb_linear(x[:, self.cat_feats].type(torch.int)) + ffm\n",
    "        return torch.sigmoid(x.squeeze(1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# pytorch Lightning модель для обучения\n",
    "class ClicksModel(pl.LightningModule):\n",
    "    def __init__(self, field_dims, embed_dim, cat_feats, cont_feats):\n",
    "        super().__init__()\n",
    "        self.model = FFModel(field_dims, embed_dim, cat_feats, cont_feats)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        loss = nn.BCELoss()\n",
    "        preds = self(x)\n",
    "        return {'loss': loss(preds, y), 't_preds': preds, 't_true': y}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        roc = AUROC(num_classes=2).to(self.device)\n",
    "        all_preds = torch.hstack([x['t_preds'] for x in outputs])\n",
    "        all_targets = torch.hstack([x['t_true'] for x in outputs])\n",
    "        avg_roc = roc(all_preds, all_targets.type(torch.int))\n",
    "        print(f\"Epoch {self.trainer.current_epoch}, Train_loss: {round(float(avg_loss), 3)}, \"\n",
    "              f\"Train_roc_auc: {round(float(avg_roc), 3)}\")\n",
    "        self.log('train_loss', avg_loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log('train_roc_auc', avg_roc, prog_bar=True, on_epoch=True, on_step=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\" Define optimizers and LR schedulers. \"\"\"\n",
    "        # optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "        optimizer = torch.optim.Adagrad(self.parameters(), weight_decay=5e-4)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                  mode='max',\n",
    "                                                                  factor=0.2,\n",
    "                                                                  patience=5,\n",
    "                                                                  verbose=True)\n",
    "        lr_dict = {\n",
    "            \"scheduler\": lr_scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "            \"monitor\": \"val_roc_auc\"\n",
    "        }\n",
    "\n",
    "        return [optimizer], [lr_dict]\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"the full validation loop\"\"\"\n",
    "        x, y = batch\n",
    "        ce_loss = nn.BCELoss()\n",
    "        preds = self(x).detach()\n",
    "        loss = ce_loss(preds, y)\n",
    "        return {'val_loss': loss, 'v_preds': preds, 'v_true': y}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \"\"\"log and display average val loss and val_f1\"\"\"\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        roc = AUROC(num_classes=2).to(self.device)\n",
    "        all_preds = torch.hstack([x['v_preds'] for x in outputs])\n",
    "        all_targets = torch.hstack([x['v_true'] for x in outputs])\n",
    "        val_roc = roc(all_preds, all_targets.type(torch.int))\n",
    "        print(f\"Epoch {self.trainer.current_epoch}, Val_loss: {round(float(avg_loss), 3)}, \"\n",
    "              f\"Val_roc_auc: {round(float(val_roc), 3)}\")\n",
    "        self.log('val_loss', avg_loss, prog_bar=True, on_epoch=True, on_step=False)\n",
    "        self.log('val_roc_auc', val_roc, prog_bar=True, on_epoch=True, on_step=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# функция для обучения модели\n",
    "\n",
    "def train():\n",
    "\n",
    "    MyModelCheckpoint = ModelCheckpoint(dirpath='checkpoints/',\n",
    "                                        filename='best_model',\n",
    "                                        monitor='val_roc_auc',\n",
    "                                        mode='max',\n",
    "                                        save_top_k=1)\n",
    "\n",
    "\n",
    "    MyEarlyStopping = EarlyStopping(monitor=\"val_roc_auc\",\n",
    "                                    mode=\"max\",\n",
    "                                    patience=10,\n",
    "                                    verbose=True)\n",
    "\n",
    "    # колонки ['hour', 'os_id', 'country_id', 'zone_id', 'banner_id', 'oaid_hash']\n",
    "\n",
    "    field_dims = np.max(train_dataset.X[:, :-1], axis=0).astype(int) + 1\n",
    "    cat_feats = np.arange(train_dataset.X.shape[1]-1)\n",
    "    cont_feats = [train_dataset.X.shape[1]-1]\n",
    "    # размер эмбеддингов будет равен 10\n",
    "    model = ClicksModel(field_dims, 10, cat_feats, cont_feats)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=2048)\n",
    "    val_loader = DataLoader(val_dataset, shuffle=False, batch_size=2048)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "        gpus=1,\n",
    "        callbacks=[MyEarlyStopping, MyModelCheckpoint],\n",
    "        log_every_n_steps=1\n",
    "    )\n",
    "    trainer.fit(model, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | FFModel | 11.7 M\n",
      "----------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.676    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "548771a438884ba78124325b8a42f0e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val_loss: 0.471, Val_roc_auc: 0.52\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efc6036ad41e4325b2b45f270a808388"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "971180a46d404aefa3b5b5275122343d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved. New best score: 0.738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val_loss: 0.16, Val_roc_auc: 0.738\n",
      "Epoch 0, Train_loss: 0.102, Train_roc_auc: 0.718\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9faf760426fa4c199a317371eb4ef4e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.010 >= min_delta = 0.0. New best score: 0.748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val_loss: 0.158, Val_roc_auc: 0.748\n",
      "Epoch 1, Train_loss: 0.098, Train_roc_auc: 0.742\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d78b5b0fc574f8eb9589d481bb29631"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.003 >= min_delta = 0.0. New best score: 0.751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Val_loss: 0.157, Val_roc_auc: 0.751\n",
      "Epoch 2, Train_loss: 0.097, Train_roc_auc: 0.748\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "86cd724b8d55460b8f516f8c718bfb33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.006 >= min_delta = 0.0. New best score: 0.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Val_loss: 0.156, Val_roc_auc: 0.756\n",
      "Epoch 3, Train_loss: 0.097, Train_roc_auc: 0.752\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27e683851791485ca22e27f0a42d7521"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.007 >= min_delta = 0.0. New best score: 0.764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Val_loss: 0.155, Val_roc_auc: 0.764\n",
      "Epoch 4, Train_loss: 0.097, Train_roc_auc: 0.755\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acd1e1226ba840be833dd6fe417c031d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Val_loss: 0.155, Val_roc_auc: 0.763\n",
      "Epoch 5, Train_loss: 0.096, Train_roc_auc: 0.758\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5778c5465d4148ec9cb1e8fb35049372"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.003 >= min_delta = 0.0. New best score: 0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Val_loss: 0.154, Val_roc_auc: 0.767\n",
      "Epoch 6, Train_loss: 0.096, Train_roc_auc: 0.759\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "449be85cb14541098cbd3b4921b57e83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.000 >= min_delta = 0.0. New best score: 0.767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Val_loss: 0.154, Val_roc_auc: 0.767\n",
      "Epoch 7, Train_loss: 0.096, Train_roc_auc: 0.761\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e49a86c52b848b68c1ae5dbf31ee7d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.001 >= min_delta = 0.0. New best score: 0.768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Val_loss: 0.154, Val_roc_auc: 0.768\n",
      "Epoch 8, Train_loss: 0.096, Train_roc_auc: 0.762\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af1017d97f734afabe5d62981c3e40ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Val_loss: 0.154, Val_roc_auc: 0.768\n",
      "Epoch 9, Train_loss: 0.096, Train_roc_auc: 0.763\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5c09c7a7fc54a9a9c88344d6a2bc079"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.003 >= min_delta = 0.0. New best score: 0.771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Val_loss: 0.154, Val_roc_auc: 0.771\n",
      "Epoch 10, Train_loss: 0.096, Train_roc_auc: 0.764\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24d2443eb5314730b0e659802c0fd690"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Val_loss: 0.154, Val_roc_auc: 0.77\n",
      "Epoch 11, Train_loss: 0.096, Train_roc_auc: 0.764\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "049d7efb7c6b41f6a520275f3603e994"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Val_loss: 0.154, Val_roc_auc: 0.77\n",
      "Epoch 12, Train_loss: 0.096, Train_roc_auc: 0.765\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ecd16af9d0d4d129fcbba738c835250"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Val_loss: 0.154, Val_roc_auc: 0.771\n",
      "Epoch 13, Train_loss: 0.096, Train_roc_auc: 0.765\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "182cd98732224eeaa7da1d527e6290a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.001 >= min_delta = 0.0. New best score: 0.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Val_loss: 0.154, Val_roc_auc: 0.772\n",
      "Epoch 14, Train_loss: 0.096, Train_roc_auc: 0.765\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e02d1e01e4b4310948d2b09b1d526f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Val_loss: 0.154, Val_roc_auc: 0.773\n",
      "Epoch 15, Train_loss: 0.096, Train_roc_auc: 0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_roc_auc improved by 0.002 >= min_delta = 0.0. New best score: 0.773\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "545066bd00bc439093853900fd3e312e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Val_loss: 0.154, Val_roc_auc: 0.77\n",
      "Epoch 16, Train_loss: 0.096, Train_roc_auc: 0.766\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a823854907c40aa9d103d9aced6e984"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Val_loss: 0.153, Val_roc_auc: 0.771\n",
      "Epoch 17, Train_loss: 0.096, Train_roc_auc: 0.766\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "249b049b33fc4120808b7adff69d13e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Val_loss: 0.154, Val_roc_auc: 0.77\n",
      "Epoch 18, Train_loss: 0.096, Train_roc_auc: 0.766\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91124d597e384c9f851fdedfe9e64064"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Val_loss: 0.154, Val_roc_auc: 0.771\n",
      "Epoch 19, Train_loss: 0.096, Train_roc_auc: 0.767\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00e4c25dea8540eaa17cb8e59153801b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Val_loss: 0.155, Val_roc_auc: 0.771\n",
      "Epoch 20, Train_loss: 0.096, Train_roc_auc: 0.767\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64b633a9317d4319962138de23f99865"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Val_loss: 0.154, Val_roc_auc: 0.771\n",
      "Epoch 21, Train_loss: 0.096, Train_roc_auc: 0.767\n",
      "Epoch 00022: reducing learning rate of group 0 to 2.0000e-03.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65b42ab2744f4ff0b06cdf7e2f5d7029"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Val_loss: 0.154, Val_roc_auc: 0.773\n",
      "Epoch 22, Train_loss: 0.095, Train_roc_auc: 0.772\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bb8672f8d3c4e5cafea3ab701c58d35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Val_loss: 0.154, Val_roc_auc: 0.773\n",
      "Epoch 23, Train_loss: 0.095, Train_roc_auc: 0.772\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a63b2d81483f4d299e04592b756b35f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Val_loss: 0.154, Val_roc_auc: 0.773\n",
      "Epoch 24, Train_loss: 0.095, Train_roc_auc: 0.772\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "744aac449bdc41f5acfbdd5107e3e7df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_roc_auc did not improve in the last 10 records. Best score: 0.773. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Val_loss: 0.154, Val_roc_auc: 0.773\n",
      "Epoch 25, Train_loss: 0.095, Train_roc_auc: 0.772\n"
     ]
    }
   ],
   "source": [
    "train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Оценка модели на тесте"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4159/4159 [00:11<00:00, 374.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.13859916958197083, Roc auc: 0.7466247598149071\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ClicksDataset(test_data, train_dataset.encoders)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=512, num_workers=4)\n",
    "\n",
    "field_dims = np.max(train_dataset.X[:, :-1], axis=0).astype(int) + 1\n",
    "cat_feats = np.arange(train_dataset.X.shape[1]-1)\n",
    "cont_feats = [train_dataset.X.shape[1]-1]\n",
    "model = ClicksModel.load_from_checkpoint('checkpoints/best_model.ckpt', field_dims=field_dims, embed_dim=10, cat_feats=cat_feats, cont_feats=cont_feats)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "predictions = []\n",
    "\n",
    "for x, y in tqdm(test_loader):\n",
    "    predictions.extend(model(x).detach().cpu().numpy().tolist())\n",
    "    y_true.extend(y.cpu().numpy().tolist())\n",
    "\n",
    "ll = log_loss(y_true, predictions)\n",
    "roc = roc_auc_score(y_true, predictions)\n",
    "\n",
    "print(f\"Log loss: {ll}, Roc auc: {roc}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получилось как-то не так уж хорошо, как могло быть (сравнивая с результатами с пред.домашки, где модель была попроще). Хотя, конечно, и лучше бейзлайна.\n",
    "\n",
    "Мои предположения - у меня есть ошибки в имплементации алгоритма (плюс я там сама еще придумала способы работы с числовыми фичами, и не уверена, что правильно придумала)\n",
    "\n",
    "Плюс другое предположение, которое проще проверить: из-за того, что урезали кол-во значение в колонке с идентификаторами пользователя, могло оказаться, что в тесте в этой колонке слишком много нулей (так как заполняла нулями значения тех юзеров, которые были не представлены или представлены слишком мало в датасете). Вообще говоря, это значит, что для модели это все одно значение, что возможно могло плохо сказаться на ее работе.\n",
    "\n",
    "Посмотрим же на распределения значений в этой колонке во всех частях датасета"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0.00000e+00, 1.00000e+00, 2.00000e+00, ..., 1.61559e+05,\n        1.61560e+05, 1.61561e+05]),\n array([8497256,      18,      10, ...,      10,      27,      13]))"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_dataset.X[:, 5], return_counts=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0.00000e+00, 1.00000e+00, 5.00000e+00, ..., 1.61558e+05,\n        1.61560e+05, 1.61561e+05]),\n array([1422091,       2,      15, ...,      21,       6,       1]))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(val_dataset.X[:, 5], return_counts=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0.00000e+00, 3.00000e+00, 5.00000e+00, ..., 1.61555e+05,\n        1.61558e+05, 1.61560e+05]),\n array([1920043,       2,      15, ...,       3,       2,       4]))"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_dataset.X[:, 5], return_counts=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Грустная картина получается, нулей много абсолютно везде, возможно использование этой колонки вообще потеряло смысл. Но использовать ее полностью, без урезания кол-во возможных значений, у меня не получилось - получаются огроменные эмбеддинги, и модель получается тоже огромной. Интересно было бы послушать, как все-таки правильно работать с такого рода категориальными переменными, которые имеют очень много значений, в моделях, подобных FFM.\n",
    "\n",
    "Я бы попробовала сравнить свои результаты с результатами какой-нибудь готовой имплементации FFM, но на это, к сожалению, уже совсем нет времени."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
