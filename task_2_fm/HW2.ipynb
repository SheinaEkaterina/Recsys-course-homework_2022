{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Будем использовать реализацию `field-aware factorization` machine из `xlearn`","metadata":{}},{"cell_type":"code","source":"!wget \"https://github.com/aksnzhy/xlearn/releases/download/v0.4.4/xlearn-0.4.4-py2.py3-none-manylinux1_x86_64.whl\" -O \"xlearn-0.4.4-py2.py3-none-manylinux1_x86_64.whl\"\n!pip install \"xlearn-0.4.4-py2.py3-none-manylinux1_x86_64.whl\"","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:17:51.236646Z","iopub.execute_input":"2022-11-27T21:17:51.237654Z","iopub.status.idle":"2022-11-27T21:18:04.808539Z","shell.execute_reply.started":"2022-11-27T21:17:51.237560Z","shell.execute_reply":"2022-11-27T21:18:04.806720Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2022-11-27 21:17:52--  https://github.com/aksnzhy/xlearn/releases/download/v0.4.4/xlearn-0.4.4-py2.py3-none-manylinux1_x86_64.whl\nResolving github.com (github.com)... 140.82.114.3\nConnecting to github.com (github.com)|140.82.114.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://objects.githubusercontent.com/github-production-release-asset-2e65be/93925242/27e91600-719a-11e9-90ea-cda1ffa5e6e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221127T211752Z&X-Amz-Expires=300&X-Amz-Signature=42e2f80908e3789e42fb91999829159988939f55a9ba15e93184b629d18c2e42&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=93925242&response-content-disposition=attachment%3B%20filename%3Dxlearn-0.4.4-py2.py3-none-manylinux1_x86_64.whl&response-content-type=application%2Foctet-stream [following]\n--2022-11-27 21:17:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/93925242/27e91600-719a-11e9-90ea-cda1ffa5e6e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221127%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221127T211752Z&X-Amz-Expires=300&X-Amz-Signature=42e2f80908e3789e42fb91999829159988939f55a9ba15e93184b629d18c2e42&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=93925242&response-content-disposition=attachment%3B%20filename%3Dxlearn-0.4.4-py2.py3-none-manylinux1_x86_64.whl&response-content-type=application%2Foctet-stream\nResolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 226343 (221K) [application/octet-stream]\nSaving to: ‘xlearn-0.4.4-py2.py3-none-manylinux1_x86_64.whl’\n\nxlearn-0.4.4-py2.py 100%[===================>] 221.04K  --.-KB/s    in 0.02s   \n\n2022-11-27 21:17:52 (10.8 MB/s) - ‘xlearn-0.4.4-py2.py3-none-manylinux1_x86_64.whl’ saved [226343/226343]\n\nProcessing ./xlearn-0.4.4-py2.py3-none-manylinux1_x86_64.whl\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xlearn==0.4.4) (1.7.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xlearn==0.4.4) (1.21.6)\nxlearn is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport copy\nimport json\n\nimport pandas as pd\nimport numpy as np\nimport xlearn as xl\n\nfrom typing import List, Dict, Tuple, Optional\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import log_loss, roc_auc_score\n\n# Без этого не работает xlearn в colab и kaggle\nos.environ['USER'] = 'xlearn'","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:18:04.815502Z","iopub.execute_input":"2022-11-27T21:18:04.815886Z","iopub.status.idle":"2022-11-27T21:18:05.645555Z","shell.execute_reply.started":"2022-11-27T21:18:04.815844Z","shell.execute_reply":"2022-11-27T21:18:05.644320Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Загрузим данные из файла, сразу оставив только нужные колонки. Колонку `impressions` не используем, так как из предыдущего задания помним, что она константа","metadata":{}},{"cell_type":"code","source":"full_data = pd.read_csv(\n    \"data.csv\",\n    usecols=[\n        \"date_time\",\n        \"zone_id\",\n        \"banner_id\",\n        \"campaign_clicks\",\n        \"os_id\",\n        \"country_id\",\n        \"oaid_hash\",\n        \"clicks\"\n    ],\n    parse_dates=[\"date_time\"],\n    infer_datetime_format=True\n)\nfull_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:18:05.647317Z","iopub.execute_input":"2022-11-27T21:18:05.647880Z","iopub.status.idle":"2022-11-27T21:19:08.368570Z","shell.execute_reply.started":"2022-11-27T21:18:05.647813Z","shell.execute_reply":"2022-11-27T21:19:08.367250Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"            date_time  zone_id  banner_id            oaid_hash  \\\n0 2021-09-27 00:01:30        0          0  5664530014561852622   \n1 2021-09-26 22:54:49        1          1  5186611064559013950   \n2 2021-09-26 23:57:20        2          2  2215519569292448030   \n3 2021-09-27 00:04:30        3          3  6262169206735077204   \n4 2021-09-27 00:06:21        4          4  4778985830203613115   \n\n   campaign_clicks  os_id  country_id  clicks  \n0                0      0           0       1  \n1                0      0           1       1  \n2                3      0           0       1  \n3                0      1           1       1  \n4                0      1           0       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>zone_id</th>\n      <th>banner_id</th>\n      <th>oaid_hash</th>\n      <th>campaign_clicks</th>\n      <th>os_id</th>\n      <th>country_id</th>\n      <th>clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-09-27 00:01:30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5664530014561852622</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-09-26 22:54:49</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5186611064559013950</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-09-26 23:57:20</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2215519569292448030</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-09-27 00:04:30</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6262169206735077204</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-09-27 00:06:21</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4778985830203613115</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Analysis + Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Анализ имеющихся данных возьмём из предыдущего дз. \n\nТакже оттуда возьмём часть от `feature engineering`: из колонки `date_time` получим фичу с часом дня.","metadata":{}},{"cell_type":"code","source":"full_data['date'] = full_data['date_time'].dt.date\nfull_data['time'] = full_data['date_time'].dt.time\nfull_data['day_hour'] = full_data.date_time.dt.hour\nfull_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:19:08.371230Z","iopub.execute_input":"2022-11-27T21:19:08.371847Z","iopub.status.idle":"2022-11-27T21:19:22.583455Z","shell.execute_reply.started":"2022-11-27T21:19:08.371813Z","shell.execute_reply":"2022-11-27T21:19:22.582027Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"            date_time  zone_id  banner_id            oaid_hash  \\\n0 2021-09-27 00:01:30        0          0  5664530014561852622   \n1 2021-09-26 22:54:49        1          1  5186611064559013950   \n2 2021-09-26 23:57:20        2          2  2215519569292448030   \n3 2021-09-27 00:04:30        3          3  6262169206735077204   \n4 2021-09-27 00:06:21        4          4  4778985830203613115   \n\n   campaign_clicks  os_id  country_id  clicks        date      time  day_hour  \n0                0      0           0       1  2021-09-27  00:01:30         0  \n1                0      0           1       1  2021-09-26  22:54:49        22  \n2                3      0           0       1  2021-09-26  23:57:20        23  \n3                0      1           1       1  2021-09-27  00:04:30         0  \n4                0      1           0       1  2021-09-27  00:06:21         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>zone_id</th>\n      <th>banner_id</th>\n      <th>oaid_hash</th>\n      <th>campaign_clicks</th>\n      <th>os_id</th>\n      <th>country_id</th>\n      <th>clicks</th>\n      <th>date</th>\n      <th>time</th>\n      <th>day_hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-09-27 00:01:30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5664530014561852622</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2021-09-27</td>\n      <td>00:01:30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-09-26 22:54:49</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5186611064559013950</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-09-26</td>\n      <td>22:54:49</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-09-26 23:57:20</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2215519569292448030</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2021-09-26</td>\n      <td>23:57:20</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-09-27 00:04:30</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6262169206735077204</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2021-09-27</td>\n      <td>00:04:30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-09-27 00:06:21</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4778985830203613115</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2021-09-27</td>\n      <td>00:06:21</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Здесь разделим данные на тест (последний день) и трейн. Также снова вспомним про предыдущее дз и удалим из данных для обучения день `2021-09-01`, так как имеем всего одного прецедента в этот день.","metadata":{}},{"cell_type":"code","source":"full_data = full_data[full_data.date != pd.Timestamp('2021-09-01').date()]\n\ndata_test = full_data[full_data.date == pd.Timestamp('2021-10-02').date()]\nprint(f\"Test size: {len(data_test)}\")\ndata_train = full_data[full_data.date != pd.Timestamp('2021-10-02').date()]\nprint(f\"Train size: {len(data_train)}\")","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:19:22.585035Z","iopub.execute_input":"2022-11-27T21:19:22.585702Z","iopub.status.idle":"2022-11-27T21:19:31.650348Z","shell.execute_reply.started":"2022-11-27T21:19:22.585665Z","shell.execute_reply":"2022-11-27T21:19:31.648856Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Test size: 2128978\nTrain size: 13692493\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Реализация `ffm` из `xlearn` принимает на вход данные в формате `libffm`, поэтому здесь определим функции для конвертации данных из `pandas.DataFrame` в необходимый формат. \n\nНесколько важных моментов:\n* Номера фичам даём такие, какие получили бы при `one-hot` кодировании категориальных фичей и последующей нумерации каждого столбика числом от `0`  до `коичество столбиков (фичей)`\n* В файл для каждого прецедента записываем только те категориальные фичи, которые бы при `one-hot` кодировании у него имели значение `1`. + к категоримальным фичам добавляем числовые\n* На `field`-ы разбиваем наиболее простым способом: один `field` -- это колонка в `pandas.DataFrame`, до `one-hot` кодирования категориальных фичей.\n* Номера для фичей получаем используя только информацию из трейн части данных. Это приводит к тому, что если какое-то значение категориальной фичи не попало в трейн, но есть в тесте, то для предсказания оно использоваться не будет.","metadata":{}},{"cell_type":"code","source":"def collect_categorical_codes(data: pd.DataFrame, categorical_features: List[str]) -> Tuple[Dict[str, Dict[int, int]], int]:\n    \"\"\"\n    Получаем номера для всех категориальных фичей. \n    Как это делаем описано, в коментарии перед данной ячейкой\n    \"\"\"\n    categorical_codes = {}\n    total_codes = 0\n    for feature in categorical_features:\n        label_encoder = LabelEncoder().fit(data[feature])\n        categorical_codes[feature] = {label: code + total_codes for code, label in enumerate(label_encoder.classes_)}\n        total_codes += len(label_encoder.classes_)\n    return categorical_codes, total_codes\n        \ndef collect_feature_codes(data: pd.DataFrame, categorical_features: List[str], numerical_features: List[str]) -> Tuple[Dict[str, Dict[int, int]], Dict[str, int], int]:\n    \"\"\"\n    Получаем номера для всех фичей, которые хотим использовать.\n    \"\"\"\n    categorical_codes, total_features = collect_categorical_codes(data, categorical_features)\n    numerical_codes = {feature: total_features + i for i, feature in enumerate(numerical_features)}\n    return categorical_codes, numerical_codes, total_features + len(numerical_codes)\n\ndef write_data(data: pd.DataFrame, output_path: str, field2id: Dict[str, int], categorical_codes: List[str], numerical_codes: List[str], target: str):\n    \"\"\"\n    Записываем данные в файл в необходимом формате\n    \"\"\"\n    with open(output_path, 'w') as output_file:\n        for index, row in tqdm(data.iterrows(), total=len(data)):\n            sample = f\"{row[target]}\"\n            for feature, feature_codes in categorical_codes.items():\n                code = feature_codes.get(row[feature], None)\n                # Если для значения фичи нет номера, то есть такого значения не было в трейне, \n                # то просто пропускаем эту фичу для текущего прецендента\n                if code is not None:\n                    sample += f\" {field2id[feature]}:{code}:1\"\n            for feature, feature_code in numerical_codes.items():\n                sample += f\" {field2id[feature]}:{feature_code}:{row[feature]}\"\n            output_file.write(f\"{sample}\\n\")\n\ndef convert_to_libffm(data_train: pd.DataFrame, data_test: pd.DataFrame, output_prefix: str, categorical_features: List[str], numerical_features: List[str], target: str):\n    field2id = {feature: i for i, feature in enumerate(numerical_features + categorical_features)}\n    categorical_codes, numerical_codes, total_features = collect_feature_codes(data_train, categorical_features, numerical_features)\n    write_data(data_train, f\"{output_prefix}_train.txt\", field2id, categorical_codes, numerical_codes, target)\n    write_data(data_test, f\"{output_prefix}_test.txt\", field2id, categorical_codes, numerical_codes, target)\n    return f\"{output_prefix}_train.txt\", f\"{output_prefix}_test.txt\"","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:19:31.654648Z","iopub.execute_input":"2022-11-27T21:19:31.655044Z","iopub.status.idle":"2022-11-27T21:19:31.674749Z","shell.execute_reply.started":"2022-11-27T21:19:31.655012Z","shell.execute_reply":"2022-11-27T21:19:31.673395Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Определим здесь колонки, которые будем использовать: это `6` категориальных фичей и `1` числовая.\n\nКаждая колонка -- это один `field`, то есть для нашей `ffm` имеем `7` филдов.","metadata":{}},{"cell_type":"code","source":"categorical_features = [\"zone_id\", \"banner_id\", \"os_id\", \"country_id\", \"oaid_hash\", \"day_hour\"]\nnumerical_features = [\"campaign_clicks\"]","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:19:31.676442Z","iopub.execute_input":"2022-11-27T21:19:31.677790Z","iopub.status.idle":"2022-11-27T21:19:31.692314Z","shell.execute_reply.started":"2022-11-27T21:19:31.677741Z","shell.execute_reply":"2022-11-27T21:19:31.691100Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Model selection","metadata":{}},{"cell_type":"markdown","source":"Здесь опишем функцию по созданию фолдов для кросс-валидации. Каждый фолд отдельно сконвертируем к необходимому формату и сразу сохраним в файл.\n\nСамо разбиение на фолды такое же как в предыдущем дз: `5` фолдов, полученных с помощью `TimeSeriesSplit`. Мотивация такая же как в первом дз.","metadata":{}},{"cell_type":"code","source":"def create_folds(data: pd.DataFrame) -> List[Tuple[str, str]]:\n    # Необходимо для TimeSeriesSplit\n    data = data.sort_values(by=['date_time'])\n\n    splits = []\n\n    np.random.seed(42)\n\n    tscv = TimeSeriesSplit(n_splits=5)\n    for i, (train, val) in enumerate(tqdm(tscv.split(data), total=5)):\n        train = copy.deepcopy(train)\n        np.random.shuffle(train)\n    \n        data_train_i = data.iloc[train]\n        data_val_i = data.iloc[val]\n    \n        split_files = convert_to_libffm(\n            data_train=data_train_i,\n            data_test=data_val_i,\n            output_prefix=f\"data_split_{i}\",\n            categorical_features=categorical_features,\n            numerical_features=numerical_features,\n            target=\"clicks\"\n        )\n        \n        splits.append(split_files)\n    return splits","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:19:31.694764Z","iopub.execute_input":"2022-11-27T21:19:31.695196Z","iopub.status.idle":"2022-11-27T21:19:31.706792Z","shell.execute_reply.started":"2022-11-27T21:19:31.695157Z","shell.execute_reply":"2022-11-27T21:19:31.705543Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Здесь опишем функции по \n* Созданию модели\n* Предикту\n* Считыванию настоящих `label`-ов из файла с данными в формате `libffm`\n* Подсчёту метрик","metadata":{}},{"cell_type":"code","source":"def create_model(param, model_path: str, train_path: str, val_path: Optional[str] = None):\n    ffm_model = xl.create_ffm()\n    ffm_model.setTrain(train_path)\n    if val_path is not None:\n        # Используем early stopping\n        ffm_model.setValidate(val_path)\n    ffm_model.fit(param, model_path)\n    del ffm_model\n\ndef predict(model_path: str, data_path: str) -> np.ndarray:\n    ffm_model = xl.create_ffm()\n    ffm_model.setSigmoid()\n    ffm_model.setTest(data_path)\n    y_pred_positive_class = ffm_model.predict(model_path)\n    \n    y_pred_positive_class = np.expand_dims(y_pred_positive_class, 1)\n    y_pred = np.hstack([1 - y_pred_positive_class, y_pred_positive_class])\n    \n    del ffm_model\n    del y_pred_positive_class\n    \n    return y_pred\n\ndef read_y_true(path: str) -> np.ndarray:\n    y_true = []\n    with open(path) as y_true_file:\n        for line in y_true_file:\n            y_true.append(float(line.split(' ', 1)[0]))\n    return np.array(y_true)\n\ndef get_score(y_true, y_pred):\n    # y_pred.shape == [N, 2].\n    # Первый столбец -- вероятности 0 (отсутствия клика)\n    # Второй столбец -- вероятность 1 (клика)\n    return {\n        'log-loss': log_loss(y_true, y_pred),\n        'roc-auc': roc_auc_score(y_true, y_pred[:, 1])\n    }","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:19:31.708703Z","iopub.execute_input":"2022-11-27T21:19:31.709104Z","iopub.status.idle":"2022-11-27T21:19:31.721931Z","shell.execute_reply.started":"2022-11-27T21:19:31.709071Z","shell.execute_reply":"2022-11-27T21:19:31.720697Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Для `ffm` модели в `xlearn` есть различные параметры. Подбирать будем коэффицент регуляризации и размерность ембедингов для фичей. \n\nТут зафиксируем те параметры, которые не будут меняться","metadata":{}},{"cell_type":"code","source":"SEED = 42\n\n# Взят из туториала по xlearn. \n# Можно было бы подбирать и lr, но это займёт дополнительное время.\nLR = 0.2 \n\nMAX_EPOCHS = 20","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:19:31.725651Z","iopub.execute_input":"2022-11-27T21:19:31.726070Z","iopub.status.idle":"2022-11-27T21:19:31.741036Z","shell.execute_reply.started":"2022-11-27T21:19:31.726037Z","shell.execute_reply":"2022-11-27T21:19:31.740060Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Теперь определим функции по подбору параметров на кросс-валидации. Стоит заметить, что при обучении будем использовать `early stopping`","metadata":{}},{"cell_type":"code","source":"def cv(param, splits: List[Tuple[str, str]]):\n    scores = []\n    for i in tqdm(range(len(splits))):\n        model_path = \"cv_model.out\"\n        \n        create_model(param, model_path, train_path=splits[i][0], val_path=splits[i][1])\n        \n        y_true = read_y_true(splits[i][1])\n        y_pred = predict(model_path, splits[i][1])\n        \n        score = get_score(y_true, y_pred)\n        scores.append(score)\n        del y_pred\n        del y_true\n    return {key: [v[key] for v in scores] for key in scores[0].keys()}\n\ndef search_params(splits, reg_lambdas: List[float], dims: List[int]):\n    result = {}\n    for reg_lambda in reg_lambdas:\n        for dim in dims:\n            param = {'task':'binary', 'seed': SEED, 'lr': LR, 'epoch': MAX_EPOCHS, 'lambda': reg_lambda, 'k': dim}\n            result[(reg_lambda, dim)] = cv(param, splits)\n    return result\n\ndef summarize_search_result(search_result):\n    summary = {}\n    for param, result in search_result.items():\n        summary[param] = {metric: np.mean(scores) for metric, scores in result.items()}\n    return summary","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:19:31.742408Z","iopub.execute_input":"2022-11-27T21:19:31.743577Z","iopub.status.idle":"2022-11-27T21:19:31.756748Z","shell.execute_reply.started":"2022-11-27T21:19:31.743529Z","shell.execute_reply":"2022-11-27T21:19:31.755440Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Запустим кросс валидацию. \n\nВ текущем ноутбуке ячейка не выполнена, так как кросс валидация занимает какое-то время. \n\nЯчейка была выполнена отдельно, но к ноутбуку приложены:\n* логи (файл `cv.log`) \n* результаты (файл `search_param_result.json`)\n* фолды для кросс валидации https://disk.yandex.ru/d/v8-9jeVUHz9LhA","metadata":{}},{"cell_type":"code","source":"splits = create_folds(data_train)\n\nsearch_result = search_params(\n    splits,\n    reg_lambdas=[0.02, 0.002, 0.0002],  # Значение 0.002 взято из туториала по xlearn\n    dims=[4, 8, 12, 16]\n)\n\nwith open('search_param_result.json', 'w') as search_result_file:\n    json.dump(search_result, search_result_file, indent=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на результаты кросс валидации, усреднив метрики по фолдам","metadata":{}},{"cell_type":"code","source":"with open('search_param_result.json') as search_result_file:\n    search_result = json.load(search_result_file)\n    print(json.dumps(summarize_search_result(search_result), indent=4))","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:20:49.486356Z","iopub.execute_input":"2022-11-27T21:20:49.486823Z","iopub.status.idle":"2022-11-27T21:20:49.497120Z","shell.execute_reply.started":"2022-11-27T21:20:49.486784Z","shell.execute_reply":"2022-11-27T21:20:49.495657Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{\n    \"(0.02, 4)\": {\n        \"log-loss\": 0.11539835525103695,\n        \"roc-auc\": 0.7299507150202166\n    },\n    \"(0.02, 8)\": {\n        \"log-loss\": 0.1153856699759717,\n        \"roc-auc\": 0.72988419377394\n    },\n    \"(0.02, 12)\": {\n        \"log-loss\": 0.11538973750783495,\n        \"roc-auc\": 0.7297822414424606\n    },\n    \"(0.02, 16)\": {\n        \"log-loss\": 0.11540441531715931,\n        \"roc-auc\": 0.7296921623171697\n    },\n    \"(0.002, 4)\": {\n        \"log-loss\": 0.10947132751585889,\n        \"roc-auc\": 0.7470878055716395\n    },\n    \"(0.002, 8)\": {\n        \"log-loss\": 0.10950923476995604,\n        \"roc-auc\": 0.7472322523606433\n    },\n    \"(0.002, 12)\": {\n        \"log-loss\": 0.10952441327564229,\n        \"roc-auc\": 0.7472887819711581\n    },\n    \"(0.002, 16)\": {\n        \"log-loss\": 0.10954547443276948,\n        \"roc-auc\": 0.7473441481093044\n    },\n    \"(0.0002, 4)\": {\n        \"log-loss\": 0.10694826109407625,\n        \"roc-auc\": 0.7561098452976388\n    },\n    \"(0.0002, 8)\": {\n        \"log-loss\": 0.10673685807088526,\n        \"roc-auc\": 0.7563976710891531\n    },\n    \"(0.0002, 12)\": {\n        \"log-loss\": 0.10672045664115384,\n        \"roc-auc\": 0.7558525939777178\n    },\n    \"(0.0002, 16)\": {\n        \"log-loss\": 0.10676513561341654,\n        \"roc-auc\": 0.7558183979446261\n    }\n}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Здесь видно, что лучшим коэффициентом регуляризации является `0.0002`. С таким коэффициентом варианты с размерностью `8` и `12` дают примерно одинаковые результаты. Выбрав меньшую размерность, лучшими будем считать следующие параметры:\n* `regularization lambda = 0.0002`\n* `dim = 8`\n\nТак как при кросс валидации мы использовали `early stopping`, то чтобы обучить итоговую модель, осталось определиться с количеством эпох обучения. Для этого ещё раз запустим обучение на самом большом фолде с лучшими параметрами и посмотрим на какой эпохе произошёл `early stopping`.","metadata":{}},{"cell_type":"code","source":"BEST_LAMBDA = 0.0002\nBEST_DIM = 8","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:22:04.111641Z","iopub.execute_input":"2022-11-27T21:22:04.112193Z","iopub.status.idle":"2022-11-27T21:22:04.118371Z","shell.execute_reply.started":"2022-11-27T21:22:04.112149Z","shell.execute_reply":"2022-11-27T21:22:04.116897Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"param = {'task':'binary', 'seed': SEED, 'lr': LR, 'epoch': MAX_EPOCHS, 'lambda': BEST_LAMBDA, 'k': BEST_DIM}\ncreate_model(\n    param, \n    'model.out', \n    train_path='data_splits_5/data_split_4_train.txt', \n    val_path='data_splits_5/data_split_4_test.txt'\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:22:11.452663Z","iopub.execute_input":"2022-11-27T21:22:11.453137Z","iopub.status.idle":"2022-11-27T21:24:10.281679Z","shell.execute_reply.started":"2022-11-27T21:22:11.453101Z","shell.execute_reply":"2022-11-27T21:24:10.280414Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n           _\n          | |\n     __  _| |     ___  __ _ _ __ _ __\n     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n      >  <| |___|  __/ (_| | |  | | | |\n     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n\n        xLearn   -- 0.44 Version --\n----------------------------------------------------------------------------------------------\n\n\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n\u001b[32m[------------] \u001b[0mBinary file (data_splits_5/data_split_4_train.txt.bin) NOT found. Convert text file to binary file.\n\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n\u001b[32m[------------] \u001b[0mBinary file (data_splits_5/data_split_4_test.txt.bin) NOT found. Convert text file to binary file.\n\u001b[32m[------------] \u001b[0mNumber of Feature: 4753950\n\u001b[32m[------------] \u001b[0mNumber of Field: 7\n\u001b[32m[------------] \u001b[0mTime cost for reading problem: 36.13 (sec)\n\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n\u001b[32m[------------] \u001b[0mModel size: 2.02 GB\n\u001b[32m[------------] \u001b[0mTime cost for model initial: 4.80 (sec)\n\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n\u001b[32m[ \u001b[0m   5%\u001b[32m      ]\u001b[0m     1            0.095464            0.148328               11.50\n\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     2            0.091483            0.146703               12.05\n\u001b[32m[ \u001b[0m  15%\u001b[32m      ]\u001b[0m     3            0.087712            0.146452               12.01\n\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     4            0.083701            0.147361               12.37\n\u001b[32m[ \u001b[0m  25%\u001b[32m      ]\u001b[0m     5            0.079332            0.148582               11.66\n\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     6            0.074803            0.151407               11.88\n\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 3, best loss: 0.146452\u001b[0m\n\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n\u001b[32m[------------] \u001b[0mModel file: model.out\n\u001b[32m[------------] \u001b[0mTime cost for saving model: 2.47 (sec)\n\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n\u001b[32m\u001b[1m[------------] Total time cost: 118.82 (sec)\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"`early stopping` случился на `3` эпохе, поэтому будем обучать итоговую модель в течении `3` эпох.","metadata":{}},{"cell_type":"markdown","source":"# Final model training","metadata":{}},{"cell_type":"markdown","source":"Первым делом преобразуем всю обучающую и тестовую выборку к необходимому формату","metadata":{}},{"cell_type":"code","source":"y_true = data_test[\"clicks\"]\n\ndata_train_path, data_test_path = convert_to_libffm(\n    data_train=data_train.sample(frac=1, random_state=42),\n    data_test=data_test,\n    output_prefix=f\"data_full\",\n    categorical_features=categorical_features,\n    numerical_features=numerical_features,\n    target=\"clicks\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:24:54.410903Z","iopub.execute_input":"2022-11-27T21:24:54.411365Z","iopub.status.idle":"2022-11-27T21:53:54.891648Z","shell.execute_reply.started":"2022-11-27T21:24:54.411329Z","shell.execute_reply":"2022-11-27T21:53:54.889858Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13692493 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fe4d2cf5e10452a872d3d9ecf2ff75d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2128978 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"258de325d54746fc97bf21df59420a9d"}},"metadata":{}}]},{"cell_type":"markdown","source":"Наконец обучим итоговую модель","metadata":{}},{"cell_type":"code","source":"best_param = {'task':'binary', 'seed': SEED, 'lr': LR, 'epoch': 3, 'lambda': BEST_LAMBDA, 'k': BEST_DIM}\ncreate_model(\n    best_param, \n    \"best_model.out\", \n    train_path=data_train_path\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:54:13.073672Z","iopub.execute_input":"2022-11-27T21:54:13.074110Z","iopub.status.idle":"2022-11-27T21:55:42.319050Z","shell.execute_reply.started":"2022-11-27T21:54:13.074077Z","shell.execute_reply":"2022-11-27T21:55:42.317687Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n           _\n          | |\n     __  _| |     ___  __ _ _ __ _ __\n     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n      >  <| |___|  __/ (_| | |  | | | |\n     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n\n        xLearn   -- 0.44 Version --\n----------------------------------------------------------------------------------------------\n\n\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Validation file(dataset) not found, xLearn has already disable early-stopping.\u001b[0m\n\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n\u001b[32m[------------] \u001b[0mBinary file (data_full_train.txt.bin) NOT found. Convert text file to binary file.\n\u001b[32m[------------] \u001b[0mNumber of Feature: 5665386\n\u001b[32m[------------] \u001b[0mNumber of Field: 7\n\u001b[32m[------------] \u001b[0mTime cost for reading problem: 38.87 (sec)\n\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n\u001b[32m[------------] \u001b[0mModel size: 2.41 GB\n\u001b[32m[------------] \u001b[0mTime cost for model initial: 5.05 (sec)\n\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n\u001b[32m[------------]\u001b[0m Epoch      Train log_loss     Time cost (sec)\n\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            0.103269               13.20\n\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            0.098696               14.64\n\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            0.094058               14.03\n\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n\u001b[32m[------------] \u001b[0mModel file: best_model.out\n\u001b[32m[------------] \u001b[0mTime cost for saving model: 3.19 (sec)\n\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n\u001b[32m\u001b[1m[------------] Total time cost: 89.24 (sec)\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Получим предикты для последнего дня","metadata":{}},{"cell_type":"code","source":"y_pred = predict(\"best_model.out\", data_test_path)","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:55:56.826078Z","iopub.execute_input":"2022-11-27T21:55:56.826889Z","iopub.status.idle":"2022-11-27T21:56:03.341202Z","shell.execute_reply.started":"2022-11-27T21:55:56.826845Z","shell.execute_reply":"2022-11-27T21:56:03.339690Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n           _\n          | |\n     __  _| |     ___  __ _ _ __ _ __\n     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n      >  <| |___|  __/ (_| | |  | | | |\n     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n\n        xLearn   -- 0.44 Version --\n----------------------------------------------------------------------------------------------\n\n\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for prediction task.\n\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n\u001b[32m[------------] \u001b[0mLoad model from best_model.out\n\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n\u001b[32m[------------] \u001b[0mScore function: ffm\n\u001b[32m[------------] \u001b[0mNumber of Feature: 5665386\n\u001b[32m[------------] \u001b[0mNumber of K: 8\n\u001b[32m[------------] \u001b[0mNumber of field: 7\n\u001b[32m[------------] \u001b[0mTime cost for loading model: 1.71 (sec)\n\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n\u001b[32m[------------] \u001b[0mBinary file (data_full_test.txt.bin) NOT found. Convert text file to binary file.\n\u001b[32m[------------] \u001b[0mTime cost for reading problem: 4.18 (sec)\n\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n\u001b[32m[------------] \u001b[0mThe test loss is: 0.127808\n\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n\u001b[32m\u001b[1m[------------] Total time cost: 6.49 (sec)\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Итоговые метрики для `ffm` модели","metadata":{}},{"cell_type":"code","source":"print(json.dumps(get_score(y_true, y_pred), indent=4))","metadata":{"execution":{"iopub.status.busy":"2022-11-27T21:56:10.857044Z","iopub.execute_input":"2022-11-27T21:56:10.857459Z","iopub.status.idle":"2022-11-27T21:56:12.377133Z","shell.execute_reply.started":"2022-11-27T21:56:10.857427Z","shell.execute_reply":"2022-11-27T21:56:12.376010Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"{\n    \"log-loss\": 0.1278090157666381,\n    \"roc-auc\": 0.8060228967331167\n}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Для сравнения вспомним метрики из предыдущего дз.\n\nМетрики линейной модели:\n```\n{\n    \"log-loss\": 0.13148437882433509,\n    \"roc-auc\": 0.7919810325455986\n}\n```\nМетрики среднего по тестовой выборке:\n```\n{\n    \"log-loss\": 0.15303289904918538,\n    \"roc-auc\": 0.5\n}\n```","metadata":{}},{"cell_type":"markdown","source":"Полученная `ffm` модель показывает наиболее хорошие результаты","metadata":{}}]}