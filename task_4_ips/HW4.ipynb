{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Считываем данные и дропаем ненужные колонки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                    date_time  zone_id  banner_id  os_id  country_id  \\\n0  2021-09-27 00:01:30.000000        0          0      0           0   \n1  2021-09-26 22:54:49.000000        1          1      0           1   \n2  2021-09-26 23:57:20.000000        2          2      0           0   \n3  2021-09-27 00:04:30.000000        3          3      1           1   \n4  2021-09-27 00:06:21.000000        4          4      1           0   \n\n   banner_id0        g0  coeff_sum0  banner_id1        g1  coeff_sum1  clicks  \n0        1240  0.035016   -7.268846           0  0.049516   -5.369901       1  \n1           1  0.054298   -2.657477         269  0.031942   -4.449220       1  \n2           2  0.014096   -3.824875          21  0.014906   -3.939309       1  \n3           3  0.015232   -3.461357          99  0.050671   -3.418403       1  \n4           4  0.051265   -4.009026    11464230  0.032005   -2.828797       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>zone_id</th>\n      <th>banner_id</th>\n      <th>os_id</th>\n      <th>country_id</th>\n      <th>banner_id0</th>\n      <th>g0</th>\n      <th>coeff_sum0</th>\n      <th>banner_id1</th>\n      <th>g1</th>\n      <th>coeff_sum1</th>\n      <th>clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-09-27 00:01:30.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1240</td>\n      <td>0.035016</td>\n      <td>-7.268846</td>\n      <td>0</td>\n      <td>0.049516</td>\n      <td>-5.369901</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-09-26 22:54:49.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.054298</td>\n      <td>-2.657477</td>\n      <td>269</td>\n      <td>0.031942</td>\n      <td>-4.449220</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-09-26 23:57:20.000000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.014096</td>\n      <td>-3.824875</td>\n      <td>21</td>\n      <td>0.014906</td>\n      <td>-3.939309</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-09-27 00:04:30.000000</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.015232</td>\n      <td>-3.461357</td>\n      <td>99</td>\n      <td>0.050671</td>\n      <td>-3.418403</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-09-27 00:06:21.000000</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0.051265</td>\n      <td>-4.009026</td>\n      <td>11464230</td>\n      <td>0.032005</td>\n      <td>-2.828797</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/data.csv')\n",
    "data.drop(['campaign_clicks', 'rate0', 'rate1', 'impressions', 'oaid_hash'], axis=1, inplace=True)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Преобразуем дату"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def analysis(data: pd.DataFrame):\n",
    "    data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "\n",
    "analysis(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разделяем на трейн и тест по дате. От трейна берём один процент, чтобы быстрее обучалось. Делаем три копии теста: одна для подсчёта pi остаётся дата фреймом, две другие для модели с banner_id = banner_id0 и banner_id1 соответственно."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def feature_engineering(data: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame):\n",
    "    train = data[data['date_time'] < '2021-10-02'].sample(frac=0.01, random_state=1337)\n",
    "    train_clicks = train['clicks']\n",
    "    test = data[data['date_time'] >= '2021-10-02']\n",
    "    test = test[test['banner_id0'] == test['banner_id']]\n",
    "    test_for_ips = test.copy()\n",
    "    test_clicks = test['clicks']\n",
    "    train = train.drop(['date_time', 'clicks'], axis=1)\n",
    "    test = test.drop(['date_time', 'clicks'], axis=1)\n",
    "    test_1 = test.copy()\n",
    "    test_1['banner_id'] = test_1['banner_id1']\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    train = ohe.fit_transform(train)\n",
    "    test = ohe.transform(test)\n",
    "    test_1 = ohe.transform(test_1)\n",
    "    return train, train_clicks, test, test_1, test_clicks, test_for_ips\n",
    "\n",
    "train_x, train_y, test_x_0, test_x_1, test_y, test_for_ips = feature_engineering(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверяем, что все данные имеют ожидаемый размер."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date_time  zone_id  banner_id  os_id  country_id  banner_id0  \\\n",
      "0 2021-09-27 00:01:30        0          0      0           0        1240   \n",
      "1 2021-09-26 22:54:49        1          1      0           1           1   \n",
      "2 2021-09-26 23:57:20        2          2      0           0           2   \n",
      "3 2021-09-27 00:04:30        3          3      1           1           3   \n",
      "4 2021-09-27 00:06:21        4          4      1           0           4   \n",
      "\n",
      "         g0  coeff_sum0  banner_id1        g1  coeff_sum1  clicks  \n",
      "0  0.035016   -7.268846           0  0.049516   -5.369901       1  \n",
      "1  0.054298   -2.657477         269  0.031942   -4.449220       1  \n",
      "2  0.014096   -3.824875          21  0.014906   -3.939309       1  \n",
      "3  0.015232   -3.461357          99  0.050671   -3.418403       1  \n",
      "4  0.051265   -4.009026    11464230  0.032005   -2.828797       1  \n",
      "(15821472, 12)\n",
      "(136925,)\n",
      "(136925, 542705)\n",
      "(1890562, 12)\n",
      "(1890562,)\n"
     ]
    }
   ],
   "source": [
    "print(data.head())\n",
    "print(data.shape)\n",
    "print(train_y.shape)\n",
    "print(train_x.shape)\n",
    "print(test_for_ips.shape)\n",
    "print(test_y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Используем LogisticRegression, который упоминался в лекции, вместе с liblinear - не SGD-like оптимизатором."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def create_model(penalty, C):\n",
    "    return LogisticRegression(C = C, penalty=penalty, solver='liblinear')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверяем, что с моделью всё нормально"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc=0.7702231730484378, log_loss=0.1394408753167321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "model = create_model(penalty='l2', C=1).fit(train_x, train_y)\n",
    "y_pred_proba = model.predict_proba(test_x_0)[:, 1]\n",
    "roc_auc_metric = roc_auc_score(test_y, y_pred_proba)\n",
    "log_loss_metric = log_loss(test_y, y_pred_proba)\n",
    "print(f\"roc_auc={roc_auc_metric}, log_loss={log_loss_metric}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "P(N_1 > N_2) = P(N_1 - N_2 > 0) = 1 - F_{N_1 - N_2}(0). N_1 - N_2 - тоже нормальное со средним как разность средних и квадратом стандартного отклонения как сумма квадратов стандартных отклонений. Также добавим немного, чтобы стандартное отклонение было не 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def calc_pi(coeff0, g0, coeff1, g1):\n",
    "    return 1 - norm.cdf(0, loc=coeff0 - coeff1, scale=np.sqrt(g0 ** 2 + g1 ** 2) + 1e-6)\n",
    "\n",
    "pi_0 = calc_pi(test_for_ips['coeff_sum0'], test_for_ips['g0'], test_for_ips['coeff_sum1'], test_for_ips['g1'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Считаем новые коэффы с помощью logit и также подсчитываем pi_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from scipy.special import logit\n",
    "\n",
    "test_for_ips['coeff_sum0_new'] = logit(model.predict_proba(test_x_0)[:, 1])\n",
    "test_for_ips['coeff_sum1_new'] = logit(model.predict_proba(test_x_1)[:, 1])\n",
    "\n",
    "pi_1 = calc_pi(test_for_ips['coeff_sum0_new'], test_for_ips['g0'], test_for_ips['coeff_sum1_new'], test_for_ips['g1'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Чтобы не делить на 0, добавим немного к pi_0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07195291109093356\n"
     ]
    }
   ],
   "source": [
    "cips = np.mean(test_y * np.minimum(pi_1 / (pi_0 + 1e-10), 10))\n",
    "print(cips)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
