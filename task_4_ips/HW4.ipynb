{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy import sparse\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я не стал добавлять код для обработки данных в этот ноутбук, он представлен в `data_processing.py`. В нем выполняются практически такие же операции, как и в первых 2 заданиях, в результате генерируются и сохранаются на диск 2 словаря. Их ключи -- названия признаков или групп признаков в случае one-hot кодирования, значения -- 2-мерные массивы значений. Прочитаем обработанные данные с помощью `pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coeff_sum0': (12041815, 1),\n",
       " 'hour': (12041815, 1),\n",
       " 'coeff_sum1': (12041815, 1),\n",
       " 'country_id': (12041815, 17),\n",
       " 'zone_id': (12041815, 771),\n",
       " 'weekday': (12041815, 1),\n",
       " 'g0': (12041815, 1),\n",
       " 'banner_id': (12041815, 1052),\n",
       " 'g1': (12041815, 1),\n",
       " 'clicks': (12041815, 1),\n",
       " 'os_id': (12041815, 8),\n",
       " 'banner_id1': (12041815, 1052)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/processed\")\n",
    "\n",
    "with open(DATA_DIR / \"train.pkl\", \"rb\") as fin:\n",
    "    train_data = pickle.load(fin)\n",
    "with open(DATA_DIR / \"test.pkl\", \"rb\") as fin:\n",
    "    test_data = pickle.load(fin)\n",
    "\n",
    "feature_names = set(train_data.keys())\n",
    "assert all(feature in feature_names for feature in test_data.keys())\n",
    "{name: train_data[name].shape for name in feature_names}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_arrays(data: dict, use_banner_id1: bool = False\n",
    "                     ) -> tuple[sparse.csr_array, sparse.csr_array]:\n",
    "    features = [\"weekday\", \"hour\", \"zone_id\", \"country_id\", \"os_id\"]\n",
    "    features.append(\"banner_id1\" if use_banner_id1 else \"banner_id\")\n",
    "    x = sparse.hstack([data[feature] for feature in features], format=\"csr\")\n",
    "    y = data[\"clicks\"].ravel()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.10216763969008638\n",
      "test loss: 0.13370016832950768\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = construct_arrays(train_data, False)\n",
    "model = LogisticRegression(C=5.0, solver=\"liblinear\")\n",
    "model.fit(x_train, y_train)\n",
    "train_loss = log_loss(y_train, model.predict_proba(x_train)[:, 1])\n",
    "print(f\"train loss: {train_loss}\")\n",
    "\n",
    "x_test, y_test = construct_arrays(test_data, False)\n",
    "test_loss = log_loss(y_test, model.predict_proba(x_test)[:, 1])\n",
    "print(f\"test loss: {test_loss}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения log loss получились примерно такими же, как и первом задании."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчёт clipped IPS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для расчёта $\\pi_0$ нужно определить вероятность того, что случайная величина $\\xi_0 \\sim N(\\mu_0, \\sigma_0)$ окажется больше чем $\\xi_1 \\sim N(\\mu_1, \\sigma_1)$. Для этого можно ввести случайную величину $\\eta = \\xi_1 - \\xi_0 \\sim N(\\mu_1 - \\mu_0, \\sqrt{\\sigma_1^2 + \\sigma_0^2})$. Тогда искомая веростность $P(\\xi_0 > \\xi_1) = P(\\eta < 0) = \\mathcal{F}_\\eta(0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pi(mu_0: np.ndarray, mu_1: np.ndarray,\n",
    "               sigma_0: np.ndarray, sigma_1: np.ndarray,\n",
    "               min_var: float = 1e-7) -> np.ndarray:\n",
    "    var = np.maximum(np.sqrt(sigma_0**2 + sigma_1**2), min_var)\n",
    "    return norm.cdf((mu_1 - mu_0) / var).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_0_train = compute_pi(train_data[\"coeff_sum0\"], train_data[\"coeff_sum1\"],\n",
    "                        train_data[\"g0\"], train_data[\"g1\"], min_var=1e-7)\n",
    "pi_0_test = compute_pi(test_data[\"coeff_sum0\"], test_data[\"coeff_sum1\"],\n",
    "                       test_data[\"g0\"], test_data[\"g1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для $\\pi_1$ нам понадобятся логиты предсказанных моделей вероятностей для выбранных и алтернативных баннеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_sum0_train = model.predict_log_proba(x_train)[:, 1]\n",
    "\n",
    "x_train1, _ = construct_arrays(train_data, use_banner_id1=True)\n",
    "coeff_sum1_train = model.predict_log_proba(x_train1)[:, 1]\n",
    "\n",
    "coeff_sum0_test = model.predict_log_proba(x_test)[:, 1]\n",
    "\n",
    "x_test1, _ = construct_arrays(test_data, use_banner_id1=True)\n",
    "coeff_sum1_test = model.predict_log_proba(x_test1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_1_train = compute_pi(coeff_sum0_train, coeff_sum1_train,\n",
    "                        train_data[\"g0\"].ravel(), train_data[\"g1\"].ravel())\n",
    "pi_1_test = compute_pi(coeff_sum0_test, coeff_sum1_test,\n",
    "                        test_data[\"g0\"].ravel(), test_data[\"g1\"].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cips(r: np.array, pi_0: np.ndarray, pi_1: np.ndarray,\n",
    "                 lambda_coef: float = 10., eps: float = 1e-7):\n",
    "    return np.mean(r * np.clip(pi_1 / np.maximum(pi_0, eps), None, lambda_coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06499140517867957"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cips(y_train, pi_0_train, pi_1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08643633061000076"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cips(y_test, pi_0_test, pi_1_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения рассчитаем среднее число кликов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02469146054809844, 0.036045013178339795)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49448eeb8252ad14269e9870f41be38726e4e73e71663eea00cd1e0ba3be12df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
