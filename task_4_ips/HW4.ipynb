{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# HW4. Offline Policy Evaluation: Clipped IPS\n",
    "\n",
    "\n",
    "Сначала повторим шаги подготовки данных и обучения модели с первого дз"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Подготовка данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                    date_time  zone_id  banner_id  campaign_clicks  os_id  \\\n1  2021-09-26 22:54:49.000000        1          1                0      0   \n2  2021-09-26 23:57:20.000000        2          2                3      0   \n3  2021-09-27 00:04:30.000000        3          3                0      1   \n4  2021-09-27 00:06:21.000000        4          4                0      1   \n5  2021-09-27 00:06:50.000000        5          5                0      2   \n\n   country_id  banner_id0        g0  coeff_sum0  banner_id1        g1  \\\n1           1           1  0.054298   -2.657477         269  0.031942   \n2           0           2  0.014096   -3.824875          21  0.014906   \n3           1           3  0.015232   -3.461357          99  0.050671   \n4           0           4  0.051265   -4.009026    11464230  0.032005   \n5           2           5  0.337634   -3.222757          37  0.338195   \n\n   coeff_sum1  impressions  clicks  \n1   -4.449220            1       1  \n2   -3.939309            1       1  \n3   -3.418403            1       1  \n4   -2.828797            1       1  \n5   -3.221755            1       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_time</th>\n      <th>zone_id</th>\n      <th>banner_id</th>\n      <th>campaign_clicks</th>\n      <th>os_id</th>\n      <th>country_id</th>\n      <th>banner_id0</th>\n      <th>g0</th>\n      <th>coeff_sum0</th>\n      <th>banner_id1</th>\n      <th>g1</th>\n      <th>coeff_sum1</th>\n      <th>impressions</th>\n      <th>clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2021-09-26 22:54:49.000000</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.054298</td>\n      <td>-2.657477</td>\n      <td>269</td>\n      <td>0.031942</td>\n      <td>-4.449220</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-09-26 23:57:20.000000</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.014096</td>\n      <td>-3.824875</td>\n      <td>21</td>\n      <td>0.014906</td>\n      <td>-3.939309</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-09-27 00:04:30.000000</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.015232</td>\n      <td>-3.461357</td>\n      <td>99</td>\n      <td>0.050671</td>\n      <td>-3.418403</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-09-27 00:06:21.000000</td>\n      <td>4</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0.051265</td>\n      <td>-4.009026</td>\n      <td>11464230</td>\n      <td>0.032005</td>\n      <td>-2.828797</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2021-09-27 00:06:50.000000</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0.337634</td>\n      <td>-3.222757</td>\n      <td>37</td>\n      <td>0.338195</td>\n      <td>-3.221755</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/data.csv')\n",
    "# сразу удаляем ненужные колонки - те, которые не будем использовать ни в обучении, ни в оценке политики\n",
    "data = data.drop([\"oaid_hash\", \"rate0\", \"rate1\"], axis=1)\n",
    "# плюс фильтруем те данные, у которых banner_id0 не совпадает с banner_id, как написано в задании\n",
    "data = data[data['banner_id0'] == data['banner_id']]\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "     banner_id0  banner_id1        g0        g1  coeff_sum0  coeff_sum1  \\\n164          76         401  0.055551  0.030272   -2.926980   -3.390642   \n166          46    11464251  0.017521  0.085038   -1.377320   -3.329596   \n168          76    11464252  0.171074  0.079034   -3.112081   -1.907685   \n169          46           0  0.017439  0.017624   -2.493974   -3.889516   \n359           2          49  0.020414  0.068041   -2.154111   -3.088063   \n\n     clicks  \n164       1  \n166       1  \n168       1  \n169       1  \n359       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>banner_id0</th>\n      <th>banner_id1</th>\n      <th>g0</th>\n      <th>g1</th>\n      <th>coeff_sum0</th>\n      <th>coeff_sum1</th>\n      <th>clicks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>164</th>\n      <td>76</td>\n      <td>401</td>\n      <td>0.055551</td>\n      <td>0.030272</td>\n      <td>-2.926980</td>\n      <td>-3.390642</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>46</td>\n      <td>11464251</td>\n      <td>0.017521</td>\n      <td>0.085038</td>\n      <td>-1.377320</td>\n      <td>-3.329596</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>168</th>\n      <td>76</td>\n      <td>11464252</td>\n      <td>0.171074</td>\n      <td>0.079034</td>\n      <td>-3.112081</td>\n      <td>-1.907685</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>46</td>\n      <td>0</td>\n      <td>0.017439</td>\n      <td>0.017624</td>\n      <td>-2.493974</td>\n      <td>-3.889516</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>2</td>\n      <td>49</td>\n      <td>0.020414</td>\n      <td>0.068041</td>\n      <td>-2.154111</td>\n      <td>-3.088063</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# так как до этого подготовка данных и обучение модели не предполагали наличие этих новых колонок\n",
    "# создадим отдельный датасет только с ними, затем будем использовать его для подсчетов ips\n",
    "test_for_ips = data[pd.to_datetime(data['date_time']) >= pd.to_datetime('2021-10-02')][[\"banner_id0\", \"banner_id1\", \"g0\", \"g1\", \"coeff_sum0\", \"coeff_sum1\", \"clicks\"]].copy()\n",
    "test_for_ips.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16061/4279608246.py:21: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  train = data[data['date'] < pd.to_datetime('2021-10-02')]\n",
      "/tmp/ipykernel_16061/4279608246.py:22: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  test = data[data['date'] == pd.to_datetime('2021-10-02')]\n",
      "/home/alyona-pestova/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0, 4, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/home/alyona-pestova/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [0, 4, 5] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12056598, 2888) (1890562, 2888) (1890562, 2888) (12056598,) (1890562,)\n"
     ]
    }
   ],
   "source": [
    "# а данные для обучения и теста модели подготовим почти идентично с тем, как готовили к первому дз\n",
    "# по факту просто убираю колонку campaign_clicks\n",
    "# плюс сразу готовлю два отдельных тестовых датасета X_test и X_test_counter\n",
    "# - реальный тест (banner_id = banner_id0) и тест, где banner_id = banner_id1\n",
    "\n",
    "def feature_engineering(data: pd.DataFrame):\n",
    "    data = data.copy()\n",
    "    data = data.drop([\"banner_id0\", \"g0\", \"g1\", \"coeff_sum0\", \"coeff_sum1\", \"campaign_clicks\"], axis=1)\n",
    "\n",
    "    # создаем колонки час и день недели\n",
    "    data['date_time'] = pd.to_datetime(data['date_time'])\n",
    "    data['day_of_week'] = data['date_time'].dt.dayofweek\n",
    "    data['hour'] = data['date_time'].dt.hour\n",
    "    data['date'] = data['date_time'].dt.date\n",
    "    # эти колонки будем использовать для обучения (кроме date и clicks и banner_id1)\n",
    "    data = data[['day_of_week', 'hour', 'os_id', 'country_id', 'zone_id', 'banner_id', 'date', 'clicks', \"banner_id1\"]]\n",
    "    # здесь добавляю единицу, чтобы далее чуть более корректно обрабатывались нечастые случаи (и те, которые не встречались) в OneHotEncoder\n",
    "    # там они будут заменяться нулями, поэтому сдвигаю оригинальные значения на 1\n",
    "    data[['day_of_week', 'hour', 'os_id', 'country_id', 'zone_id', 'banner_id']] += 1\n",
    "    # делим на train и test\n",
    "    train = data[data['date'] < pd.to_datetime('2021-10-02')]\n",
    "    test = data[data['date'] == pd.to_datetime('2021-10-02')]\n",
    "    # лейблы\n",
    "    y_train = np.array(train['clicks'])\n",
    "    y_test = np.array(test['clicks'])\n",
    "    test_counter = test.copy()\n",
    "    test_counter['banner_id'] = test_counter['banner_id1']\n",
    "    train = train.drop(['date', \"clicks\", \"banner_id1\"], axis=1)\n",
    "    test = test.drop(['date', \"clicks\", \"banner_id1\"], axis=1)\n",
    "    test_counter = test_counter.drop(['date', \"clicks\", \"banner_id1\"], axis=1)\n",
    "    # закодируем все фичи с помощью one-hot-encoding\n",
    "    enc = OneHotEncoder(drop='first', handle_unknown='ignore', sparse=True, min_frequency=10)\n",
    "    X_train = enc.fit_transform(train)\n",
    "    X_test = enc.transform(test)\n",
    "    X_test_counter = enc.transform(test_counter)\n",
    "\n",
    "    return X_train, X_test, X_test_counter, y_train, y_test\n",
    "\n",
    "X_train, X_test, X_test_counter, y_train, y_test = feature_engineering(data)\n",
    "print(X_train.shape, X_test.shape, X_test_counter.shape, y_train.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Модель логистической регрессии. Здесь уже использую параметры, подобранные на пред.домашке, хотя и данные немного отличаются - нет колонки  campaign_clicks, как и написано в задании, однако заново прогонять кросс-валидацию слишком долго."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# обучила модель до этого, далее загружаю ее\n",
    "# model = LogisticRegression(C=1, solver='liblinear', penalty='l1')\n",
    "# model.fit(X_train, y_train)\n",
    "# pickle.dump(model, open('logreg.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "del X_train, y_train, data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Оценим модель на тесте (на последнем дне) стандартными метриками"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = pickle.load(open('logreg.pkl', 'rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.13532973588031427, roc-auc: 0.7906495312129354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "def eval_prediction(y_pred, y_test):\n",
    "    loss = log_loss(y_test, y_pred)\n",
    "    roc_score = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"Log loss: {loss}, roc-auc: {roc_score}\")\n",
    "preds = model.predict_proba(X_test)\n",
    "eval_prediction(preds[:, 1], y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Clipped IPS\n",
    "\n",
    "Сначала посчитаем \\pi_0 для всех наблюдений из теста.\n",
    "\n",
    "\n",
    "Нужно посчитать вероятность того, что одна случайная величина больше другой, то есть мы имеем:\n",
    "\n",
    "$$X \\sim N(\\text{coeff0}, g0^2), Y \\sim N(\\text{coeff1}, g1^2)$$, а их разность\n",
    "\n",
    "$$F_{Y-X} = Y - X \\sim N(\\text{coeff1} - \\text{coeff0}, g0^2 + g1^2)$$\n",
    "\n",
    "нужно посчитать $$P(X > Y) = P(Y - X < 0) = F_{Y-X}(0) = \\Phi\\left(\\dfrac{0 - (\\text{coeff1} - \\text{coeff0})}{\\sqrt{g0^2 + g1^2}}\\right) = \\Phi\\left(\\dfrac{(\\text{coeff0} - \\text{coeff1})}{\\sqrt{g0^2 + g1^2}}\\right)$$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# заметила, что в колонке g1 есть отрицательные значения, что странно для стандартного отклонения\n",
    "# видимо, это опечатка - решила взять его по модулю\n",
    "test_for_ips['g1'] = test_for_ips['g1'].apply(abs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import scipy\n",
    "def calc_pi(coeff_sum0, coeff_sum1, g0, g1):\n",
    "    # считаем вероятность, что N(coeff_sum0 - coeff_sum1, g0**2 + g1**2) > 0\n",
    "    mu = coeff_sum0 - coeff_sum1\n",
    "    sd = np.sqrt(g0 ** 2 + g1 ** 2) + 0.000001\n",
    "    # считаем вероятность того, что значение для нулевого банера больше, чем для первого\n",
    "    return scipy.stats.norm.cdf(mu / sd)\n",
    "\n",
    "np.random.seed(10)\n",
    "test_for_ips['pi_0'] = test_for_ips.apply(lambda x: calc_pi(x.coeff_sum0, x.coeff_sum1, x.g0, x.g1), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь нужно посчитать \\pi_1, для этого сначала прогоним через обученную модель оригинальные тестовые данные и получим вектор coeff_sum0 как логиты от предсказанных вероятностей модели.\n",
    "Затем, сделаем то же для наших counterfactual данных - тех, где banner_id=banner_id1, тем же способом получим coeff_sum1. Далее, используя функцию выше посчитаем \\pi_1 с полученными coeff_sum0 и coeff_sum1 и исходными g0 и g1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    return np.log(p) - np.log(1 - p)\n",
    "\n",
    "# логиты для оригинальных данных\n",
    "test_for_ips[\"preds0\"] = logit(model.predict_proba(X_test)[:, 1])\n",
    "# логиты для counterfactual данных\n",
    "test_for_ips[\"preds1\"] = logit(model.predict_proba(X_test_counter)[:, 1])\n",
    "\n",
    "# считаем \\pi_1\n",
    "test_for_ips[\"pi_1\"] = test_for_ips.apply(lambda x: calc_pi(x.preds0, x.preds1, x.g0, x.g1), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          banner_id0  banner_id1        g0  g1  coeff_sum0  coeff_sum1  \\\n",
      "2237              53    11464658  0.053149 NaN   -2.680475         NaN   \n",
      "2320              53    11464674  0.060256 NaN   -2.683287         NaN   \n",
      "3632              53    11464937  0.053055 NaN   -2.679521         NaN   \n",
      "6396              25    11465428  0.085486 NaN   -2.956483         NaN   \n",
      "10554             53    11466272  0.056577 NaN   -2.673896         NaN   \n",
      "...              ...         ...       ...  ..         ...         ...   \n",
      "15814927         130    14622326  0.150797 NaN   -4.626632         NaN   \n",
      "15816566         141    14622636  0.074683 NaN   -3.462076         NaN   \n",
      "15817556          28    14622810  0.014501 NaN   -2.951138         NaN   \n",
      "15818967          28    14623093  0.007713 NaN   -2.782285         NaN   \n",
      "15821364         141    14623582  0.057890 NaN   -3.317025         NaN   \n",
      "\n",
      "          clicks  pi_0    preds0    preds1  pi_1  \n",
      "2237           1   NaN -0.149904 -1.493457   NaN  \n",
      "2320           1   NaN -0.149904 -1.493457   NaN  \n",
      "3632           1   NaN -0.173967 -1.517520   NaN  \n",
      "6396           1   NaN  1.815853  0.332709   NaN  \n",
      "10554          1   NaN -0.170303 -1.513857   NaN  \n",
      "...          ...   ...       ...       ...   ...  \n",
      "15814927       0   NaN -5.485928 -5.991756   NaN  \n",
      "15816566       0   NaN -3.376541 -3.437464   NaN  \n",
      "15817556       0   NaN -3.026582 -3.198212   NaN  \n",
      "15818967       0   NaN -2.855306 -3.026935   NaN  \n",
      "15821364       0   NaN -2.968744 -3.029667   NaN  \n",
      "\n",
      "[4892 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# плюс оказалось, что для некоторых наблюдений в колонках g0 и coeff_sum1 стоят NA\n",
    "# для дальнейших рассчетов они нужны, поэтому удалю их\n",
    "print(test_for_ips[test_for_ips['g1'].isna()])\n",
    "test_for_ips = test_for_ips[~test_for_ips['g1'].isna()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "теперь осталось только посчитать отношение pi_0 и pi_1, взять минимум из этого отношения и лямбды (равной 10), перемножить с вектором награды (который у нас совпадает с колонкой clicks) и взять среднее."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cips: 0.08673718055443559\n"
     ]
    }
   ],
   "source": [
    "ratio = (test_for_ips[\"pi_0\"].to_numpy() + 0.00001) / (test_for_ips[\"pi_1\"].to_numpy() + 0.00001)\n",
    "ratio = np.clip(ratio, 0, 10)\n",
    "v = ratio * test_for_ips[\"clicks\"].to_numpy()\n",
    "V = np.mean(v)\n",
    "print('cips:', V)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
